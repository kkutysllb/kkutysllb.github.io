<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一花一菩提，一云一世界</title>
  
  <subtitle>佛系ICT人士技术博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://kkutysllb.cn/"/>
  <updated>2019-06-13T18:43:26.024Z</updated>
  <id>https://kkutysllb.cn/</id>
  
  <author>
    <name>kkutysllb</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2019-06-13-正则表达式基础入门</title>
    <link href="https://kkutysllb.cn/2019/06/14/2019-06-13-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"/>
    <id>https://kkutysllb.cn/2019/06/14/2019-06-13-正则表达式基础入门/</id>
    <published>2019-06-13T18:34:29.000Z</published>
    <updated>2019-06-13T18:43:26.024Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是正则表达式"><a href="#什么是正则表达式" class="headerlink" title="什么是正则表达式"></a><strong>什么是正则表达式</strong></h2><p>简单地说，正则表达式就是为处理大量的字符串及文本而定义的一套规则和方法。可能通过这句话大家还是不明白什么是正则表达式，这里我也就不罗列正则表达式的定义了，反正就是罗列了，你还是不明白。我们通过一个例子来说明：<a id="more"></a></p><p>首先，我们在Notepad++中建立一个文本，名字随便起，在文中添加如下三行内容：</p><p><img src="https://i.loli.net/2019/06/14/5d02979ec67fe28937.jpg"></p><p>这时，我们需要搜索这个文本文件中的kkutysllb这个单词，很简单，通过ctrl+F快捷键打开搜索栏，输入kkutysllb即可，如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0297bfe6f2062416.jpg"></p><p>根据搜索结果，我们找到了3个kkutysllb字符组。那么，这时我们需求变一下，需要查找以kkutysllb开头的文本，我们如何查找？眼睛不瘸的你一定发现了，Nodepad++搜索栏中有<strong>“正则表达式”</strong>字串！！！</p><p>所以，我们开心的再次Ctrl+F打开搜索栏，选中正则表达式，在目标栏中输入^kkutysllb，点击查找所有，即可满足我们的需求。</p><p><img src="https://i.loli.net/2019/06/14/5d0297dab6efd13398.jpg"></p><p>是不是很神奇？这就是正则表达式存在的意义，我们可以把上面^kkutysllb看做一个正则表达式（本来就是），这个正则表达式的意思就是“<strong>以kkutysllb开头的行”</strong>。</p><p>到目前为止，我们已经初步接触到了正则表达式，现在让我回过头来看看开头那句话—<strong>简单地说，正则表达式就是为处理大量的字符串及文本而定义的一套规则和方法。</strong>现在，你是不是就理解一点儿了？其实，正则表达式在编写程序时经常会用到，因为我们写的代码程序主要用来处理各种数据和文本，有了正则表达式可以让程序代码足够精简且强大。同时，在Linux的文本处理三剑客中也会经常用到正则表达式（后面会专门讲三剑客工具），通过正则表达式可以将复杂的处理化繁为简，提高运维脚本编写效率，而且<strong>在Linux运维工具中只有三剑客工具支持正则表达式。</strong></p><p>最后，我们正式给出正则表达式的官方定义：<strong>正则表达式，又称规则表达式，英文为Regular Expression，常简写为regex，regexp或RE。正则表达式是计算机科学的一个概念，通常被用来检索、替换那些符合某个模式（规则）的文本。</strong></p><h2 id="正则表达式入门"><a href="#正则表达式入门" class="headerlink" title="正则表达式入门"></a><strong>正则表达式入门</strong></h2><p>为了让大家对Linux中使用正则表达式有个感性认识，我们需要借助一个常见的命令grep来讲述。至于grep是个啥？大家暂时把他理解成一个搜索工具即可，详细用法后面会有一篇专门介绍grep的文章。现在，大家暂时“照猫画猫”跟着我做就行。</p><p>当grep与正则结合时，可以说是如胶似漆。。。不对，应该严肃点儿说是。。。如鱼得水！！！<strong>grep会根据“正则的含义”在文本中搜索符合条件的字符串。</strong>我们首先在目录下创建一个测试文件test，写入如下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># cat test </span></span><br><span class="line">kkutysllb</span><br><span class="line">I Love kkutysllb</span><br><span class="line">He is an interesting man</span><br><span class="line">He is my role model</span><br><span class="line">The qq number of kkutysllb is: 31468130</span><br><span class="line">kkutysllb<span class="string">'s Homepage: https://kkutysllb.cn</span></span><br><span class="line"><span class="string">His common names: kkutysllb,kkutys,123kkutysllb123,kkutysllb78</span></span><br><span class="line"><span class="string">kkutysllb cool</span></span><br></pre></td></tr></table></figure><p>如果我们想搜索出test文件中包括kkutysllb的行，可以使用如下命令：</p><p><img src="https://i.loli.net/2019/06/14/5d02982896d8638434.jpg"></p><p>如上图，可以看出只要包含kkutysllb字符串的行都会被搜索出来。但是如果我们只想搜索以kkutysllb字符串的开始的行呢？这时候，正则表达式就派上用场了。<strong>在正则表达式中，^符号表示以什么字符串开头</strong>，^kkutysllb就表示以kkutysllb字符串开头。因此，为了满足我们的需求，可以使用如下命令：</p><p><img src="https://i.loli.net/2019/06/14/5d0298440a11611473.jpg"></p><p>那么，我们如果想查找以kkutysllb字符串结尾的行呢？可以使$符号来表示以什么字符串结尾，kkutysllb$就表示以kkutysllb字符串结尾。命令如下：</p><p><img src="https://i.loli.net/2019/06/14/5d02986ce8aa912334.jpg"></p><p>我们学会了^和$，知道它们是正则表达式中分别用于锚定行首和行尾，那么如果我们把它们结合起来使用呢？比如：^kkutysllb$代表几个意思？我们先来分下下，^kkutysllb表示以kkutysllb字符串开头，紧接着kkutysllb%$代表以kkutysllb字符串结尾，也就是说<strong>^kkutysllb%$代表</strong>以kkutysllb开头同时以kkutysllb结尾的字符串，也就是说<strong>整行只有kkutysllb一个字符串的场景</strong>。我们不妨验证下，命令如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0298883d19419948.jpg"></p><p>如上图，聪明如我，果然如此！那如果符号^和$之间什么都没有呢？也就是我们要匹配^$代表什么意思？其实，<strong>^$就代表空行的意思。</strong>为了显示清楚，我们将空行的的行号打印出来，命令如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0298a0db5c358766.jpg"></p><p>可以看到我们的测试文件中第9行与第10行为空行，与实际情况一样。</p><p>现在，我们已经能够灵活的锚定行首和行尾了，那么，正则表达式能不能锚定词首或词尾呢？那必须滴。。。<strong>在正则表达式中，”\&lt;”表示锚定词首，”>“表示锚定词尾。</strong>比如：我们想搜索单词以kkutys开头的行，命令如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0298c33c86416242.jpg"></p><p>如上图，可以看见123kkutysllb123这个单词没有被匹配到，至于它所在行被匹配输出，是因为它前后单词都是以kkutys开头的。我们再来匹配以单词cool结尾的行，命令如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0298e1696bb46682.jpg"></p><p>那么，聪明如我你一定想到了，要匹配整个单词，就将”\&lt;”和”>“结合起来使用就行了。其实，在正则表达式中，<strong>除了使用”\&lt;”和”>“去锚定词首和词尾外，还可以使用“\b”去完成同样的锚定功能。</strong>验证如下：</p><p><img src="https://i.loli.net/2019/06/14/5d0298fd5e74197615.jpg"></p><p>如上图，表示搜索以123开头，同时以123结尾，中间是任意多个字母组成的单词的行。根据搜索条件，就找到了123kkutysllb123这个单词所在的行。这里的示例主要是说明<strong>“\b”可以取代”\&lt;”和”>“来锚定词首和词尾，在实际中shell脚本中我也建议大家这样使用。</strong>至于[a-z]*的匹配规则后面会讲到，目前入门这里不是重点。</p><p>“\b”还有一个孪生兄弟“\B”，虽然它们有“血缘”，但是“性格迥异”，也就是功能完全不一样。“\b”是用来锚定词首和词尾，换句话说也就是用来锚定单词的边界。而<strong>“\B”正好相反，它是用来匹配非单词边界的</strong>，这样说可能并不容易理解，看了底下的示例你会秒懂！！！示例如下：</p><p><img src="https://i.loli.net/2019/06/14/5d02991e205d421193.jpg"></p><p>如上图，它的意思是匹配非kkutysllb单词所在的行，也就是说只要该行中存在不是以kkutysllb作为词首和词尾，而是作为中间内容的单词，就会匹配输出。至于“\B”匹配词首或词尾的用法，聪明如我你一定会掌握，这里不再赘述。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>通过上面的示例，大家可能发现我们使用的都是与“位置”有关，比如“行首、行尾、词首、词尾”等，我们可以把上面是示例中用到的符号归纳为“位置匹配”有关的正则表达式符合，我们不妨做个总结，便于以后查询。<strong>这些“位置匹配”相关的符号包括：^、$、\&lt;、>、\b、\B。</strong></p><p><strong>^：表示锚定行首，此字符后面的任意内容必须出现在行首，才能匹配。</strong></p><p><strong>$：表示锚定行尾，此字符前面的任意内容必须出现在行尾，才能匹配。</strong></p><p><strong>^$：表示匹配空行，这里所描述的空行只表示回车符，而空格和tab键制表符等只能算空字符串，不能当做空行处理。</strong></p><p><strong>^abc$：表示abc独占一行的场景才会被匹配到。</strong></p><p><strong>\&lt;或者\b：表示锚定词首，其后面的字符必须作为单词首部出现才能被匹配。</strong></p><p><strong>>或者\b：表示锚定词尾，其前面的字符必须作为单词尾部出现才能被匹配。</strong></p><p><strong>\B：用于匹配非单词边界，与\b是“性格迥异”的亲兄弟。</strong></p><p>在正则表达式中，包含<strong>基础正则表达式</strong>和<strong>扩展正则表达式</strong>两种，大家暂时不用纠结，后面会有专门总结扩展正则表达式的文章。我们现在主要需要掌握的都是基础正则表达式，只要学会了基础正则表达式，掌握扩展正则表达式只是分分钟的事情。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是正则表达式&quot;&gt;&lt;a href=&quot;#什么是正则表达式&quot; class=&quot;headerlink&quot; title=&quot;什么是正则表达式&quot;&gt;&lt;/a&gt;&lt;strong&gt;什么是正则表达式&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;简单地说，正则表达式就是为处理大量的字符串及文本而定义的一套规则和方法。可能通过这句话大家还是不明白什么是正则表达式，这里我也就不罗列正则表达式的定义了，反正就是罗列了，你还是不明白。我们通过一个例子来说明：
    
    </summary>
    
      <category term="shell编程" scheme="https://kkutysllb.cn/categories/shell%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="DevOps" scheme="https://kkutysllb.cn/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-12-网络虚拟化概述</title>
    <link href="https://kkutysllb.cn/2019/06/12/2019-06-12-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A6%82%E8%BF%B0/"/>
    <id>https://kkutysllb.cn/2019/06/12/2019-06-12-网络虚拟化概述/</id>
    <published>2019-06-12T14:09:08.000Z</published>
    <updated>2019-06-12T14:50:30.177Z</updated>
    
    <content type="html"><![CDATA[<p>网络作为提供数据交换的模块，是数据中心内最为核心的基础设施之一，并直接关系到数据中心的能力、规模、可扩展性和管理性。为了满足日益增长的网络服务需求，特别是移动互联网业务的爆发式增长，数据中心逐渐向大型化、自动化、虚拟化、多租户的方向发展。传统网络设备不仅部署慢、调整难、成本高，而且其二层地址表项的规模直接决定了数据中心的规模。为此，网络虚拟化的概念应运而生。<a id="more"></a></p><p><img src="https://i.loli.net/2019/06/12/5d0108389809573087.jpg"></p><p>事实上，网络虚拟化这个概念由来已久。早在1990年代，世界上就出现了第一个虚拟局域网VLAN，后来逐渐出现GRE、VPN、L2TP等网络虚拟化技术。到今天，很多公司如Vmware、华为等都在使用这种不依赖物理设备的技术。最初，网络虚拟技术被设置为一个简单的开关功能，后续随着二层广播风暴的隔离和跨网络连接需求的出现，VLAN和VPN技术也应运而生。如今随着云计算技术的推动，在数据中心层面不再是简单的三层架构，而是演进出了大二层和spine-liaf架构，同时随着东西向流量的增加，I/O虚拟化技术、虚拟接入识别、物理网络可靠性以及路由网络随选SDN等技术为云数据中心提供自动化的强有力手段。</p><h2 id="传统二、三层网络中的虚拟化"><a href="#传统二、三层网络中的虚拟化" class="headerlink" title="传统二、三层网络中的虚拟化"></a>传统二、三层网络中的虚拟化</h2><h3 id="网络的基础知识—OSI模型和TCP-IP模型"><a href="#网络的基础知识—OSI模型和TCP-IP模型" class="headerlink" title="网络的基础知识—OSI模型和TCP/IP模型"></a><strong>网络的基础知识—OSI模型和TCP/IP模型</strong></h3><p><strong>开放式系统互联通信参考模型</strong>（Open System Interconnection Reference Model，OSI），简称为OSI模型（OSI model），如下图左边所示，<strong>是一种概念模型</strong>，由国际标准化组织提出，是一个试图使各种计算机在世界范围内互连为网络的标准框架。OSI的七层网络协议体系结构的概念清楚，理论也较为完整，但是它<strong>既复杂也不实用。</strong></p><p><img src="https://i.loli.net/2019/06/12/5d01085f46c1356706.jpg"></p><p>为此，<strong>互联网协议套件（Internet Protocol Suite，IPS</strong>）的概念被提出，它是<strong>一个网络通信模型</strong>，包含整个网络传输协议家族，是网络的基础通信架构，通常被称为TCP/IP协议族（TCP/IP Protocol Suite，或TCP/IP Protocols），简称TCP/IP模型。如上图右边所示，OSI模型与TCP/IP模型的对比示意图。</p><p>TCP/IP模型应用的非常广泛，它是一个四层的体系结构，包括：<strong>网络接口层、网际层（IP）、传输层（TCP或UDP）、应用层（各种应用层协议，如：TELNET、FTP、SMTP等）</strong>。通过这四层的协同工作，能够完成一些特定的任务。每一层创建在低一层提供的服务上，并且为高一层提供服务。 整个TCP/IP协议栈则负责解决数据如何通过许许多多个点对点通路（一个点对点通路，也称为一”跳”, 1 hop）顺利传输，由此不同的网络成员能够在许多”跳”的基础上创建相互的数据通路。 </p><h3 id="绕不开的二层和三层"><a href="#绕不开的二层和三层" class="headerlink" title="绕不开的二层和三层"></a><strong>绕不开的二层和三层</strong></h3><p>二层交换技术是发展比较成熟的技术，二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。三层交换技术就是将路由技术与交换技术合二为一的技术。在对第一个数据流进行路由后，它将会产生一个MAC地址与IP地址的映射表，当同样的数据流再次通过时，将根据此表直接从二层通过而不是再次路由，从而消除了路由器进行路由选择而造成网络的延迟，提高了数据包转发的效率。</p><p><img src="https://i.loli.net/2019/06/12/5d01087e357d454361.jpg"></p><p>二层网络就是数据链路层，只完成本地网络的互通，只识别相同的数据链路层协议，二层交换机是基于MAC地址转发，并且支持高密度以太网接口。而三层网络就是IP网络层，负责不同物理网络的连接，就像是树干一样，将物理世界与应用世界互联。可以识别多种链路层协议，使用IP协议屏蔽差异，兼容互联。三层路由器都是基于IP地址转发，可以支持ATM/SDN/以太网等多种链路层接口。</p><p>数据包在二、三层网络中转发，其封装格式示意图如下所示，数据包从四层发送到三层会被添加上IP首部然后进行转发，同样数据包到达二层会被添加上二层协议如以太首部然后进行转发，这个过程叫做<strong>封装</strong>。</p><p><img src="https://i.loli.net/2019/06/12/5d010898a434795631.jpg"></p><p>数据包从二层发送到三层时，会被二层设备剥离对应的首部，露出上层设备能够识别的首部，如IP首部，同样三层向四层转发的时，也会剥离本层的协议首部露出上层设备能够识别的首部，这个过程叫做<strong>解封装</strong>。能够执行二层封装、解封装的设备为二层设备，如二层交换机。能够执行三层封装、解封装的设备为三层设备，如路由器。三层交换机既能执行二层封装解封装，也能执行三层封装解封装，为三层设备。</p><p>数据包在两个网络端点之间传输，可以有三种传送方式：<strong>单播、组播</strong>和<strong>广播</strong>。</p><p><img src="https://i.loli.net/2019/06/12/5d0108bd833a193969.jpg"></p><p>单播方式中，发送源端明确知道目的端地址，直接使用该地址与接收者建立联系。组播方式中，发送源端将数据同时传递给一组目的地址，多个client组成接收者，接收者与源之间的路径由组播协议计算后得出。在广播方式中，发送源端不知道目的端地址，首先会发一个询问给在同一广播域的所有设备，真正的接收者收到该询问后会给源以单播的方式回一个答复，其他设备则不理会该询问。当网络很大的时候，广播包会占用一定的带宽，造成带宽的浪费，一个二层的本地网络就是广播域。</p><h3 id="最原始的网络虚拟化VLAN的技术实现"><a href="#最原始的网络虚拟化VLAN的技术实现" class="headerlink" title="最原始的网络虚拟化VLAN的技术实现"></a><strong>最原始的网络虚拟化VLAN的技术实现</strong></h3><p>在实际的物理二层网络中，经常会有广播包的发送需求，如果不加限制，除了会带来安全性和带宽占用浪费等问题外，最重要的是会产生<strong>广播风暴</strong>。所谓广播风暴，是指由于网络拓扑的设计和连接问题，或者其他原因导致广播包在网段内大量复制传播，导致网络性能下降甚至瘫痪。如下图所示，为了解决这个问题，传统网络使用虚拟局域网技术VLAN来实现。</p><p><img src="https://i.loli.net/2019/06/12/5d0108ef17a0911208.jpg"></p><p><strong>VLAN的主要作用就是隔离广播域</strong>，不同的VLAN之间不能直接通信。VLAN技术把用户划分成多个逻辑的网络（group），组内可以通信，组间不允许直接通信，二层转发的单播、组播、广播报文只能在组内转发。同时，VLAN技术可以很容易地实现组成员的添加或删除。也就是说，VLAN技术提供了一种管理手段，控制终端之间的互通。如上图，组1和组2的PC无法相互直接通信。</p><p>如下图所示，<strong>VLAN是通过对传统的数据帧添加tag字段来实现的。</strong>添加VLAN信息的方法最常用的就是IEEE802.1Q协议，还有一种是ISL协议。</p><p><img src="https://i.loli.net/2019/06/12/5d0109114f93969773.jpg"></p><p>IEEE802.1Q所附加的VLAN识别信息，位于数据帧中“<strong>发送源MAC地址</strong>”与“<strong>类别域（Type Field）</strong>”之间。具体内容为2字节的<strong>TPID</strong>和2字节的<strong>TCI</strong>，共计4字节。 在数据帧中添加了4字节的内容，那么CRC值自然也会有所变化。这时数据帧上的CRC是插入TPID、TCI后，对包括它们在内的整个数据帧重新计算后所得的值。<strong>TPID (Tag Protocol Identifier）</strong>是IEEE定义的新的类型，表明这是一个加了802.1Q标签的帧，<strong>TPID包含了一个固定的值0x8100</strong>。<strong>TCI (Tag Control Information）</strong>包括<strong>用户优先级(User Priority，3bit)、规范格式指示器(Canonical Format Indicator，1bit)</strong>和 <strong>VLAN ID（12bit）</strong>。VLAN ID 是对 VLAN 的识别字段，支持4096(2的12次方) VLAN 的识别。在4096个可能的VID 中，VID＝0 用于识别帧优先级。 4095(FFF)作为预留值，所以 VLAN 配置的最大可能值为4094，有效的VLAN ID范围一般为1-4094。</p><p>在VLAN中有以下两种链路类型：<strong>普通链路</strong>和<strong>中继链路</strong>。<strong>普通链路（Access Link）是用于连接用户主机和交换机的链路</strong>。通常情况下，主机并不需要知道自己属于哪个VLAN，主机硬件通常也不能识别带有VLAN标记的帧。因此，主机发送和接收的帧都是untagged帧。<strong>中继链路（Trunk Link）是用于交换机间的互连或交换机与路由器之间的连接</strong>。中继链路可以承载多个不同VLAN数据，数据帧在中继链路传输时，中继链路的两端设备需要能够识别数据帧属于哪个VLAN，所以在中继链路上传输的帧都是Tagged帧。</p><p>在VLAN网络中，针对上述两种不同的链路类型使用场景，分别有三种网络端口类型去适配：<strong>Access端口、Trunk端口</strong>和<strong>Hybrid端口</strong>。<strong>Access接口</strong>是交换机上用来连接用户主机的接口，它只能接入【普通链路。仅仅允许唯一的VLAN ID通过本接口，这个VLAN ID与接口的缺省VLAN ID相同，Access接口发往对端设备的以太网帧永远是不带标签的untagged帧。<strong>Trunk接口</strong>是交换机上用来和其他交换机连接的接口，它只能连接中继链路，允许多个VLAN的帧（带Tag标记）通过。<strong>Hybrid接口</strong>是交换机上既可以连接用户主机，又可以连接其他交换机的接口。Hybrid接口既可以连接普通链路又可以连接中继链路。Hybrid接口允许多个VLAN的帧通过，并可以在出接口方向将某些VLAN帧的Tag剥掉。<strong>而在虚拟交换机只用Access接口和Trunk接口。</strong></p><p><strong>各类型接口对数据帧的处理方式汇总如下：</strong></p><table><thead><tr><th><strong>接口类型</strong></th><th><strong>对接收不带Tag的报文处理</strong></th><th><strong>对接收带Tag的报文处理</strong></th><th><strong>发送帧处理过程</strong></th></tr></thead><tbody><tr><td><strong>Access接口</strong></td><td>接收该报文，并打上缺省的VLAN ID。</td><td>当VLAN ID与缺省VLAN ID相同时，接收该报文。当VLAN ID与缺省VLAN ID不同时，丢弃该报文。</td><td>先剥离帧的PVID Tag，然后再发送。</td></tr><tr><td><strong>Trunk接口</strong></td><td>打上缺省的VLAN ID，当缺省VLAN ID在允许通过的VLAN ID列表里时，接收该报文。打上缺省的VLAN ID，当缺省VLAN ID不在允许通过的VLAN ID列表里时，丢弃该报文。</td><td>当VLAN ID在接口允许通过的VLAN ID列表里时，接收该报文。当VLAN ID不在接口允许通过的VLAN ID列表里时，丢弃该报文。</td><td>当VLAN ID与缺省VLAN ID相同，且是该接口允许通过的VLAN ID时，去掉Tag，发送该报文。当VLAN ID与缺省VLAN ID不同，且是该接口允许通过的VLAN ID时，保持原有Tag，发送该报文。</td></tr><tr><td><strong>Hybrid接口</strong></td><td>打上缺省的VLAN ID，当缺省VLAN ID在允许通过的VLAN ID列表里时，接收该报文。打上缺省的VLAN ID，当缺省VLAN ID不在允许通过的VLAN ID列表里时，丢弃该报文。</td><td>当VLAN ID在接口允许通过的VLAN ID列表里时，接收该报文。当VLAN ID不在接口允许通过的VLAN ID列表里时，丢弃该报文。</td><td>当VLAN ID是该接口允许通过的VLAN ID时，发送该报文。可以通过命令设置发送时是否携带Tag。</td></tr></tbody></table><h3 id="爱折腾的VPN"><a href="#爱折腾的VPN" class="headerlink" title="爱折腾的VPN"></a>爱折腾的VPN</h3><p>VPN技术起初是为了解决明文数据在网络上传输带来的安全隐患而产生的。TCP/IP协议族中的很多协议都采用明文传输，如telnet、ftp、tftp等。一些黑客可能为了获取非法利益，通过诸如窃听、伪装等攻击方式截获明文数据，使企业或者个人蒙受损失。VPN技术可以从某种程度上解决该问题。例如，它可以对公网上传输的数据进行加密，即使黑客通过窃听工具截获到数据，也无法了解数据信息的含义。VPN也可以实现数据传输双方的身份验证，避免黑客伪装成网络中的合法用户攻击网络资源。</p><p><strong>VPN（virtual private network，虚拟专用网）就是在两个网络实体之间建立的一种受保护的连接，这两个实体可以通过点到点的链路直接相连</strong>，但通常情况下他们会相隔较远的距离。</p><p><img src="https://i.loli.net/2019/06/12/5d0109693d58327773.jpg"></p><p>VPN技术通过使用加密技术防止数据被窃听，并且通过数据完整性校验防止数据被破坏、篡改。通过认证机制实现通信双方身份确认，来防止通信数据被截获和回放。此外，在VPN中还可以定义何种流量需要被保护，数据被保护的机制以及数据封的过程。</p><p>VPN技术有两种基本的连接模式：<strong>隧道模式</strong>和<strong>传输模式</strong>。这两种模式实际上定义了两台实体设备之间传输数据时所采用的不同的封装过程。<strong>传输模式一个最显著的特点就是：在整个VPN的传输过程中，IP包头并没有被封装进去，这就意味着从源端到目的端数据始终使用原有的IP地址进行通信</strong>。如下图所示，而传输的实际数据载荷被封装在VPN报文中。对于大多数VPN传输而言，VPN的报文封装过程就是数据的加密过程，因此，攻击者截获数据后将无法破解数据内容，但却可以清晰地知道通信双方的地址信息。</p><p><img src="https://i.loli.net/2019/06/12/5d010980d1cb013743.jpg"></p><p>由于传输模式封装结构相对简单（每个数据报文较隧道模式封装结构节省20字节），因此传输效率较高，多用于通信双方在同一个局域网内的情况。</p><p>隧道模式中，如下图所示VPN设备将整个三层数据报文封装在VPN数据内，再为封装后的数据报文添加新的IP包头。由于新IP包头中封装的是VPN设备的ip地址信息，所以当攻击者截获数据后，不但无法了解实际载荷数据的内容，同时也无法知道实际通信双方的地址信息。</p><p><img src="https://i.loli.net/2019/06/12/5d01099ec713e51544.jpg"></p><p>由于隧道模式的VPN在安全性和灵活性方面具有很大的优势，在企业环境中应用十分广泛，总部和分公司跨广域网的通信、移动用户在公网访问公司内部资源等很多情况，都会应用隧道模式的VPN对数据传输进行加密。</p><p>通常情况下，VPN的类型分为<strong>站点到站点VPN</strong>和<strong>远程访问VPN</strong>。站点到站点VPN就是通过隧道模式在VPN网关之间保护两个或者更多的站点之间的流量，站点间的流量通常是指局域网之间（L2L）的通信流量。L2L的VPN多用于总部与分公司、分公司之间在公网上传输重要业务数据。比如：我们各地市VOBB固网用户接入方式就是这种类型，对于两个地市的固网终端用户来说，在VPN网关（针对现网来说可以看成一个统一的逻辑设备，包含现网中的SR、BRAS、FW、CE、SBC等设备)中间的网络是透明的，就好像通过一台路由器连接的两个局域网。各地市终端设备通过VPN连接访问核心网或其他地市接入网络资源。数据包封装的地址都是各地市规划的内网地址（一般为私有地址），而VPN网关对数据包进行的再次封装过程，客户端是全然不知的。</p><p>远程访问VPN通常用于单用户设备与VPN网关之间通信连接，单用户设备一般为一台pc或小型办公网络等。VPN连接的一端为PC，可能会让很多人误解远程访问VPN使用传输模式，但因为该种VPN往往也是从公网传输关键数据，而且单一用户更容易成为黑客的攻击对象，所以远程访问VPN对于安全性要求较高，更适用于隧道模式，如下图所示。</p><p><img src="https://i.loli.net/2019/06/12/5d0109b8111ea32153.jpg"></p><p>要想实现隧道模式的通信，就需要给远程客户端分配两个IP地址：一个是它自己的NIC地址，另一个是内网地址。也就是说远程客户端在VPN建立过程中同时充当VPN网关（使用NIC地址）和终端用户（使用内网地址）。比如：我们使用VPN代理软件从公网访问4A服务器，或者私有云远程用户从公网访问私有云资源都是这种方式。</p><h2 id="数据中心对网络的总体要求"><a href="#数据中心对网络的总体要求" class="headerlink" title="数据中心对网络的总体要求"></a><strong>数据中心对网络的总体要求</strong></h2><p>随着电信云NFV的全面部署，以及后续5G网络架构的演进，利用虚拟化和面向服务的技术，能够为智能设备提供广泛的业务服务。虚拟化是IaaS服务的基础，计算虚拟化将一台物理服务器”分裂“成多个虚拟服务器来调度，虚拟服务器作为业务的承载者和物理服务器一样，有着网络通信需求。也就是说不仅虚拟服务器之间需要网络通信，虚拟服务器与外部也存在网络通信的需求。在这种模式下，计算和存储能力向网络中心迁移，形成云化数据中心，大量的计算请求、信息请求依托网络向数据中心发送，网络成为数据中心的和用户的纽带。因此，如下图所示，云化数据中心对网络存在<strong>业务发展弹性、虚拟感知技术、网络资源整合和共享、高效运维和能耗管理</strong>等4大要求。</p><p><img src="https://i.loli.net/2019/06/12/5d0109d8eaa4462134.jpg"></p><h3 id="业务发展弹性需求"><a href="#业务发展弹性需求" class="headerlink" title="业务发展弹性需求"></a><strong>业务发展弹性需求</strong></h3><p>在信息化蓬勃发展的今天，业务流量增长异常迅猛。为了应对这一切，数据中心不仅需要提升服务器性能和网卡接入带宽，也需要充分利用现有的IT资源。分布式计算和虚拟化应运而生，流量模型随之从南北向流量为主向东西向流量为主转变。</p><p><img src="https://i.loli.net/2019/06/12/5d010a1496dca41543.jpg"></p><p>从Gartner 的报告中可以看到服务器10GE TOR 接入从2011年开始迅速成为主流，所占份额不断扩大，必然会导致网络侧上行40GE/100GE互联大量应用。横向交互流量增大使网络模型从传统的三层模型向胖树架构演进，横向无阻塞和大缓存成为数据中心网络规划设计的基本需求。</p><p>在这种计算、存储、网络整合的云数据中心内，对网络的要求<strong>由连接变为服务</strong>。因为，云计算本身就是一种服务，能按需、弹性提供，且可计量。网络资源被云计算整合在基础设施资源中，自然也是一种可按需、弹性提供，且可计量的服务。</p><h3 id="虚拟感知技术需求"><a href="#虚拟感知技术需求" class="headerlink" title="虚拟感知技术需求"></a><strong>虚拟感知技术需求</strong></h3><p>服务器虚拟化使得可以高效利用IT资源，降低企业运营成本成为可能。服务器内多虚拟机之间的交互流量，传统网络设备无法感知，也不能进行流量监控和必要的策略控制。虚拟机的灵活部署和动态迁移需要网络接入侧做相应的调整，在迁移时保持业务不中断。</p><p><img src="https://i.loli.net/2019/06/12/5d010a439d87c85492.jpg"></p><p>虚拟机的大量运用以及虚拟机交互流量的出现，使网络的前沿深入到服务器内部。虚拟拓扑发现，虚拟机策略下发，接入侧交换机网络配置和动态调整对传统网络模型和管理模式提出了很大的挑战。虚拟机迁移的物理范围不应过小，否则无法充分利用空闲的服务器资源。迁移后虚拟机的IP地址不变，以保持业务不中断。因此，迁移不能跨VLAN。综合以上两点，对数据中心网络提出了大二层的需求。</p><h3 id="网络资源的整合与共享"><a href="#网络资源的整合与共享" class="headerlink" title="网络资源的整合与共享"></a><strong>网络资源的整合与共享</strong></h3><p>数据中心对网络可靠性和安全性的需求是最基本的需求。可靠性设计包括：链路冗余、关键设备冗余和重要业务模块冗余。安全性设计包括物理空间的安全控制及网络的安全控制。企业多业务系统安全隔离和冗余设计导致网络资源成本高昂，利用率低，运维复杂。 </p><p><img src="https://i.loli.net/2019/06/12/5d010a64adca313019.jpg"></p><p>在云计算时代，为了充分利用网络资源实现业务的灵活部署，需要将多业务网络纵向融合成一张物理网，通过网络设备的虚拟化实现业务隔离和冗余备份。对于多类型的网络可以横向融合，通过采用FCOE和DCB等技术降低管理复杂性以及部署扩展性的挑战。</p><h3 id="高效的运维的电源管理"><a href="#高效的运维的电源管理" class="headerlink" title="高效的运维的电源管理"></a><strong>高效的运维的电源管理</strong></h3><p>数据中心内部存在网络设备和IT资源数量大，厂商多，运行配置复杂等问题。数据中心网络延伸到服务器内部，需要物理和虚拟网络拓扑完整展示，实现网络流量的精细化管理和监控，针对网络故障快速定位是对云计算时代数据中心运维的基本需求。 不断攀升的能耗成本，催高了数据中心的运营成本，绿色节能是云计算数据中心的必备条件。</p><p><img src="https://i.loli.net/2019/06/12/5d010a89b362689802.jpg"></p><h2 id="数据中心层面的网络虚拟化"><a href="#数据中心层面的网络虚拟化" class="headerlink" title="数据中心层面的网络虚拟化"></a><strong>数据中心层面的网络虚拟化</strong></h2><p>随着云计算、大数据、物联网等技术的发展，传统的网络虚拟化技术，已经难以满足云时代下多租户的需求。例如：广泛被使用的VLAN技术，虽然可以在物理交换机上通过划分多个VLAN来隔离，并虚拟出多个逻辑网络，但是其设计和配置，通常基于固定的规划，以及网络和服务器的位置不会频繁变更为前提。而面对云化的数据中心，大量虚拟机的动态的生命周期变化，以及弹性漂移和伸缩的特点，对网络提出了更高的按需配置和随动的要求。也就说，在云化数据中心内，网络不仅仅提供连接，更是一种服务，一种像虚拟化的计算资源一样逻辑隔离，弹性且可计量的服务。</p><h3 id="从计算虚拟化走向网络虚拟化"><a href="#从计算虚拟化走向网络虚拟化" class="headerlink" title="从计算虚拟化走向网络虚拟化"></a><strong>从计算虚拟化走向网络虚拟化</strong></h3><p><strong>网络虚拟化是指将网络的控制从网络硬件中脱离出来，交给虚拟化的网络层处理。这个虚拟化的网络层加载在整个物理网络之上，屏蔽掉底层的物理差异，在虚拟空间重建整个网络。</strong>如下图所示，就像计算虚拟化中将物理服务器整合抽象为计算资源池一样，物理网络也被泛化为网络资源池，通过控制面软件的集中调度，使得底层网络资源更加灵活。</p><p><img src="https://i.loli.net/2019/06/12/5d010aca0dde071037.jpg"></p><p>逻辑网络资源池是一种逻辑资源的灵活管理抽象，是对底层物理网络的一种形象描述。每一个虚拟网络可以根据业务或部门进行灵活分配，各个虚拟网络之间逻辑隔离。因此，每个虚拟网络内的网络资源变更，不会影响其它虚拟网络。与服务器虚拟化类似，网络虚拟化可以在很短的时间（秒级）创建L2、L3到L7的网络服务，如交换，路由，防火墙和负载均衡等。虚拟网络独立于底层网络硬件，可以按照业务需求配置、修改、保存、删除，而无需重新配置底层物理硬件或拓扑。这种网络技术的革新为实现软件定义网络SDN和软件定义数据中心（SDDC）奠定了基础。</p><p><img src="https://i.loli.net/2019/06/12/5d010af5908e959720.jpg"></p><p>云化数据中心内部的网络要同时解决<strong>多租户资源隔离</strong>和<strong>内外互通访问</strong>的需求。多租户环境中主要存在私有云场合，一个租户就是任何一个应用，租户内的安全、资源对外隔离且排他，因此需要有网络的隔离作为基础。同时，云化的数据中心不再局限四面墙之内，需要实现地理上相互隔离的故障转移性，位于虚拟网络内的应用需要访问外部网络环境，外部网络环境也需要访问虚拟网络内的资源。因此，虚拟网络也必须具备内外互通的开放性，通过利用隧道封装技术实现跨地理资源的迁移特性。</p><p>如下所示，隧道封装技术是一种通过使用互联网络的基础设施在网络之间传递数据的方式，使用隧道传递的数据（或负载）可以是不同协议的数据帧或包。隧道协议将这些数据帧或包重新封装在新的包头中发送，新的包头提供路由信息，使封装的负载数据可以通过互联网络传递。被封装的数据包在隧道的两个端点之间通过公共互联网络进行路由，其所经过的逻辑路径就是隧道。一旦到达网络端点，数据将被解包并转发到最终的目的地。</p><p><img src="https://i.loli.net/2019/06/12/5d010b1763a9e52967.jpg"></p><p>网络虚拟化将网络的边缘从硬件交换机推到了服务器里面，将服务器和虚拟机的所有部署、管理的职能从原来的系统管理员+网络管理员的模式变成了纯系统管理员的模式，让服务器的业务部署变得简单，不再依赖于形态和功能各异的硬件交换机，一切归于软件控制，实现自动化部署。这就是网络虚拟化在数据中心中最大的价值所在，也是为什么大家明知服务器的性能远远比不上硬件交换机但还是使用网络虚拟化技术的根本原因。</p><h3 id="数据中心网络虚拟化的层次"><a href="#数据中心网络虚拟化的层次" class="headerlink" title="数据中心网络虚拟化的层次"></a>数据中心网络虚拟化的层次</h3><p>随着越来越多的服务器被虚拟化，网络已经延伸到Hypervisor内部，网络通信的端点已经从以前的服务器变成了运行在服务器中的虚拟机，数据包从虚拟机的虚拟网卡流出，通过Hypervisor内部的虚拟交换机，在经过服务器的物理网卡流出到上联交换机。因此，<strong>虚拟化环境下的网络虚拟化需要解决端到端的问题。</strong>在整个过程中，虚拟交换机，网卡的I/O问题以及虚拟机的网络接入都是虚拟化的重点。如下图所示，每一个层面网络虚拟化的实现技术和方式均不同，我个人将其归纳为4个部分：<strong>服务器内部I/O虚拟化、服务器内部的虚拟接入、服务器与物理网络的连接、物理交换网络。</strong></p><p><img src="https://i.loli.net/2019/06/12/5d010b3af1e6193765.jpg"></p><p><strong>第一部分是服务器内部的IO虚拟化。</strong>多个虚拟机共享服务器中的物理网卡，需要一种机制既能保证I/O的效率，又要保证多个虚拟机对用物理网卡共享使用。I/O虚拟化的出现就是为了解决这类问题，详情可参见本站《计算虚拟化之I/O虚拟化》一文，这里不再赘述。</p><p><strong>第二部分是服务器内部的虚拟接入识别。</strong>用于识别不同虚拟机的网络包。在传统的服务器虚拟化方案中，从虚拟机的虚拟网卡发出的数据包在经过服务器的物理网卡传送到外部网络的上联交换机后，虚拟机的标识信息被屏蔽掉了，上联交换机只能感知从某个服务器的物理网卡流出的所有流量而无法感知服务器内某个虚拟机的流量，这样就不能从传统网络设备层面来保证QoS和安全隔离。虚拟接入要解决的问题是要把虚拟机的网络流量纳入传统网络交换设备的管理之中，需要对虚拟机的流量做标识。</p><p>在解决虚拟接入的问题时，思科和惠普分别提出了自己的解决方案。思科的是VN-Tag, 惠普的方案是VEPA(VirtualEthernet Port Aggregator)。为了制定下一代网络接入的话语权，思科和惠普这两个巨头在各自的方案上都毫不让步，纷纷将自己的方案提交为标准，分别为802.1Qbh和802.1Qbg。</p><p><strong>第三部分是服务器到网络的连接。</strong>网络连接技术一直都在追求更高的带宽中发展，比如Infiniband和10Gb以太网。在传统的企业级数据中心IT构架中，服务器到存储网络和互联网络的连接是异构和分开的。存储网络用光纤，互联网用以太网线（ISCSI虽然能够在IP层上跑SCSI，但是性能与光纤比还是差的很远）。数据中心连接技术的发展趋势是用一种连接线将数据中心存储网络和互联网络聚合起来，使服务器可以灵活的配置网络端口，简化IT部署。以太网上的<strong>FCOE</strong>技术和**Infiniband技术本身都使这种趋势成为可能。</p><p>Infiniband 技术产生于上个世纪末，是由Compaq、惠普、IBM、戴尔、英特尔、微软和Sun七家公司共同研究发展的高速先进的I/O标准。InfiniBand是一种长缆线的连接方式，具有高速、低延迟的传输特性。基于InfiniBand技术的网卡的单端口带宽可达20Gbps，为了发挥Infiniband设备的性能，需要一整套的软件栈来驱动和使用，这其中最著名的就是OFED（OpenFabrics Enterprise Distribution）,它基于Infiniband设备实现了RDMA（remote direct memoryaccess）。RDMA的最主要的特点就是零拷贝和旁路操作系统，数据直接在设备和应用程序内存之间传递，这种传递不需要CPU的干预和上下文切换。OFED还实现了一系列的其它软件栈：IPoIB（IP over Infiniband），SRP（SCSI RDMA Protocol）等，这就为Infiniband聚合存储网络和互联网络提供了基础。OFED由OpenFabrics联盟负责开发。</p><p>FCOE的出现则为数据中心互联网络和存储网络的聚合提供了另一种可能。FCOE是将光纤信道直接映射到以太网线上，这样光纤信道就成了以太网线上除了互联网网络协议之外的另一种网络协议。FCOE能够很容易的和传统光纤网络上运行的软件和管理工具相整合，因而能够代替光纤连接存储网络。虽然出现的晚，但FCOE发展极其迅猛。与Infiniband技术需要采用全新的链路相比，企业更愿意升级已有的以太网。在两者性能接近的情况下，采用FCOE方案似乎性价比更高。</p><p><strong>第四部分是网络交换。</strong>需要将物理网络和逻辑网络有效的分离，另外网络设备如交换机、路由器等需要具备1：N和N:1的虚拟化能力。在这一层面上要解决的问题则是要对现有的互联网络进行升级，使之满足新业务的需求，网络虚拟化则是这一变革的重要方向。在这一方向上目前有两种做法，一种是在原有的基础设施上添加新的协议来解决新的问题；另一种则完全推倒重来，希望设计出一种新的网络交换模型。</p><p>当虚拟数据中心开始普及后，虚拟数据中心本身的一些特性引入了对网络新的需求。物理机的位置一般是相对固定的，虚拟化方案的一个很大的特性在于虚拟机可以迁移。当虚拟机的迁移发生在不同网络，不同数据中心之间时，对网络产生了新的要求，比如需要保证虚拟机的IP在迁移前后不发生改变，需要保证虚拟机内运行在第二层（链路层）的应用程序也在迁移后仍可以跨越网络和数据中心进行通信等等。在这方面，Cisco连续推出了OTV，LISP和VXLAN等一系列解决方案，也就是隧道封装技术。</p><p><strong><em>以上就是云计算时代网络虚拟化的基本概述，不知你看明白没有，反正我是觉得我写明白了！！！</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;网络作为提供数据交换的模块，是数据中心内最为核心的基础设施之一，并直接关系到数据中心的能力、规模、可扩展性和管理性。为了满足日益增长的网络服务需求，特别是移动互联网业务的爆发式增长，数据中心逐渐向大型化、自动化、虚拟化、多租户的方向发展。传统网络设备不仅部署慢、调整难、成本高，而且其二层地址表项的规模直接决定了数据中心的规模。为此，网络虚拟化的概念应运而生。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-09-Linux原生的存储虚拟化软RAID和LVM</title>
    <link href="https://kkutysllb.cn/2019/06/09/2019-06-09-Linux%E5%8E%9F%E7%94%9F%E7%9A%84%E5%AD%98%E5%82%A8%E8%99%9A%E6%8B%9F%E5%8C%96%E8%BD%AFRAID%E5%92%8CLVM/"/>
    <id>https://kkutysllb.cn/2019/06/09/2019-06-09-Linux原生的存储虚拟化软RAID和LVM/</id>
    <published>2019-06-09T10:06:49.000Z</published>
    <updated>2019-06-09T10:39:12.805Z</updated>
    
    <content type="html"><![CDATA[<p>为了让大家更好理解存储虚拟化的特点，本文将讲解各个常用RAID技术方案的特性，并通过实际部署软RAID 10、RAID 5+备份盘等方案来更直观地体验RAID的效果，以便进一步了解生产环境对硬盘设备的IO读写速度和数据冗余备份机制的需求。同时，本文还将介绍LVM的部署、扩容、缩小、快照以及卸载删除的相关知识，以便让大家通过开源存储虚拟化基础对存储虚拟化的块级虚拟化和文件系统级虚拟化有个更深刻的理解。<a id="more"></a></p><h2 id="RAID-技术"><a href="#RAID-技术" class="headerlink" title="RAID 技术"></a>RAID 技术</h2><p>这里主要介绍开源RAID技术，至于华为的RAID2.0技术详见存储虚拟化其他文章。<strong>RAID技术通过把多个硬盘设备组合成一个容量更大、安全性更好的磁盘阵列，并把数据切割成多个区段后分别存放在各个不同的物理硬盘设备上，然后利用分散读写技术来提升磁盘阵列整体的性能，同时把多个重要数据的副本同步到不同的物理硬盘设备上，从而起到了非常好的数据冗余备份效果。</strong></p><p>RAID技术的设计初衷是减少因为采购硬盘设备带来的费用支出，但是与数据本身的价值相比较，现代企业更看重的则是RAID技术所具备的冗余备份机制以及带来的硬盘吞吐量的提升。RAID技术的几种状态如下图所示：</p><p><img src="https://i.loli.net/2019/06/09/5cfcdaae3092b89150.jpg"></p><p><strong>RAID组变为降级状态后，在重建的过程中，如果还有别的成员盘出现故障，故障的成员盘的个数超过了阵列的冗余磁盘的个数，整个RAID组将为变为失效状态，此时原RAID组中的数据将会无法读取。</strong></p><h3 id="RAID-0"><a href="#RAID-0" class="headerlink" title="RAID 0"></a>RAID 0</h3><p><strong>RAID 0技术把多块物理硬盘设备（至少两块）通过硬件或软件的方式串联在一起，组成一个大的卷组，并将数据依次写入到各个物理硬盘中。</strong>在最理想的状态下，<strong>硬盘设备的读写性能会提升数倍</strong>，但是若任意一块硬盘发生故障将导致整个系统的数据都受到破坏。也就说，<strong>RAID 0技术能有效提升硬盘数据的吞吐率，但不具备数据备份和错误修复能力。</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfcdad639e1883289.jpg"></p><p>如上图，RAID 0使用<strong>“分条”（stripe）技术</strong>把数据分布到各个磁盘上，RAID 0至少使用两个磁盘，<strong>并将数据分成从512字节到数兆字节（一般是512Byte的整数倍）的若干块</strong>，这些数据块可以并行写到不同的磁盘中。第1块数据被写到驱动器1中，第2块数据被写到驱动器2中，如此类推，当系统到达阵列中的最后一个磁盘时，就重新回到驱动器1的下一分条进行写操作，分割数据将I/O负载平均分配到所有的驱动器。</p><p><strong>RAID 0的数据写入是以分条形式将数据均匀分布到RAID 组的各个硬盘中。</strong>即一个分条的所有分块写满后，再开始在下一个分条上进行数据写入。如上图，现在有数据D0 ，D1 ，D2 ，D3 ，D4 ，D5需要在RAID 0中进行写入，首先将第一个数据D0写入第一块硬盘位于第一个分条的块，将第二个数据D1写入第二块硬盘位于第一个分条的块，至此，第一个分条的各个块写满了数据，当有数据D2需要写入时，就要对下一个分条进行写入，将数据D2写入第一块硬盘位于第二个分条的块中… 数据块D3，D4，D5的写入同理。<strong>写满一个分条的所有块再开始在下一个分条中进行写入。</strong></p><p><strong>RAID 0在收到数据读取指令后，就会在各个硬盘中进行搜索，看需要读取的数据块位于哪一个硬盘上，再依次对需要读取的数据进行读取。</strong>如上图，现在收到读取数据D0 ，D1 ，D2 ，D3 ，D4 ，D5的指令，首先从第一块磁盘读取数据块D0，再从第二块磁盘读取数据块D1…对各个数据块，从磁盘阵列读取后再由RAID控制器进行整合后传送给系统。至此，整个读取过程结束。</p><h3 id="RAID-1"><a href="#RAID-1" class="headerlink" title="RAID 1"></a>RAID 1</h3><p>RAID 1技术是把<strong>两块以上</strong>的硬盘进行绑定，在写入数据时，是将数据同时写入到多块硬盘设备上，其中某一块硬盘用作数据的备份或镜像。当其中某一块硬盘发生故障后，一般会自动切换的方式来恢复数据的正常使用。</p><p><img src="https://i.loli.net/2019/06/09/5cfcdb033aa6557058.jpg"></p><p><strong>如上图，RAID 1也被称为镜像，其目的是为了打造出一个安全性极高的RAID。</strong>RAID 1使用两组相同的磁盘系统互作镜像，速度没有提高，但是允许单个磁盘故障，数据可靠性最高。其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。</p><p><strong>RAID 1在进行数据写入的时候，并不是像RAID 0那样将数据分条写入所有磁盘，而是将数据分别写入成员盘，各个成员磁盘上的数据完全相同，互为镜像。</strong>如上图，需要将数据块D0，D1，D2写入RAID 1，先在两个磁盘上同时写入数据块D0，再在两个磁盘上同时写入数据块D1，以此类推。</p><p><strong>RAID 1在进行数据读取的时候，正常情况下可以实现数据盘和镜像盘同时读取数据，提高读取性能，如果一个磁盘损坏，则IO自动到存活的盘读取数据。</strong></p><p><strong>RAID 1的成员磁盘是互为镜像的，成员磁盘的内容完全相同，这样，任何一组磁盘中的数据出现问题，都可以马上从其它成员磁盘进行镜像恢复。</strong>比如：磁盘1损坏导致数据丢失，我们需要将故障磁盘用正常磁盘替换，再读取磁盘2的数据，将其复制到磁盘1上，从而实现了数据的恢复。</p><h3 id="RAID-3"><a href="#RAID-3" class="headerlink" title="RAID 3"></a>RAID 3</h3><p><strong>RAID 3是带有专用奇偶位的条带化阵列，是RAID 0的一种改进模式。它也采用了奇偶校验技术，不过没有使用海明码技术而采用较为简单的异或算法。</strong>在阵列中有一个驱动器专门用来保存其它驱动器中对应分条中数据的奇偶校验信息。奇偶位是编码信息，如果某个驱动器中的数据出错或者某一个驱动器故障，可以通过对奇偶校验信息的计算来恢复出故障驱动器中的数据信息。在数据密集型环境或者是单一用户环境中，组建RAID 3对访问较长的连续记录较好。在写入数据时，RAID 3会把数据的写入操作分散到多个磁盘上进行，然而不管是向哪一个数据盘写入数据，都需要同时重写校验盘中的相关信息。因此，对于那些经常需要执行大量写入操作的应用来说，校验盘的负载将会很大，无法满足程序的运行速度，从而导致整个RAID系统性能的下降。</p><p><img src="https://i.loli.net/2019/06/09/5cfcdb2c9c17861030.jpg"></p><p><strong>RAID 3是单盘容错并行传输。即采用Stripping技术将数据分块</strong>，对这些块进行异或校验，校验数据写到最后一个硬盘上。它的特点是有一个盘为校验盘，数据以位或字节的方式存于各盘（分散记录在组内相同扇区的各个硬盘上）。当一个硬盘发生故障，除故障盘外，写操作将继续对数据盘和校验盘进行操作。</p><p><strong>RAID3的数据读取是按照分条来进行的。</strong>将每个磁盘的驱动器主轴马达做精确的控制，同一分条上各个磁盘上的数据位同时读取，各个驱动器得到充分利用，读性能较高。 <strong>RAID 3的数据读写属于并行方式。</strong></p><p><strong>RAID 3的数据恢复是通过对剩余数据盘和校验盘的异或计算重构故障盘上应有的数据来进行的。</strong>如上图的RAID 3磁盘结构，当磁盘2故障，其上存储的数据位A1，B1，C1丢失，我们需要经过这样一个数据恢复过程：首先恢复数据A1，根据同一分条上其它数据盘和校验盘上的数据A0，A2，P1，进行异或运算，得到应有的数据A1，再用相同方法恢复出数据B1，C1的数据，至此，磁盘2上的数据全部得到了恢复。<strong>由于校验集中在一个盘，因此在数据恢复时，校验盘写压力比较大，影响性能。</strong></p><h3 id="RAID-5"><a href="#RAID-5" class="headerlink" title="RAID 5"></a>RAID 5</h3><p><strong>RAID5是一种旋转奇偶校验独立存取的阵列方式，它与RAID3不同的是没有固定的校验盘，</strong>而是按某种规则把奇偶校验信息均匀地分布在阵列所属的硬盘上，所以在每块硬盘上，既有数据信息也有校验信息。这一改变解决了争用校验盘的问题，能并发进行多个写操作。所以RAID 5即适用于大数据量的操作，也适用于各种事务处理，它是一种快速、大容量和容错分布合理的磁盘阵列。当有N块阵列盘时，可用容量为N-1块盘容量。 <strong>RAID 3、RAID 5中，在一块硬盘发生故障后，RAID组从ONLINE变为DEGRADED方式，直到故障盘恢复。但如果在DEGRADED状态下，又有第二块盘故障，整个RAID组的数据将丢失。</strong> </p><p><img src="https://i.loli.net/2019/06/09/5cfcdb527467110620.jpg"></p><p><strong>RAID 5的数据写入也是按分条进行的，各个磁盘上既存储数据块，又存储校验信息。</strong>一个分条上的数据块写入完成后，将产生的校验信息写入对应的校验磁盘中。<strong>由于RAID 5的数据是按照数据分条存储的，在读取的时候，按照分条进行读取。</strong></p><p>当RAID5中某一个磁盘故障，在恢复的时候，可利用其它存活成员盘数据进行异或逆运算，恢复故障盘上的数据。</p><h3 id="RAID-6"><a href="#RAID-6" class="headerlink" title="RAID 6"></a>RAID 6</h3><p><strong>RAID 6是带有两种校验的独立磁盘结构，采用两种奇偶校验方法，需要至少N+2(N&gt;2)个磁盘来构成阵列</strong>，一般用在数据可靠性、可用性要求极高的应用场合 。常用的RAID 6技术有<strong>RAID6 P＋Q</strong>和<strong>RAID6 DP。</strong></p><p>RAID 6实际上是在RAID 5基础上为了进一步保证数据可用性和可靠性设计的一种RAID方式。与<strong>RAID 5相比除了有通常的异或校验方式外，还增加了另一种特殊的异或校验方式和该方式校验数据存放区域</strong>，因此RAID 6的数据冗余性能相当好。但是，由于增加了一个校验，所以写入的效率比RAID 5要低，而且控制系统的设计也更为复杂，第二个校验区也减少了有效存储空间。</p><p>目前RAID 6还没有统一的标准，各家公司的实现方式都有所不同，主要有以下两种方式：</p><ul><li><strong>RAID P+Q： 华为、HDS</strong></li><li><strong>RAID DP： NetApp</strong></li></ul><p><strong>两种技术获取校验信息的方法不同，但是都能够在两块成员盘故障的情况下读取数据，数据不丢失。</strong></p><p><strong>1）RAID6 P＋Q的工作原理</strong></p><p>RAID6 P＋Q需要计算出两个校验数据P和Q，当有两个数据丢失时，根据P和Q恢复出丢失的数据。校验数据P和Q是由以下公式计算得来的：</p><p>​     <strong>P=D0⊕ D1 ⊕ D2 ……</strong>      </p><p>​     <strong>Q=(α⊗D0)⊕(β⊗D1)⊕(γ⊗D2)……</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfcdb8e3f83772882.jpg"></p><p>在RAID6 P＋Q中，<strong>P和Q是两个相互独立的校验值，它们的计算互不影响，都是由同一分条上其它数据磁盘上的数据依据不同的算法计算而来的。</strong></p><p><strong>其中，P值的获得是通过同一分条上除P和Q之外的其它所有数据盘上数据的简单异或运算得到。Q值的获得过程就相对复杂一些，它首先对同一分条其他磁盘上的各个数据分别进行一个变换，然后再将这些变换结果进行异或操作而得到校验盘上的数据。</strong>这个变换被称为<strong>GF变换</strong>，它是一种常用的数学变换方法，可以通过查GF变换表而得到相应的变换系数，再将各个磁盘上的数据与变换系数进行运算就得到了GF变换后的数据，这个变换过程是由RAID控制器来完成的。</p><p>以上图为例，P1是由分条0中的数据D0、D1、D2进行简单的异或运算而得到的。同理，P2是由分条1中的数据D3、D4、D5进行简单的异或运算而得到， P3是由分条2中的数据D6、D7、D8进行简单的异或运算而得到。Q1是由分条0中的数据D0、D1、D2分别进行GF变换之后再进行异或运算而得到的。同理，Q2是由分条1中的数据D3、D4、D5分别进行GF变换之后再进行异或运算而得到， Q3是由分条2中的数据D6、D7、D8分别进行GF变换之后再进行异或运算而得到。</p><p>当某一个分条中有一块磁盘发生故障，根本不需要Q，直接用校验值P与其他正常数据进行异或运算就可以恢复出故障盘上面的数据，数据恢复比较方便。当分条中有两块磁盘发生故障，如果其中包含Q所在的磁盘，则可以先恢复出数据盘上面的数据，再恢复出校验盘Q上的校验值；如果故障盘不包含Q所在的盘，则可以将两个校验公式作为方程组，从而可以恢复出两个故障盘上面的数据。</p><p><strong>2）RAID6 DP的工作原理</strong></p><p>DP就是Double Parity，就是在RAID4所使用的一个行XOR校验磁盘的基础上又增加了一个磁盘用于存放斜向的XOR校验信息。</p><p><img src="https://i.loli.net/2019/06/09/5cfcdbac4614d91015.jpg"></p><p>横向校验盘中P0—P3为各个数据盘中横向数据的校验信息。比如：P0=D0  XOR D1 XOR D2 XOR D3。斜向校验盘中DP0—DP3为各个数据盘及横向校验盘的斜向数据校验信息。比如：DP0=D0 XOR D5 XOR D10 XOR D15</p><p><strong>RAID6 DP 同样也有两个相互独立的校验信息块，但是与RAID6 P＋Q 不同的是，它的第二块校验信息是斜向的。横向校验信息和斜向校验信息都使用异或校验算法而得到，</strong>横向校验盘中的信息的获得方法非常简单：P0是由条带0中的数据D0、D1、D2、 D3进行简单的异或运算而得到的。同理， P1是由分条1中的数据D4、D5、D6、D7进行简单的异或运算而得到。</p><p>斜向校验盘中校验信息的获得依然是采用数据之间的异或运算，只是数据块的选取相对复杂一些，是一个斜向的选取过程：由分条0上面第一个磁盘上的数据D0、分条1上面第二个磁盘上的数据D5、分条2上面第三个磁盘上的数据D10、分条3上面第四个磁盘上的数据D15经过异或校验而得到校验信息DP0；由分条0上面第二个磁盘上的数据D1、分条1上面第三个磁盘上的数据D6、分条2上面第四个磁盘上的数据D11、分条3上面校验盘上面的信息P3经过异或校验而得到校验信息DP1；由分条0上面第三个磁盘上的数据D2、分条1上面第四个磁盘上的数据D7、分条2上面校验盘上面的信息P2、分条3上面第一个磁盘上的数据D12经过异或校验而得到校验信息DP2。</p><p><strong>RAID6 DP允许阵列中同时有两个磁盘失效</strong>，我们以上图为例，假设磁盘1、2故障，则数据D0、D1、D4、D5、D8、D9、D12、D13失效，其他磁盘数据和校验信息正常。我们来看一下数据恢复是怎样一个过程：首先根据DP2和斜向校验恢复出D12， D12 =D2 ⊕ D7 ⊕ P2 ⊕DP2，然后利用P3和横向校验恢复出D13， D13 =D12 ⊕ D14 ⊕ D15 ⊕P3 ；根据DP3斜向校验恢复出D8， D8 =D3 ⊕ P1 ⊕DP3 ⊕ D13，利用P2和横向校验恢复出D9， D9 =D8 ⊕ D10 ⊕ D11 ⊕ P2；根据DP4和斜向校验恢复出D4，利用P1和横向校验恢复出D5，以此类推进而恢复出磁盘1、2上的所有数据。</p><h3 id="RAID-10"><a href="#RAID-10" class="headerlink" title="RAID 10"></a>RAID 10</h3><p>RAID 10是将镜像和条带进行组合的RAID级别，先进行RAID 1镜像然后再做RAID  0。RAID 10也是一种应用比较广泛的RAID级别。</p><p><img src="https://i.loli.net/2019/06/09/5cfcdbd591c9b84222.jpg"></p><p>RAID 10集RAID 0和RAID 1的优点于一身，适合应用在速度和容错要求都比较高的场合。先进行镜像，再进行分条。物理磁盘1和物理磁盘2组成RAID 1，物理磁盘3和物理磁盘4组成RAID 1，两个RAID 1再进行RAID 0。 </p><p>当不同RAID1中的磁盘，如物理磁盘2和物理磁盘4发生故障导致数据失效时，整个阵列的数据读取不会受到影响，因为物理磁盘1和物理磁盘3上面已经保存了一份完整的数据。但是如果组成RAID 1的磁盘（如物理磁盘1和物理磁盘2）同时故障，数据将不能正常读取。</p><h3 id="RAID-50"><a href="#RAID-50" class="headerlink" title="RAID 50"></a>RAID 50</h3><p>RAID 50是将RAID 5和RAID 0进行两级组合的RAID级别，第一级是 RAID 5，第二级为RAID 0。</p><p><img src="https://i.loli.net/2019/06/09/5cfcdbfae058d26478.jpg"></p><p>RAID 50是RAID 5和RAID 0的结合，先将3个或3个以上磁盘实现RAID 5，再把若干个RAID 5进行RAID 0分条。 RAID 50需要至少6个磁盘构成，把数据分条后分放到各个RAID 5中，在RAID 5中再进行分条和计算校验值及校验值的分布式存储。</p><p>如上图，物理磁盘1、2、3实现RAID 5，物理磁盘4、5、6实现RAID 5，再将两个RAID 5放在一起进行分条。允许不同RAID 5中的多块磁盘同时失效，但是一旦同一RAID 5中的两块磁盘故障，将会导致阵列失效。</p><h3 id="常用RAID级别的比较和应用场景"><a href="#常用RAID级别的比较和应用场景" class="headerlink" title="常用RAID级别的比较和应用场景"></a>常用RAID级别的比较和应用场景</h3><p><img src="https://i.loli.net/2019/06/09/5cfcdc2bd733957285.jpg"></p><p><strong>RAID组成员盘个数不建议过多，例如超过20块成员盘的RAID,不但性能比8-9块成员盘RAID组(建议RAID5成员盘个数)低，且在运行过程中RAID组失效的概率增加。</strong></p><table><thead><tr><th><strong>RAID级别</strong></th><th><strong>RAID 0</strong></th><th><strong>RAID 1</strong></th><th><strong>RAID 3</strong></th><th><strong>RAID 5 /6</strong></th><th><strong>RAID 10</strong></th></tr></thead><tbody><tr><td>典型应用环境</td><td>迅速读写，安全性要求不高，如图形工作站等</td><td>随机数据写入，安全性要求高，如服务器、数据库存储领域</td><td>连续数据传输，安全性要求高，如视频编辑、大型数据库等</td><td>随机数据传输，安全性要求高，如金融、数据库、存储等</td><td>数据量大，安全性要求高，如银行、金融等领域</td></tr></tbody></table><h3 id="虚拟机中的RAID实操"><a href="#虚拟机中的RAID实操" class="headerlink" title="虚拟机中的RAID实操"></a>虚拟机中的RAID实操</h3><p><strong>由于我们在虚拟机中搭建实验环境，所以采用Linux的软RAID来搭建，与实际生产环境硬件RAID卡相比，除了性能上不达标，一些关键特性不具备外，在数据写入、读取和恢复方面的机制类似，便于大家理解RAID的工作特性。</strong></p><p>首先我们给虚拟机挂载4块数据盘，用于组建RAID 10，如下图所示：</p><p><img src="https://i.loli.net/2019/06/09/5cfcdc63ca58f65011.jpg"></p><p><strong>mdadm命令用于管理Linux系统中的软件RAID硬盘阵列</strong>，格式为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mdadm [模式]  [选项] [成员设备名称]</span><br></pre></td></tr></table></figure><p>mdadm命令在Linux系统 中创建和管理软件RAID磁盘阵列，它涉及的理论知识的操作过程与生产环境中的完全一致。mdadm常用命令选项如下：</p><p><strong>1）创建模式命令选项和专用选项</strong></p><ul><li>-C 创建RAID</li><li>-l 指定级别</li><li>-n 指定设备个数</li><li>-v 显示创建过程</li><li>-a {yes|no} 自动为其创建设备文件</li><li>-c 指定数据块大小（chunk）</li><li>-x 指定空闲盘（热备磁盘）个数，空闲盘（热备磁盘）能在工作盘损坏后自动顶替</li></ul><p><strong>注意：创建阵列时，阵列所需磁盘数为-n参数和-x参数的个数和</strong></p><p>下面开始创建RAID过程：</p><p><strong>Step1：在系统中，通过mdadm创建一个软RAID 10，命名为/dev/md10，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mdadm -Cv /dev/md10 -a yes -n 4 -l 10 /dev/sdb /dev/sdc /dev/sde /dev/sdd</span></span><br><span class="line">mdadm: layout defaults to n2</span><br><span class="line">mdadm: layout defaults to n2</span><br><span class="line">mdadm: chunk size defaults to 512K</span><br><span class="line">mdadm: size <span class="built_in">set</span> to 20954112K</span><br><span class="line">mdadm: Defaulting to version 1.2 metadata</span><br><span class="line">mdadm: array /dev/md10 started.</span><br><span class="line">[root@c7-test01 ~]<span class="comment"># fdisk -l | grep "/dev/md10"</span></span><br><span class="line">Disk /dev/md10: 42.9 GB, 42914021376 bytes, 83816448 sectors</span><br></pre></td></tr></table></figure><p>通过上面的校验我们发现RAID 10创建成功，且大小为42.9G，符合预期。</p><p><strong>Step2：将创建好的md10格式化为ext4文件系统</strong>，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mkfs.ext4 /dev/md10</span></span><br><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS <span class="built_in">type</span>: Linux</span><br><span class="line">Block size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Fragment size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Stride=128 blocks, Stripe width=256 blocks</span><br><span class="line">2621440 inodes, 10477056 blocks</span><br><span class="line">523852 blocks (5.00%) reserved <span class="keyword">for</span> the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=2157969408</span><br><span class="line">320 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">4096000, 7962624</span><br><span class="line">Allocating group tables: <span class="keyword">done</span>                            </span><br><span class="line">Writing inode tables: <span class="keyword">done</span>                            </span><br><span class="line">Creating journal (32768 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p><strong>Step3：创建挂载点，把md10设备进行挂载，挂载后就可以发现md10可用空间为40G，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mkdir /home/data</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mount /dev/md10 /home/data</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        41G  2.4G   37G   7% /</span><br><span class="line">devtmpfs        2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs           2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs           2.0G   12M  2.0G   1% /run</span><br><span class="line">tmpfs           2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       380M  102M  254M  29% /boot</span><br><span class="line">tmpfs           394M     0  394M   0% /run/user/0</span><br><span class="line">/dev/md10        40G   49M   38G   1% /home/data</span><br></pre></td></tr></table></figure><p><strong>Step4：查看/dev/md10磁盘阵列的详细信息，并把挂载信息写入到配置文件中，使其开机即挂载永久生效。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mdadm -D /dev/md10</span></span><br><span class="line">/dev/md10:</span><br><span class="line">           Version : 1.2</span><br><span class="line">     Creation Time : Sun Jun  9 12:52:22 2019</span><br><span class="line">        Raid Level : raid10</span><br><span class="line">        Array Size : 41908224 (39.97 GiB 42.91 GB)</span><br><span class="line">     Used Dev Size : 20954112 (19.98 GiB 21.46 GB)</span><br><span class="line">      Raid Devices : 4</span><br><span class="line">     Total Devices : 4</span><br><span class="line">       Persistence : Superblock is persistent</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">   Update Time : Sun Jun  9 12:59:55 2019</span><br><span class="line">         State : clean </span><br><span class="line">Active Devices : 4</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">   Working Devices : 4</span><br><span class="line">    Failed Devices : 0</span><br><span class="line">     Spare Devices : 0</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">        Layout : near=2</span><br><span class="line">    Chunk Size : 512K</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">Consistency Policy : resync</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">          Name : c7-test01:10  (<span class="built_in">local</span> to host c7-test01)</span><br><span class="line">          UUID : 7f68ffce:e80f0c04:6c58f40c:526c5508</span><br><span class="line">        Events : 17</span><br><span class="line"></span><br><span class="line">Number   Major   Minor   RaidDevice State</span><br><span class="line">   0       8       16        0      active sync <span class="built_in">set</span>-A   /dev/sdb</span><br><span class="line">   1       8       32        1      active sync <span class="built_in">set</span>-B   /dev/sdc</span><br><span class="line">   2       8       64        2      active sync <span class="built_in">set</span>-A   /dev/sde</span><br><span class="line">   3       8       48        3      active sync <span class="built_in">set</span>-B   /dev/sdd</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># echo "/dev/md10 /home/data ext4 defaults 0 0" &gt;&gt; /etc/fstab</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># cat /etc/fstab </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /etc/fstab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Created by anaconda on Sat Jun  1 20:49:28 2019</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Accessible filesystems, by reference, are maintained under '/dev/disk'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">UUID=f078e329-6693-4fdd-89ad-0d5734b5e35f /                       ext4    defaults        1 1</span><br><span class="line">UUID=13919904-2c90-429c-b5ea-56f823a6e87c /boot                   ext4    defaults        1 2</span><br><span class="line">UUID=d3b139fc-7730-4bee-886b-1d4e0d681bae swap                    swap    defaults        0 0</span><br><span class="line">/dev/md10 /home/data ext4 defaults 0 0</span><br></pre></td></tr></table></figure><p><strong>2）管理模式</strong></p><ul><li>-a(–add)：添加磁盘</li><li>-d(–del)：删除磁盘</li><li>-r(–remove)：从RAID中移除损坏的成员盘</li><li>-f(–fail)：模拟成员盘故障</li><li>-S：停止阵列工作</li></ul><p><strong>注意：新增加的硬盘需要与原硬盘大小一致，且如果原有阵列缺少工作磁盘（如raid1只有一块在工作，raid5只有2块在工作），这时新增加的磁盘直接变为工作磁盘，如果原有阵列工作正常，则新增加的磁盘为热备磁盘。</strong></p><p><strong>Step1：模拟成员盘/dev/sdb故障，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mdadm /dev/md10 -f /dev/sdb</span></span><br><span class="line">mdadm: <span class="built_in">set</span> /dev/sdb faulty <span class="keyword">in</span> /dev/md10</span><br></pre></td></tr></table></figure><p><strong>Step2：查看RAID状态，此时md10仍正常工作，但出于降级状态，符合预期。</strong>如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfcdd3b93e4e31750.jpg"></p><p>在RAID 10级别的磁盘阵列中，当RAID 1磁盘阵列中存在一个故障盘时并不影响RAID 10磁盘阵列的使用，但是磁盘阵列此时出于降级使用状态。当购买了新的硬盘设备后再使用mdadm命令来予以替换即可，在此期间我们可以在/home/data目录中正常地创建或删除文件。由于我们是在虚拟机中模拟硬盘，所以先重启系统，然后再把新的硬盘添加到RAID磁盘阵列中。这个过程不是我们讨论的重点，现在/dev/sdb成员盘故障，使得md10处于降级使用状态，如果/dev/sdd故障呢？/dev/sdc故障呢？这两点才是我们要重点讨论的地方。</p><p><strong>Step3：再次模拟成员/dev/sdd故障，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mdadm /dev/md10 -f /dev/sdd</span></span><br><span class="line">mdadm: <span class="built_in">set</span> /dev/sdd faulty <span class="keyword">in</span> /dev/md10</span><br></pre></td></tr></table></figure><p><strong>Step4：再次查看RAID的状态，</strong>如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfcdd99db98b69860.jpg"></p><p>此时阵列中虽然坏了两块成员盘/dev/sdb和/dev/sdd，因为这两块成员盘同属于不同的RAID 1，所以阵列状态仍为降级状态，也就是表示还可以使用。接下来，我们模拟同一个RAID1中两块成员盘故障，看看阵列状态是否能达到我们预期的失效态。在模拟之前，需要先恢复一块成员盘，比如：/dev/sdd。<strong>注意：需要重启系统后才能恢复。恢复磁盘后，需要等待一段时间，此时刚恢复的磁盘正在恢复数据，如下：</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfcddb71503b81495.jpg"></p><p><strong>Step5：模拟同一个RAID 1下两块成员盘同时故障，</strong>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]# mdadm /dev/md10 -f /dev/sdb /dev/sdc</span><br><span class="line">mdadm: set /dev/sdb faulty in /dev/md10</span><br><span class="line">mdadm: set /dev/sdc faulty in /dev/md10</span><br></pre></td></tr></table></figure><p><strong>Step6：再次查看阵列状态，此时软RAID 10虽然显示状态为降级使用，但是只有SET-A组，也就是说SET-B组的数据已丢失。</strong>如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfcddf37dc5749392.jpg"></p><p><strong><em>RAID 5 的创建方法与此类似，不过RAID 5至少需要3块硬盘，同时，为了保证数据的可靠性，可以再增加一块热备盘。当成员盘故障时，数据盘可以立即顶上去并做数据同步和恢复操作。</em></strong></p><p><strong>Step1：创建RAID 5阵列/dev/md5，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mdadm -Cv /dev/md5 -a yes -n 3 -l 5 -x 1 /dev/sdf /dev/sdg /dev/sdh /dev/sdi</span></span><br><span class="line">mdadm: layout defaults to left-symmetric</span><br><span class="line">mdadm: layout defaults to left-symmetric</span><br><span class="line">mdadm: chunk size defaults to 512K</span><br><span class="line">mdadm: size <span class="built_in">set</span> to 20954112K</span><br><span class="line">mdadm: Defaulting to version 1.2 metadata</span><br><span class="line">mdadm: array /dev/md5 started.</span><br></pre></td></tr></table></figure><p><strong>Step2：格式化md5，并创建挂载目录，并挂载磁盘</strong>，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mkfs.ext /dev/md5</span></span><br><span class="line">-bash: mkfs.ext: <span class="built_in">command</span> not found</span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mkfs.ext4 /dev/md5</span></span><br><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS <span class="built_in">type</span>: Linux</span><br><span class="line">Block size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Fragment size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Stride=128 blocks, Stripe width=256 blocks</span><br><span class="line">2621440 inodes, 10477056 blocks</span><br><span class="line">523852 blocks (5.00%) reserved <span class="keyword">for</span> the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=2157969408</span><br><span class="line">320 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">4096000, 7962624</span><br><span class="line"></span><br><span class="line">Allocating group tables: <span class="keyword">done</span>                            </span><br><span class="line">Writing inode tables: <span class="keyword">done</span>                            </span><br><span class="line">Creating journal (32768 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span>   </span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mkdir /home/code</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mount /dev/md5 /home/code</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        41G  2.4G   37G   7% /</span><br><span class="line">devtmpfs        2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs           2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs           2.0G   12M  2.0G   1% /run</span><br><span class="line">tmpfs           2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       380M  102M  254M  29% /boot</span><br><span class="line">/dev/md10        40G   49M   38G   1% /home/data</span><br><span class="line">tmpfs           394M     0  394M   0% /run/user/0</span><br><span class="line">/dev/md5         40G   49M   38G   1% /home/code</span><br></pre></td></tr></table></figure><p><strong>Step3：查看阵列md5的状态，</strong>如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfcde4c1c21492447.jpg"></p><p><strong>Step4：我们再次将成员盘/dev/sdf模拟故障，然后可以看见热备盘/dev/sdi自动顶上故障盘位置并开始同步恢复数据。</strong>如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfcde683820748137.jpg"></p><h2 id="LVM逻辑卷管理"><a href="#LVM逻辑卷管理" class="headerlink" title="LVM逻辑卷管理"></a>LVM逻辑卷管理</h2><h3 id="LVM逻辑卷管理的原理浅析"><a href="#LVM逻辑卷管理的原理浅析" class="headerlink" title="LVM逻辑卷管理的原理浅析"></a>LVM逻辑卷管理的原理浅析</h3><p>LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。</p><p><strong>LVM的工作原理其实很简单，它就是通过将底层的物理硬盘抽象的封装起来，然后以逻辑卷的方式呈现给上层应用。</strong>在传统的磁盘管理机制中，我们的上层应用是直接访问文件系统，从而对底层的物理硬盘进行读取，而在LVM中，其通过对底层的硬盘进行封装，当我们对底层的物理硬盘进行操作时，其不再是针对于分区进行操作，而是通过一个叫做逻辑卷的东西来对其进行底层的磁盘管理操作。比如说我增加一个物理硬盘，这个时候上层的服务是感觉不到的，因为呈现给上层服务的是以逻辑卷的方式。</p><p><strong>LVM最大的特点就是可以对磁盘进行动态管理。因为逻辑卷的大小是可以动态调整的，而且不会丢失现有的数据。</strong>如果我们新增加了硬盘，其也不会改变现有上层的逻辑卷。作为一个动态磁盘管理机制，逻辑卷技术大大提高了磁盘管理的灵活性。<strong>LVM的最大缺点就是影响磁盘I/O效率。</strong></p><p>在一个硬盘上创建多个逻辑卷，对创建好的卷调整大小，然后将它们挂载在’/home,/var,/tmp’等目录下，如下所示：</p><p><img src="https://i.loli.net/2019/06/09/5cfcde8ba6e8e38978.jpg"></p><blockquote><p><strong>PV（Physical Volume）- 物理卷：</strong>物理卷在逻辑卷管理中处于最底层，它可以是实际物理硬盘上的分区，也可以是整个物理硬盘，也可以是raid设备，是LVM的基本存储逻辑块，但和基本的物理存储介质(如分区、磁盘等)比较，却包含有与LVM相关的管理参数。</p><p><strong>VG（Volumne Group）- 卷组：</strong>卷组建立在物理卷之上，一个卷组中至少要包括一个物理卷，在卷组建立之后可动态添加物理卷到卷组中。一个逻辑卷管理系统工程中可以只有一个卷组，也可以拥有多个卷组。</p><p><strong>PE（physical extent）：</strong>每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是在VG过程中配置的，默认为4MB。</p><p>LVM 默认使用4MB的PE区块，而LVM的LV最多仅能含有65534个PE (lvm1 的格式)，因此默认的LVM的LV最大容量为4M*65534/(1024M/G)=256G。PE是整个LVM 最小的储存区块，也就是说，其实我们的资料都是由写入PE 来处理的。简单的说，这个PE 就有点像文件系统里面的block 角色。所以调整PE 会影响到LVM 的最大容量！不过，在 CentOS 6.x 以后，由于直接使用 lvm2 的各项格式功能，因此这个限制已经不存在了。</p><p><strong>LV（Logical Volume）- 逻辑卷</strong>：逻辑卷建立在卷组之上，卷组中的未分配空间可以用于建立新的逻辑卷，逻辑卷建立后可以动态地扩展和缩小空间。系统中的多个逻辑卷可以属于同一个卷组，也可以属于不同的多个卷组。</p></blockquote><p><strong><em>简单来说就是：PV是物理的存储设备（整块磁盘或磁盘分区），VG是一个存放PV的仓库，将仓库中所有PV重新编号，也就是PE。LV就是用重新编号的PE组成的逻辑磁盘。</em></strong></p><p><strong>LVM 主要有三类命令行工具：</strong></p><ul><li><strong>pv 开头的命令用来操作 PV 物理卷</strong></li><li><strong>vg 开头的命令用来操作 VG 逻辑卷组</strong></li><li><strong>lv 开头的命令用来操作 LV 逻辑卷</strong></li></ul><table><thead><tr><th>功能/命令</th><th>物理卷管理</th><th>卷组管理</th><th>逻辑卷管理</th></tr></thead><tbody><tr><td>扫描</td><td>pvscan</td><td>vgscan</td><td>lvscan</td></tr><tr><td>建立</td><td>pvcreate</td><td>vgcreate</td><td>lvcreate</td></tr><tr><td>显示</td><td>pvdisplay</td><td>vgdisplay</td><td>lvdisplay</td></tr><tr><td>删除</td><td>pvremove</td><td>vgremove</td><td>lvremove</td></tr><tr><td>扩展</td><td></td><td>vgextend</td><td>lvextend</td></tr><tr><td>缩小</td><td></td><td>vgreduce</td><td>lvreduce</td></tr></tbody></table><h3 id="LVM逻辑卷管理实操"><a href="#LVM逻辑卷管理实操" class="headerlink" title="LVM逻辑卷管理实操"></a>LVM逻辑卷管理实操</h3><p><strong>1）安装逻辑卷管理软件，创建物理卷，并添加卷组</strong></p><p><strong>Step1：我们首先添加两块磁盘/dev/sdb和/dev/sdc，</strong>用来作为逻辑实验的环境，方法同RAID实验添加磁盘。</p><p><img src="https://i.loli.net/2019/06/09/5cfcded42d81c26718.jpg"></p><p><strong>Step2：:安装lvm逻辑卷管理软件，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># yum install -y lvm2</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfcdf114a77617673.jpg"></p><p><strong>Step3：对添加的两块磁盘（整盘）创建物理卷</strong>，这样这两块就可以被LVM进行管理，并有相关LVM管理参数。代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># pvcreate /dev/sdb /dev/sdc</span></span><br><span class="line">Physical volume <span class="string">"/dev/sdb"</span> successfully created.</span><br><span class="line">Physical volume <span class="string">"/dev/sdc"</span> successfully created.</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfcdf41673aa85499.jpg"></p><p><strong>Step4：创建卷组datastorage ，并将两块物理盘加入到新创建的卷组中</strong>，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># vgcreate datastorage /dev/sdb /dev/sdc</span></span><br><span class="line">Volume group <span class="string">"datastorage"</span> successfully created</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfcdf6d9e48941077.jpg"></p><p><strong>2）逻辑卷管理实操</strong></p><p><strong>Step1：创建出一个150MB的逻辑卷设备lv_data01，</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># lvcreate -n lv_data01 -L 150M datastorage </span></span><br><span class="line">Rounding up size to full physical extent 152.00 MiB</span><br><span class="line">Logical volume <span class="string">"lv_data01"</span> created.</span><br></pre></td></tr></table></figure><p><strong>注意：这里切割单位的问题。在对逻辑卷进行切割时有两种计量单位。第一种是以容量为单位，所使用的参数为-L。例如，使用-L 150M生成一个大小为150MB的逻辑卷。另外一种是以基本单元的个数为单位，所使用的参数为-l。每个基本单元的大小默认为4MB。例如，使用-l 37可以生成一个大小为37×4MB=148MB的逻辑卷。我们采用的第一种切割办法。</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfcdfa428bd573707.jpg"></p><p><strong>Step2：把创建的逻辑卷格式化为ext4文件系统格式，然后挂载到/home/data01下使用。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># mkfs.ext4 /dev/datastorage/lv_data01 </span></span><br><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS <span class="built_in">type</span>: Linux</span><br><span class="line">Block size=1024 (<span class="built_in">log</span>=0)</span><br><span class="line">Fragment size=1024 (<span class="built_in">log</span>=0)</span><br><span class="line">Stride=0 blocks, Stripe width=0 blocks</span><br><span class="line">38912 inodes, 155648 blocks</span><br><span class="line">7782 blocks (5.00%) reserved <span class="keyword">for</span> the super user</span><br><span class="line">First data block=1</span><br><span class="line">Maximum filesystem blocks=33816576</span><br><span class="line">19 block groups</span><br><span class="line">8192 blocks per group, 8192 fragments per group</span><br><span class="line">2048 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">8193, 24577, 40961, 57345, 73729</span><br><span class="line">Allocating group tables: <span class="keyword">done</span>                            </span><br><span class="line">Writing inode tables: <span class="keyword">done</span>                            </span><br><span class="line">Creating journal (4096 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span> </span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mkdir /home/data01 &amp;&amp; mount /dev/datastorage/lv_data01 /home/data01</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfcdfd71812b75693.jpg"></p><p><strong>Linux系统会把LVM中的逻辑卷设备存放在/dev设备目录中（实际上是做了一个符号链接），同时会以卷组的名称来建立一个目录，其中保存了逻辑卷的设备映射文件（即/dev/卷组名称/逻辑卷名称）。设置开机自动挂载的方式，同上面RAID实操，这里不再赘述。</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfcdff11e04972825.jpg"></p><p><strong>Step3：扩容逻辑卷lv_data01，在扩容前需要先卸载挂载点，否则数据会丢失。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卸载挂载点</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># umount /home/data01/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩容到290MB</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># lvextend -L 290M /dev/datastorage/lv_data01 </span></span><br><span class="line">  Rounding size to boundary between physical extents: 292.00 MiB.</span><br><span class="line">  Size of logical volume datastorage/lv_data01 changed from 152.00 MiB (38 extents) to 292.00 MiB (73 extents).</span><br><span class="line">  Logical volume datastorage/lv_data01 successfully resized.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查磁盘完整性，并重置磁盘容量</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># e2fsck -f /dev/datastorage/lv_data01 </span></span><br><span class="line">e2fsck 1.42.9 (28-Dec-2013)</span><br><span class="line">Pass 1: Checking inodes, blocks, and sizes</span><br><span class="line">Pass 2: Checking directory structure</span><br><span class="line">Pass 3: Checking directory connectivity</span><br><span class="line">Pass 4: Checking reference counts</span><br><span class="line">Pass 5: Checking group summary information</span><br><span class="line">/dev/datastorage/lv_data01: 11/38912 files (0.0% non-contiguous), 10567/155648 blocks</span><br><span class="line">[root@c7-test01 ~]<span class="comment"># resize2fs /dev/datastorage/lv_data01 </span></span><br><span class="line">resize2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Resizing the filesystem on /dev/datastorage/lv_data01 to 299008 (1k) blocks.</span><br><span class="line">The filesystem on /dev/datastorage/lv_data01 is now 299008 blocks long.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新挂载磁盘，并查看状态</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mount /dev/datastorage/lv_data01 /home/data01</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfce0329b51717664.jpg"></p><p><strong>在前面我们的卷组是由两块硬盘设备共同组成的。用户在使用存储设备时感知不到设备底层的架构和布局，更不用关心底层是由多少块硬盘组成的，只要卷组中有足够的资源，就可以一直为逻辑卷扩容。</strong></p><p><strong>Step4：缩容逻辑卷lv_data01，在执行缩容操作前记得先把挂载点卸载掉，同时要先检查磁盘文件系统的完整性。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消挂载点，并检查文件系统完整性</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># umount /home/data01/ &amp;&amp; e2fsck -f /dev/datastorage/lv_data01 </span></span><br><span class="line">e2fsck 1.42.9 (28-Dec-2013)</span><br><span class="line">Pass 1: Checking inodes, blocks, and sizes</span><br><span class="line">Pass 2: Checking directory structure</span><br><span class="line">Pass 3: Checking directory connectivity</span><br><span class="line">Pass 4: Checking reference counts</span><br><span class="line">Pass 5: Checking group summary information</span><br><span class="line">/dev/datastorage/lv_data01: 11/75776 files (0.0% non-contiguous), 15729/299008 blocks</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把逻辑卷缩小到120M</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># resize2fs /dev/datastorage/lv_data01 120M</span></span><br><span class="line">resize2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Resizing the filesystem on /dev/datastorage/lv_data01 to 122880 (1k) blocks.</span><br><span class="line">The filesystem on /dev/datastorage/lv_data01 is now 122880 blocks long.</span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># lvreduce -L 120M /dev/datastorage/lv_data01 </span></span><br><span class="line">  WARNING: Reducing active logical volume to 120.00 MiB.</span><br><span class="line">  THIS MAY DESTROY YOUR DATA (filesystem etc.)</span><br><span class="line">Do you really want to reduce datastorage/lv_data01? [y/n]: y</span><br><span class="line">  Size of logical volume datastorage/lv_data01 changed from 292.00 MiB (73 extents) to 120.00 MiB (30 extents).</span><br><span class="line">  Logical volume datastorage/lv_data01 successfully resized.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新挂载，并查看挂载状态</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># mount /dev/datastorage/lv_data01 /home/data01/</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfce086abf0d11068.jpg"></p><p><strong>相较于扩容逻辑卷，在对逻辑卷进行缩容操作时，其丢失数据的风险更大。所以在生产环境中执行相应操作时，一定要提前备份好数据。另外Linux系统规定，在对LVM逻辑卷进行缩容操作之前，要先检查文件系统的完整性（当然这也是为了保证我们的数据安全）。</strong></p><p><strong>Step5：创建快照卷，在创建之前我们往现有挂载目录写入一个测试文件。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写入测试文件</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># echo "Welcome to kkutysllb.cn" &gt; /home/data01/redeme.txt</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># cat /home/data01/redeme.txt </span></span><br><span class="line">Welcome to kkutysllb.cn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建快照卷，使用-s 选项创建</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># lvcreate -L 120M -s -n lv_data01_snp /dev/datastorage/lv_data01</span></span><br><span class="line">  Logical volume <span class="string">"lv_data01_snp"</span> created.</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfce0b432b0b25609.jpg"></p><p>在逻辑卷lv_data01的挂载目录中创建一个100M的测试文件，可以看见快照卷的容量同步上升，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@c7-test01 ~]<span class="comment"># dd if=/dev/zero of=/home/data01/test_files bs=1M count=100</span></span><br><span class="line">100+0 records <span class="keyword">in</span></span><br><span class="line">100+0 records out</span><br><span class="line">104857600 bytes (105 MB) copied, 1.12679 s, 93.1 MB/s</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfce0f2b64cb41781.jpg"></p><p><strong>LVM的“快照卷”功能类似于虚拟机软件的还原时间点功能。</strong>例如，可以对某一个逻辑卷设备做一次快照，如果日后发现数据被改错了，就可以利用之前做好的快照卷进行覆盖还原。LVM的快照卷功能有两个特点：</p><ul><li><strong>快照卷的容量必须等同于逻辑卷的容量；</strong></li><li><strong>快照卷仅一次有效，一旦执行还原操作后则会被立即自动删除。</strong></li></ul><p><strong>Step6：校验快照卷的恢复效果，记得先取消逻辑卷lv_data01的挂载点。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消挂载</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># umount /home/data01/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用快照卷lv_data01_snp对逻辑卷lv_data01进行还原</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># umount /home/data01/</span></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># lvconvert --merge /dev/datastorage/lv_data01_snp </span></span><br><span class="line">  Merging of volume datastorage/lv_data01_snp started.</span><br><span class="line">  datastorage/lv_data01: Merged: 30.56%</span><br><span class="line">  datastorage/lv_data01: Merged: 100.00%</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新挂载逻辑卷lv_data01</span></span><br><span class="line"></span><br><span class="line"> [root@c7-test01 ~]<span class="comment"># mount /dev/datastorage/lv_data01 /home/data01/</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/06/09/5cfce149ce3fb31332.jpg"></p><p><strong>使用快照卷还原后，原来创建的100M垃圾文件也就同步被清空了，同时快照卷只能使用一次，因此也会被系统回收。如下：</strong></p><p><img src="https://i.loli.net/2019/06/09/5cfce16a065f755843.jpg"></p><p><img src="https://i.loli.net/2019/06/09/5cfce1827171255801.jpg"></p><p><strong>Step7：删除逻辑卷，首先需要取消挂载点，然后按照逻辑卷—卷组—物理卷的顺序依次删除。</strong>代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消挂载</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># umount /home/data01/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除逻辑卷lv_data01</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># lvremove /dev/datastorage/lv_data01 </span></span><br><span class="line">Do you really want to remove active logical volume datastorage/lv_data01? [y/n]: y</span><br><span class="line">  Logical volume <span class="string">"lv_data01"</span> successfully removed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除卷组</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># vgremove datastorage </span></span><br><span class="line">  Volume group <span class="string">"datastorage"</span> successfully removed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除物理卷</span></span><br><span class="line"></span><br><span class="line">[root@c7-test01 ~]<span class="comment"># pvremove /dev/sdb /dev/sdc</span></span><br><span class="line">  Labels on physical volume <span class="string">"/dev/sdb"</span> successfully wiped.</span><br><span class="line">  Labels on physical volume <span class="string">"/dev/sdc"</span> successfully wiped.</span><br></pre></td></tr></table></figure><p>完成后，通过pvdisplay、vgdisplay、lvdisplay进行校验，如下：</p><p><img src="https://i.loli.net/2019/06/09/5cfce1bb34a0084086.jpg"></p><p><strong>至此，Linux原生的存储虚拟化介绍完毕，在后续KVM和OpenStack等开源技术实操时，还会用到Linux原生的存储虚拟化LVM，网络虚拟化vSwitch等实操，所以这里还需各位好好理解并掌握。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了让大家更好理解存储虚拟化的特点，本文将讲解各个常用RAID技术方案的特性，并通过实际部署软RAID 10、RAID 5+备份盘等方案来更直观地体验RAID的效果，以便进一步了解生产环境对硬盘设备的IO读写速度和数据冗余备份机制的需求。同时，本文还将介绍LVM的部署、扩容、缩小、快照以及卸载删除的相关知识，以便让大家通过开源存储虚拟化基础对存储虚拟化的块级虚拟化和文件系统级虚拟化有个更深刻的理解。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-07-浅析5G-SBA服务网络架构</title>
    <link href="https://kkutysllb.cn/2019/06/07/2019-06-07-%E6%B5%85%E6%9E%905G-SBA%E6%9C%8D%E5%8A%A1%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"/>
    <id>https://kkutysllb.cn/2019/06/07/2019-06-07-浅析5G-SBA服务网络架构/</id>
    <published>2019-06-06T23:16:40.000Z</published>
    <updated>2019-06-07T01:01:20.730Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IMT-2020推进组提出的“三朵云“架构"><a href="#IMT-2020推进组提出的“三朵云“架构" class="headerlink" title="IMT-2020推进组提出的“三朵云“架构"></a>IMT-2020推进组提出的“三朵云“架构</h2><p>前文提出了5G网络架构是一种颠覆性的变化，之所以这么说，是从5G网络架构的实现方式来说的。由于“三朵云”概念的提出，导致5G的网络功能软件模块化实现，也就是我们常说的云化网络架构，其特征就是控制集中化、功能模块化和接口软件化。如下图所示：<a id="more"></a></p><p><img src="https://i.loli.net/2019/06/07/5cf99f183a7cc45564.jpg"></p><p>这种云化的变化针对现网架构来说其本质上是一种重构，通过控制云实现全网资源控制和能力开放，主要是各种核心网元的虚拟化实现，将传统网元的控制面功能抽象出来通过软件模块化封装，形成一个个网络控制功能模块。而传统网元的媒体转发面被一个个虚拟交换机、白盒交换机或是支持SDN流表的专有硬件替代，构成转发云，与控制云一起完成网络数据的路由控制和转发，并构成转控分离的架构，也就是俗称的C/U分离。而接入云内部无论是无线网络还是有线网络都是按照C/U分离的架构部署，同时将CDN和MEC等下沉到接入云控制面，一方面满足低时延的业务需求，同时与控制云配合实现端到端的切片网络。</p><p>为了实现上述云化网路的重构，3GPP推荐的电信云化网络的基础架构就是NFV，全球各大运营的选择也是NFV，NFV的全称就是网络功能虚拟化，通过NFV架构实现5G网络需求的SBA服务架构、网络服务的无状态设计、C/U分离和切片管理。如下图左边所示：</p><p><img src="https://i.loli.net/2019/06/07/5cf99f4286bc974621.jpg"></p><p>而NFV网络架构的提出并不是3GPP定义的，是ETSI定义的。ETSI作为NFV的发起标准组织，于2015年初发布了NFV参考架构，如上图右边所示。ETSI定义的NFV参考架构，与传统网络架构相比，进行了“三纵两横”的划分。纵向与传统网络类似，分为基础设施层、虚拟网元层和运营支撑层共3层，通过这三层实现网络功能虚拟化和网络服务的运营管理。而横向分为两个域：业务网络域和管理编排域。</p><p><strong>整个NFV架构的关键就是管理编排域MANO，MANO只是个逻辑功能，并没有实体。</strong>其本质上通过NFVO、VNFM和VIM通过一定的管理流程来创建各类虚拟网元，提供各类电信业务，从而实现对左边的业务网络域编排和管理。比如：我们需要扩容一个vMME网元，NFVO会将容量需求和业务接口需求等构建一个网元描述文件发送给VNFM，VNFM会根据这些需求生成资源清单并向NFVO申请资源，包括：需要多个虚拟机、划分为几组虚拟机组，每个虚机的CPU/内存/磁盘/IP/通信端口的规划、以及每个虚机要加载的操作系统镜像等。而NFVO接收申请后，会将资源清单发送给VIM，由VIM去筹备底层的虚拟化资源，完成后NFVO会通知VNFM资源准备好了，VNFM从而完成虚拟网元的实例化部署。</p><p>上述这种调度方式，是一种间接调度方式，资源的编排和控制统一由NFVO完成，VNFM不能直接对VIM发起资源编排需求，类似我们每个部门的领导一样要掌控一切信息。还有一种直接调度方式，就是由VNFM去直接控制VIM来完成资源的编排。从性能角度来看，直接模式更好，但是从部署落地以及后续演进角度来看，间接模式更好。目前，中国移动就是采用的这种方式。详见电信云落地若干问题一文。</p><p>而5G网络为了实现切片功能，必须在NFV架构基础上引入SDN，那么上图ETSI的NFV架构就演进成上图最右边部分，在NFVO层面引入SDNO，实现对SDNC的全局编排管理，而在VIM层面引入SDNC（主要是在OpenStack的neutron组件下挂接各厂家SDN控制器实现），实现对底层虚拟网元资源和物理网络资源的统一管理。由SDNO去编排SDNC，从而实现全网网络资源的灵活编排和部署，并实现各切片网络需求的网络隔离性。</p><h2 id="SBA服务化网络架构"><a href="#SBA服务化网络架构" class="headerlink" title="SBA服务化网络架构"></a>SBA服务化网络架构</h2><p>因此，从网络架构实现角度来说，5G网络架构相比传统2G/3G/4G架构而言，是一种颠覆性的的变化。但是，从网络功能来说，5G网络相比传统2G/3G/4G还是由一定集成性。因为，通信网络的各代演进从来都不是一种割裂的状态，而是一种螺旋式递进的规律，每一代通信网络都会继承前一代一些特征，并演变出一些的新的特征。</p><p>比如：2G到2.5G，无线接入网没有变化，核心网在电路域的基础上引入分区域，实现GPRS功能呢。到了3G，无线接入网变为NodeB+RNC的架构模式，核心网在电路域和分组域的基础上引入了IMS域。而到了4G网络时代，无线接入网少了RNC这一层，NodeB变胖了变成了eNodeB，集成了原NodeB、RNC和SGSN的部分功能，实现接入控制、移动性管理、路由控制和无线资源控制，同时各个eNodeB之间多了个X2接口，因此4G网络时代，无线接入网的变化可以总结为“少一层、多一口、胖基站”。而核心网层面电路域和IMS域没有变化，但是分组域为了学习IMS域业务-控制-转发分离的架构，也拆分为MME、S-GW和P-GW，同时引入QoS的集中控制功能PCRF。但是4G网络在分组域的这种变化并不彻底，S-GW和P-GW上还存在部分控制功能。</p><p><img src="https://i.loli.net/2019/06/07/5cf99fdd3086281355.jpg"></p><p>为了实现5G网络的功能模块化、无状态设计和C/U分离需求，3GPP在网络功能进行从新定义，将传统2G/3G/4G的网元重新定位网络功能模块，就是上图右边各种命名以F结尾的功能块。与4G网络功能相比，主要有9点变化，前6点针对4G网络功能拆分和整合，7,8,9三点是5G网络功能的新增。</p><p>AMF就相当于4G网络的MME，但是只负责用户接入控制和移动性管理，而MME的会话管理部分被拆分整合进SMF，此外SMF还整合原S-GW/P-GW的路由控制，地址分配和合法监听等控制功能。PCF与4G的PCRF相比没有多大变化，仍然负责QoS的控制，但是5G网络的QoS的是基于流的，这一点与4G网络基于承载的QoS相比，变化还是较大的。UDM与传统HSS网元类似，负责用户数据和签约信息的存储，但是UDM不具备传统HSS/HLR的鉴权功能，这一部分被拆分至AUSF功能中，其目的是为了便于互联网业务鉴权的整合，实现5G网络的统一鉴权功能。UPF就是4G网络的S-GW/P-GW的纯转发面，也就是用户面功能。</p><p>至于第七点变化的NEF功能，属于能力开放功能，便于与各类互联网和物联网应用对接和扩展。其实，在4G网络中也有能力开放，目前在杭研集中一点实现，主要实现了PCC和智能网的能力开放。而NSSF功能主要是5G网络中为了实现切片管理新增的功能，而<strong>NRF功能用于5G网络各种网元功能的注册管理，这也是实现SBA服务网络架构的关键。</strong></p><p><strong>基于SBA服务网络架构是中国移动提出的一种架构，借鉴了IT领域生产者和消费者的概念</strong>。所谓生产者就是只产生网络服务能力，至于谁去使用并不关心。而消费者就是使用网路服务能力去实现网络服务，至于网络服务能力由谁产生并不关心。</p><p>通过这种理念引进，整个网络功能实现松耦合，各个网络功能挂载一条总线上（上图右边画圈部分），各个网络功能既是生产者，也是消费者，不仅自身产生网络服务能力，同时也消费其他网络功能的能力，这种角色的转变就是通过NRF网络功能实现。各个网络功能都向NRF注册，将自己IP地址、域名和能力集等信息注册到NRF上，NRF统一监控总线上各类网络功能的变更，并及时更新已变更的信息。当某个网络功能需要与另一个网络功能通信时，会去NRF上查询对端的信息，NRF会将对端的IP、域名和能力集进行反馈。然后，该网络功能就能通过总线寻址到对端，从而完成通信。因此，这种服务化的架构不仅实现了网络功能松耦合，而且将原来架构中的固定转发路径变为点到点转发。<strong>NRF的作用类似现网DNS，VoLTE的ENS，用作全网路由寻址。</strong></p><p>还有一点变化就是在5G网络架构中，接入网是一种固移融合的组网形式，统一由AMF完成接入控制。同时，在5G网络用户的移动性附着与承载会话建立是全解耦的，也就是说用户在5G网络附着后，无需建立PDU会话承载，当有业务需求时再按需发起PDU会话承载的建立。而不像4G网络，用户附着网络必须建立一条默认PDN会话承载。这种改变一定程度上减少了全网资源消耗。</p><p><img src="https://i.loli.net/2019/06/07/5cf9a079f0d9e24978.jpg"></p><p>这种服务化架构在云原生的应用就如上图所示，每一朵云都是基于这种SBA的组网形式，不仅云内各服务松耦合，云与云之间也是一种松耦合状态，通过全网统一的编排和管理实现对接。目前，<strong>中国移动内部规划通过OSS4.0实现全网资源的统一编排和管理。</strong></p><h2 id="中国移动电信云-amp-5GC资源池部署演进策略"><a href="#中国移动电信云-amp-5GC资源池部署演进策略" class="headerlink" title="中国移动电信云&amp;5GC资源池部署演进策略"></a>中国移动电信云&amp;5GC资源池部署演进策略</h2><p>前面提到，5G网络架构的实现基于NFV/SDN的一种云化网络架构。因此，各大运营商在部署5G之前必须对传统网络进行一种云化改造。中国移动在2015年底就启动了NFV云化试点工作，经过4年多省市连续试点，目前已经解决大网云化改造中80%的问题。因此，在2019年中国移动启动电信云资源池的建设，全国分为8个大区（西北、西南、华北、华南、东北、华东1、华东2、中部），按照“三步走，两级演进”的策略，最终全网核心控制云8大区共部署10万台服务器，仅西北大区就需部署20000+服务器。如下图所示：</p><p><img src="https://i.loli.net/2019/06/07/5cf9b67d1101088422.jpg"></p><p>如上图所示，三步走策略中目前已基本完成第一步8大区电信云资源池的建设，预计在今年底8大区电信云进入商用阶段。在目前第一阶段中，首先完成大网核心网的云化改造，涉及IMS/EPC两大专业，并在今年完成各省市大网业务的上云割接，同时随着资源池规模的逐步加大，最终预计在2022年完成全网业务云化搬迁。</p><p>同时，在今年9月同步开启二阶段资源池建设，并且在一阶段电信云资源池的基础上引入5GC资源池，同步引入SDN技术。由于SDN的引入需要对已有资源池从虚层开始完成改造和重部署，考虑到已割接上云业务安全和网络稳定性，因此5GC资源池与一阶段电信云资源池采用<strong>“共址不共池”</strong>策略部署。</p><p>后续，在明年年中同步启用三阶段资源池扩容部署，主要目的是满足全网用户资源规模需求。并在明年年中同步开始一阶段4G云化核心网向5GC升级演进。</p><p>而所谓的“二级架构”是根据业务需求来逐步部署，总体原则是先“先核心后边缘”。在上述二阶段5GC资源池引入后，如果有30ms~10ms的业务需求，在各省省会城市部署边缘云资源池，主要完成CDN下沉、vBRAS改造、MEC部署以及试点CU池部署。如果有低于10ms业务需求，可考虑在地市/区县层面部署计算/存储一体化的站点计算域资源池，主要涉及C-RAN的CU/DU就近接入改造，从而满足低时延业务需求。该层面的资源池不部署管理节点，有省端边缘云统一纳管调度，同时各站点资源池之间不涉及跨池迁移特性。接入站点资源池可考虑三种部署模式“AZ、Cell和轻量化资源池”，目前在接入站点不考虑MEC需求时，统一采用AZ方式部署，如果后续部署MEC，考虑到MEC可能有运营管理需求，可考虑轻量化资源池方式部署。（AZ和Cell是OpenStack NOVA组件中的概念，因此需要大家具备OpenStack的一些基本知识，也可看我公众号的系列文章，公众号ID：CloudSupermanLLB）</p><p>而在8大区核心控制云资源池中，目前采用“二层解耦、逐步演进到三层解耦”的策略部署。如下图示所示：</p><p><img src="https://i.loli.net/2019/06/07/5cf9b6a1a3f9833513.jpg"></p><p>所谓二层解耦，就是硬件和软件解耦，目前8大区电信云资源池硬件采用中兴/浪潮服务器、华为/中兴TOR和EOR、迈普的管理TOR，西北大区除服务器为浪潮外，其余硬件配置与其他大区一致。除了硬件外，虚层VIM、虚拟网元层VNF/VNFM、编排层NFVO都是同厂商部署，由于软件层面目前因未开始正式集采招标，因此厂商还未确定。但是可以确定的是—<strong>“每个大区两个软件厂商”</strong>，由于电信云采用分布式存储，因此存储的招标与软件一起完成，目前也未确定。</p><p>二层解耦部署策略主要考虑集成交付快、不涉及不同厂商软件兼容性问题，因此问题较少，但是同样也会带来资源利用率不高的缺点。比如：厂商A的池内资源不够，即使厂商B池内由空闲资源也无法提供给厂商A使用，因为这里涉及虚层VIM、虚拟网元层VNF/VNFM、编排层NFVO和分布式存储等软件重新部署，网络改动量大，不利于大网稳定。同时，由于软件采用双厂商部署，也会导致运维人员必须掌握两个厂家软件机制、部署流程和运维管理流程等，对运维人员的要求较高。</p><p>而边缘资源池和接入站点也是采用精简化的两级部署架构，<strong>主要以业务需求来驱动。</strong>如下图所示：</p><p><img src="https://i.loli.net/2019/06/07/5cf9b6c3cca4469289.jpg"></p><p>VIM的集中管理部署在省端，采用3节点高可用部署策略，每个节点资源池可纳管不多余256个接入站点资源池，如果后续省内业务规模较大导致接入站点资源池扩容，省端的VIM集中管理节点可考虑按照3、5、7。。。等节点规划扩容（必须为奇数才能实现高可用策略）。同时，在接入站点资源池除MEC部署需求外，统一部署计算/存储一体化资源池，实现<strong>“VIM集中、AZ拉远”</strong>的部署要求，不仅利于节约投资，也方便划分省/地两端的维护界面。在接入站点，由于采用计算/存储一体化部署策略，因此存储层面必须采用分布式存储，每个计算服务器部署存储软件“机头”，每个资源池内所有服务器的硬盘（除系统盘外）构成OSD存储池，整体的管理调度由省端VIM层面部署集群控制软件来完成。详见本站分布式存储介绍文章。</p><p>按照这种“两级部署”策略，后续随着5G业务的发展，整体维护界面较清晰，同时也利于省端维护人员转型积极性的提升。整体5G电信云资源池的维护界面如下图所示：</p><p><img src="https://i.loli.net/2019/06/07/5cf9b6e4bdf5067337.jpg"></p><p>核心网控制云维护由大区负责，涉及从动环到NFVO各层面维护职责，主要全网资源监控、业务质量的分析，以及自动化手段的开发部署。随着业务需求发展，省/地两端负责边缘云资源池和接入站点的维护，同样涉及从动环到NFVO各层面维护职责。整体界面划分清晰。</p><p>在对运维人员转型要求方面主要按照NFV云化网络各层来进行专业划分，传统烟囱式的专业划分逐渐淡化和模糊化。基础设施运维层面主要负责硬件故障处理、Host OS和Hypervisor的运维管理，因此运维人员必须具备IT硬件及Linux运维实践的知识技能。业务层面的维护主要涉及传统CT网元运维管理、云管平台的运维管理，因此运维人员除掌握传统CT技能外，还需掌握云计算和虚拟化相关知识技能，并具备一定运维经验。在业务编排层面，除了要掌握各类开发语言，如：Linux shell、Python、yaml和xml等，还需具备下两层的运维经验，具备云化网络端到端拉通能力，否则开发的脚本在部署加载会引发各类不可预知的问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;IMT-2020推进组提出的“三朵云“架构&quot;&gt;&lt;a href=&quot;#IMT-2020推进组提出的“三朵云“架构&quot; class=&quot;headerlink&quot; title=&quot;IMT-2020推进组提出的“三朵云“架构&quot;&gt;&lt;/a&gt;IMT-2020推进组提出的“三朵云“架构&lt;/h2&gt;&lt;p&gt;前文提出了5G网络架构是一种颠覆性的变化，之所以这么说，是从5G网络架构的实现方式来说的。由于“三朵云”概念的提出，导致5G的网络功能软件模块化实现，也就是我们常说的云化网络架构，其特征就是控制集中化、功能模块化和接口软件化。如下图所示：
    
    </summary>
    
      <category term="5G网络架构" scheme="https://kkutysllb.cn/categories/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="5G" scheme="https://kkutysllb.cn/tags/5G/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-07-2G~5G网络架构的演进</title>
    <link href="https://kkutysllb.cn/2019/06/07/2019-06-07-2G-5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B/"/>
    <id>https://kkutysllb.cn/2019/06/07/2019-06-07-2G-5G网络架构的演进/</id>
    <published>2019-06-06T23:01:09.000Z</published>
    <updated>2019-06-06T23:14:30.813Z</updated>
    
    <content type="html"><![CDATA[<p>5G将渗透到未来社会的各个领域，以用户为中心构建全方位的信息生态系统。面对极致的体验、效率和性能要求，以及“万物互联” 的愿景，5G的网络架构设计将面临极大挑战。相较于2G/3G/4G时代，5G的网络结构会发生颠覆性的变化。<a id="more"></a></p><p><img src="https://i.loli.net/2019/06/07/5cf99b7eacb7156407.jpg"></p><p>移动通信网络架构的演进包括两个方面，即<strong>无线接入网（RAN，Radio Access Network）</strong>的演进和<strong>核心网（CN，Core Network）</strong>的演进。</p><h2 id="2G-3G-4G网络架构的演变"><a href="#2G-3G-4G网络架构的演变" class="headerlink" title="2G/3G/4G网络架构的演变"></a>2G/3G/4G网络架构的演变</h2><p><strong>从GSM网络（2G）演进到GPRS网络（2.5G），最主要的变化是引入了分组交换业务。</strong>原有的GSM网络是基于电路交换技术，不具备支持分组交换业务的功能。因此，为了支持分组业务，在原有GSM 网络结构上增加 了几个功能实体，相当于在原有网络基础上叠加了一个小型网络，共同构成GPRS网络。</p><p><img src="https://i.loli.net/2019/06/07/5cf99bb2e030d13262.jpg"></p><p>在接入网方面，在<strong>BSC上增加了分组控制单元（PCU，Packet Control Unit）</strong>，用以提供分组交换通道；<strong>在核心网方面，增加了服务型GPRS支持节点（SGSN，Service GPRS Supported Node）</strong>和<strong>网关型GPRS支持节点（GGSN，Gateway GPRS Supported Node）</strong>，功能方面与MSC和GMSC一致，区别在于处理的是分组业务，外部网络接入IP网；从GPRS叠加网络结构开始，引入了两个概念。<strong>一个是电路交换域，一个是分组交换域，即CS域与PS域。</strong></p><p>到了3G时代，在速率方面有了质的飞跃，而在网络结构上，同样发生巨大变化。首先，就是空中接口的改变，以往网络结构中的<strong>Um接口变成Uu接口</strong>，而接入网和核心网的接口也换成了<strong>Iu接口</strong>，不再是A接口。在接入网方面，不再包含BTS和BSC，取而代之的是<strong>基站NodeB与无线网络控制器（RNC，Radio Network Controller）</strong>，功能方面与以往保持一致，<strong>核心网方面基本与原有网络共用，无太大区别。</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf99bd204c3734559.jpg"></p><blockquote><p><strong>NodeB的功能：主要完成射频处理和基带处理两大类工作。</strong>射频处理主要包括发送或接收高频无线号，以及高频无线信号和基带信号的相互转换功能；基带处理主要包括信道编/译码、复用/解复用、扩频调制及解扩/解调功能。</p><p><strong>RNC的功能：主要负责控制和协调基站间配合工作，完成系统接入控制、承载控制、移动性管理、宏分集合并、无线资源管理等控制工作。</strong></p></blockquote><p>到4G时代，整个LTE网络从接 入网和核心网方面分为E-UTRAN和EPC。在接入网方面，网络扁平化，不再包含两种功能实体，整个网络只有一种基站eNodeB，它包含整个NodeB和部分RNC的功能，演进过程可以概括为<strong>“少一层，多一口，胖基站”</strong>。这样做降低了<strong>呼叫建立时延</strong>和<strong>用户数据传输时延</strong>，并且随着网络逻辑节点的减少，可以降低建设和维护成本，满足低时延、低复杂度和低成本的求。</p><p><img src="https://i.loli.net/2019/06/07/5cf99c5a308af45797.jpg"></p><blockquote><p><strong>“少一层”：</strong>4层组网架构变为3层，去掉了RNC，减少了基站和核心网之间信息交互的多节点开销，用户平面时延大大降低，系统复杂性降低。 </p><p><strong>“多一口”：</strong>以往无线基站之间是没有连接的，而eNodeB直接通过X2接口有线连接，实现无线侧IP化传输，使基站网元之间可以协调工作。eNodeB互连后，形成类似于“Mesh”的网络，避免某个基站成为孤点，这增强了网络的健壮性。 </p><p><strong>“胖基站”：</strong>eNodeB的功能由3G阶段的NodeB、RNC、SGSN、GGSN的部分功能演化而来，新增了系统接入控制、承载控制、移动性管理、无线资源管理、路由选择等。</p></blockquote><p>核心网侧也发生了重大变革。在GPRS/UMTS中，服务GPRS支持节点（SGSN）主要负责鉴权、移动性管理和路由选择，而网关GPRS支持节点（GGSN）负责IP地址分配、数据转发和计费。到了LTE时代，EPC（Evolved Packet Core）对之前的网络结构能够保持前向兼容，但自身结构方面不再有3G时的各种实体部分，主要由<strong>移动管理实体（MME，Mobile Management Entity）、服务网关S-GW和分组数据网关（P-GW）构成，外部网络只接入IP网。</strong>其中，<strong>MME主要负责移动性管理，包括承载的建立和释放、用户位置更新、鉴权、加密等</strong>，这些笼统地被称为控制面功能，而<strong>S-GW和P-GW更主要的是处理用户面的数据转发，但还保留内容过滤、数据监控与计费、接入控制以及合法监听等控制面功能。</strong>可以看到，从GPRS到EPC的演进中，有着相似的体系架构和接口，并朝着控制与转发分离的趋势演进，但这种分离并不彻底。比如MME相当于SGSN的控制面功能，S-GW则相当于SGSN的用户面。</p><p>此外， LTE核心网新增了一个网元<strong>PCRF</strong>（图中未画出），即<strong>策略与计费执行功能单元</strong>，可以实现对用户和业务态服务质量（QoS）进行控制，为用户提供差异化的服务，并且能为用户提供业务流承载资源保障以及流计费策略。</p><h2 id="5G架构设计需求分析"><a href="#5G架构设计需求分析" class="headerlink" title="5G架构设计需求分析"></a>5G架构设计需求分析</h2><p>5G的架构设计主要需要满足<strong>关键性能需求</strong>和<strong>网络运营需求</strong>。3GPP定义了5G应用的三大场景：<strong>eMBB、mMTC</strong>和<strong>uRLLC。</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf99ca6bdf6996202.jpg"></p><p><strong>对于eMBB场景，又可进一步细分为连续广覆盖场景</strong>和<strong>热点高容量场景。</strong>在连续广覆盖场景下，要随时随地提供100Mbps ~1Gbps的高体验速率，并支持在高速移动如500km/h过程中的基本服务能力和业务的连续性。在LTE网络结构中，基站间虽然可以通过X2接口实现南北向数据交互，但无线资源管理、移动性管理和站间协同能力较弱。 另外，4G主要是通过核心网实现多种无线接入的统一控制，不同的接入技术在无线侧控制面各异，无法统一，互操作复杂。在热点高容量场景下，核心网网关部署的实际位置较高，且数据转发模式单一，回传网络的容量压力较大。</p><p><strong>对于mMTC场景，</strong>当海量的5G差异化的物联网终端接入时，<strong>由于LTE采用的是与移动互联网场景相同的单一移动性和连接管理机制，承载物联网少量数据仍需消耗较大的基于隧道的GTP-C报头开销，</strong> 不仅效率低，还极有可能造成信令拥堵。</p><p><strong>对于uRLLC场景，现有网络架构的控制面功能逻辑上分布在MME/SAE-GW等多个网元中，</strong>无法实现集中控制，同一网络控制功能可能需要多个网元通过接口协议协商完成，<strong>端到端通信时需经历较长的传输时延，且可能由于某些原因存在路由迂回现象。</strong>这既无法满足5G高可靠性前提下的低时延要求（现网端到端时延与 5G的时延要求约存在两个数量级的差距），又无法满足特定业务如车联网的安全性要求。</p><p>而网络运营方面的需求主要是运营商在部署新网络时，一般都会考虑建设和运营的可行性，便利性。因此，对5G网络提出了<strong>灵活部署、覆盖与容量兼容、精细化控制、能力开放</strong>和<strong>异构兼容</strong>等需求，这些需求在当前LTE网络只能实现很少一部分。因此， 5G网络架构的设计需要满足<strong>转控分离、集中控制、分布式部署、资源池化</strong>和<strong>服务模块化</strong>等要求。</p><p><img src="https://i.loli.net/2019/06/07/5cf99ccb8141160843.jpg"></p><p><strong>综上，对于5G接入网，要设计一个满足多场景的以用户为中心的多层异构网络，以支持宏微结合，统一容纳多种接入技术，提升小区边缘协同处理效率，提高无线和回传资源利用率。对于5G核心网的设计，一方面要将转发功能进一步简化和下沉，将业务存储和计算能力从网络中心下移至网络边缘，以支持高流量和低时延业务要求，以及灵活均衡的流量负载调度功能；另一方面通过能力开放、资源编排、集中控制等更高效地支持差异化的业务需求。</strong></p><h2 id="5G网络架构的提出"><a href="#5G网络架构的提出" class="headerlink" title="5G网络架构的提出"></a><strong>5G网络架构的提出</strong></h2><p>在5G逻辑架构的设计上，业界遵循<strong>先继承、后创新</strong>的思路，参照现有成熟的LTE网络架构，<strong>引入SDN和NFV</strong>等关键技术对网络功能进行解析和重构，以逐步适应5G架构的演进需要。</p><p><img src="https://i.loli.net/2019/06/07/5cf99d251f94e28923.jpg"></p><p>为了便于大家理解，我们从LTE的网络结构分析入手，逐步引出5G的网络逻辑架构演进思路。我们将LTE非漫游网络架构从逻辑上划分为3个部分，如下图所示。 第1部分是LTE为了满足网络的后向兼容性所引入的，在此不做赘述。第2部分是接入网，接入网（空口）的演进几乎是历代移动通信网络架构演进中最为关键的部分。第3部分是核心网，是一个并不彻底的转控分离架构，且是5G时代优先需要重构的重点。因此，我们优先聚焦该部分的重构。</p><p><img src="https://i.loli.net/2019/06/07/5cf99d4d0f27a27468.jpg"></p><p><strong>Step1：</strong>为了解决控制与转发分离不彻底的问题，需要首先对兼具控制和转发功能的网关进行解耦。LTE架构中S-GW和P-GW实际上是物理网元功能合一的，在逻辑上我们可以将其视为统一的SAE-GW，然后引入SDN技术进行网络功能解耦，<strong>用户面功能由新定义的网元UPF承载</strong>，<strong>控制面功能则交由新网元SMF进行统一管理</strong>。相应地，将原本已是纯控制面网元的<strong>MME、HSS和PCRF分别定义为AMF、UDM和PCF</strong>，但对网元的实际功能只做微小的变更或整合。核心网第一步重构后的网络逻辑架构如下图所示。</p><p><img src="https://i.loli.net/2019/06/07/5cf99d6c1fb2681576.jpg"></p><p><strong>Step2：</strong>为了满足网络资源充分灵活共享的需求，实现基于实际业务需求的网络自动部署、弹性伸缩、故障隔离和自愈等，需要引入NFV对网络功能进行虚拟化。因此，我们<strong>定义新网元NF以适应新的需要。考虑到NF面向的是用户差异化的服务，我们将其置于网元PCF，并定义新的接口以便NF能够按需获取PCF的策略控制等参数。</strong>核心网第二步重构后的网络逻辑架构如下图所示。</p><p><img src="https://i.loli.net/2019/06/07/5cf99dcd9eff240196.jpg"></p><p><strong>Step3：需要将业务平台下沉到网络边缘，为用户就近提供业务计算和数据缓存能力，实现网络从接入管道向信息化服务使能平台的关键跨越。</strong>因此，需要<strong>增强UDM的功能，以承担业务平台下沉后相应的数据管理工作。</strong>同时，<strong>引入网元AUSF承担数据访问的鉴权和授权工作。</strong>此外，考虑到5G面向的是极端差异化的业务场景，传统的“竖井式”单一网络体系架构无法满足多种业务的不同QoS保障需求，还需<strong>引入网元NSSF以实现网络切片选择的功能</strong>，使网络本身具备弹性和灵活扩展的能力。核心网第三步重构后的网路逻辑架构如下图所示。</p><p><img src="https://i.loli.net/2019/06/07/5cf99de61cb1061772.jpg"></p><p><strong>Step4：接入网侧的网元编排。</strong>从1G到4G，无线通信系统经历了迅猛的发展，现实网络逐步形成了包含多种无线制式、频谱利用和覆盖范围的复杂现状。在5G时代，同一运营商将面临多张不同制式网络长期共存的局面。因此，多网络融合也将成为5G网络架构设计不可规避的因素。对此，需要改变原有网络单一的eNodeB接入形式，对接入网侧做进一步的优化和增强。<strong>需要重新定义新的网元为（R）AN，以表示接入侧不再是单一的无线接入，而是固移融合。</strong>第四步重构后的网络逻辑架构图如下图所示。</p><p><img src="https://i.loli.net/2019/06/07/5cf99e04f205e50100.jpg"></p><p><strong>Step5：</strong>完成各个网元之间逻辑接口的定义，终端UE与AMF实体之间的<strong>N1接口</strong>是新定义的空口，使得低时延、高可靠、超密连接等愿景具备落地的可能。同时，原来的NF被定义为运营商授信、自行部署的<strong>应用功能单元AF</strong>。</p><p><img src="https://i.loli.net/2019/06/07/5cf99e1c243c042206.jpg"></p><p>通过五步重构，我们就得到了3GPP所确定的5G网络架构，这是一个点到点网络架构，主要包含以下网元功能：</p><p><strong>AMF：接入和移动性管理功能单元，负责控制面的注册和连接管理、移动性管理、信令合法监听以及上下文的安全性管理。</strong>相比4G的MME，AMF将<strong>漫游控制、承载管理</strong>以及<strong>网关选择</strong>等功能剥离，是一个“瘦身版”的MME。</p><p><strong>SMF：会话管理功能单元，相当于是4G的MME和SAE-GW控制面整合后集中控制单元，主要负责会话管理，包括会话建立、变更和释放，以及AN节点和UPF间的承载维持。</strong>SMF同时也继承了4G MME的<strong>漫游控制功能、UPF选择和控制功能</strong>和P-GW的<strong>UE-IP地址分配功能。</strong></p><p><strong>UPF：数据转发功能单元，保留了4G SAE-GW的数据转发功能，包括本地移动性锚点、包路由和转发、上下行传输级包标记、包过滤和用户面策略控制功能执行，</strong>相当于SDN架构中纯转发面，无自主控制权，只能执行来自SMF的控制指令。</p><p><strong>PCF：策略控制功能单元，负责制定统一的策略框架来管理网络行为。一方面结合自定义信息作出决策并强制控制面执行，另一方面也为前端提供连接用户数据库获取用户订阅信息的渠道。</strong>PCF与4G的PCRF功能几乎相同。</p><p><strong>UDM：统一数据管理单元，类似4G的HSS分为FE和BE两个功能实体，UDM同样也包含两个功能实体UDM和UDR。</strong>UDM类似FE属于应用前端接口单元，负责鉴权、授权、位置管理和订阅管理。UDR类似BE属于用户数据库单元，负责用户数据的存储、包括订阅表示、安全认证、移动性数据、会话数据等。与HSS相比，是一个增强版的HSS。</p><p><strong>AUSF：认证服务器功能单元，负责业务层面的认证和授权，相当于将4G时代业务服务器AS中对访问进行鉴权和授权的功能单独剥离出来。</strong>作为网络准入的裁决者，AUSF联合UDM对通过AMF来访的UE进行准入授权，认证通过的UE可以凭借AUSF授权的专用秘钥token实现数据的访问和获取。</p><p><strong>NSSF：网络切片选择功能单元，主要根据网络配置，为合法的UE选择可提供特定服务的网络切片示例。</strong>其机制是通过切片需求辅助信息的匹配，为UE选择一个或一组特定的AMF提供网络服务。需要注意一点，<strong>NSSF只是完成核心网层面的切片选择，至于端到端的切片建立，是通过NSSF选择的AMF来实现接入网切片的确认。</strong></p><p><strong>AF：应用功能单元，通过与核心网交互对外提供专用服务。</strong>AF是运营商自行部署的授信的应用，可以直接访问网络的相关应用功能，<strong>无需经过其它外部接口。</strong></p><p>为契合IMT-2020推进组提出的“三朵云”5G网络架构，我们将上述重构后的网络架构进行平面的切割，如下图所示。</p><p><img src="https://i.loli.net/2019/06/07/5cf99e405847a72210.jpg"></p><p><strong>“三朵云”5G网络是一个可依业务场景灵活部署的融合网络。</strong> <strong>控制云</strong>完成全局的策略控制、会话管理、移动性管理、策略管理、信息管理等，并支持面向业务的网络能力开放，实现定制网络与服务， 满足不同新业务的差异化需求，扩展新的网络服务能力。<strong>接入云</strong>将支持用户在多种应用场景和业务需求下的智能无线接入，并实现多种无线接入技术的高效融合，无线组网可基于不同部署条件要求，进行灵活组网，并提供边缘计算能力。<strong>转发云</strong>配合接入云和控制云，实现业务汇聚转发功能，基于不同新业务的带宽和时延等需求，转发云在控制云的路径管理与资源调度下，实现eMBB、uRLLC和mMTC等不同业务数据流的高效转发与传输，保证业务端到端质量要求。“三朵云” 不可分割，协同配合，并且是基于SDN/NFV技术实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;5G将渗透到未来社会的各个领域，以用户为中心构建全方位的信息生态系统。面对极致的体验、效率和性能要求，以及“万物互联” 的愿景，5G的网络架构设计将面临极大挑战。相较于2G/3G/4G时代，5G的网络结构会发生颠覆性的变化。
    
    </summary>
    
      <category term="5G网络架构" scheme="https://kkutysllb.cn/categories/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="5G" scheme="https://kkutysllb.cn/tags/5G/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-07-华为分布式存储FusionStorage原理详解</title>
    <link href="https://kkutysllb.cn/2019/06/07/2019-06-07-%E5%8D%8E%E4%B8%BA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8FusionStorage%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
    <id>https://kkutysllb.cn/2019/06/07/2019-06-07-华为分布式存储FusionStorage原理详解/</id>
    <published>2019-06-06T22:46:10.000Z</published>
    <updated>2019-06-06T22:59:37.477Z</updated>
    
    <content type="html"><![CDATA[<h2 id="华为FusionStorage中的基础概念"><a href="#华为FusionStorage中的基础概念" class="headerlink" title="华为FusionStorage中的基础概念"></a>华为FusionStorage中的基础概念</h2><p>FusionStorage采用全分布式DHT架构，将<strong>所有元数据按规则分布在各存储节点，不存在跨节点的元数据访问</strong>，彻底避免了元数据瓶颈。该核心架构设计保证了FusionStorage系统相比分布式文件系统具备更大规模的线性扩展能力。<a id="more"></a></p><p><strong>所谓DHT架构，就是分布式哈希表，Distributed Hash Table</strong>。如下图所示，它是FusionStorage中指数据路由算法。</p><p><img src="https://i.loli.net/2019/06/07/5cf998494d5e771062.jpg"></p><p>DHT机制可以保证上层应用对数据的IO操作会均匀分布在不同服务器的不同硬盘上，不会出现局部的热点，实现全局复负载均衡。DHT采用的是开源对象存储swift中一致性哈希算法（详见OpenStack的swift介绍），每个存储节点负责存储一小部分数据，基于DHT实现整个系统的<strong>寻址</strong>和<strong>存储</strong>。</p><p>上图中，<strong>Partition</strong>代表了一块数据分区，在DHT环上映射为固定Hash段代表的数据区Pn（n=1,2,3…)。<strong>Key-Value键值对</strong>表示底层磁盘上的数据组织索引，每个Value代表一个块存储空间。当我们要查找某一个数据的存放位置时，通过key值计算散列值（哈希值），根据计算的散列值找到DHT换上某一个Partition，然后根据Partition与disk的映射关系找到对应的磁盘，再通过Value值查找磁盘上的具体数据。具体如下所示</p><p><img src="https://i.loli.net/2019/06/07/5cf99877a3e4e24277.jpg"></p><p><strong>Volume</strong>代表应用卷，也就是虚拟机能看见并挂载的虚拟磁盘，它本质上代表了应用看到的一个LBA连续编址。而Volume的LBA连续编址就是上述用于数据查找的key值。</p><p>在华为FusionStorage中还有一个基础概念就是<strong>资源池，它是由上述一组分区Partition构成的存储池。</strong>如下图所示，<strong>每个资源池对应一个DHT环。</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf9989fd248f84381.jpg"></p><p>在上图中，由两个资源池，分别对应两个DHT环，左边三个硬盘对应DHT1的三个Partition分区（P1、P2和Px），右边三块硬盘对应DHT2的三个Partition分区（P1、P2和Py）。当虚拟机挂载上面的Volume1/2/3时，将对应的LBA散列后，计算的结果分别对用DHT1的P1/P2/Px；当虚拟机挂载上面的Volume10/11时，将对应的LBA散列后，计算的结果分别对应DHT2的P1/P2/Py。</p><p>华为FusionStorage的资源池类似于SAN存储中的RAID组概念，但是<strong>与RAID相比，其优点是主要有三点：一是条带宽度大</strong>，最大支持96块盘（2份拷贝），提供超大存储空间，而且系统自动将每个卷的数据块打散存储在不同服务器的不同硬盘上，冷热不均的数据会均匀分布在不同的服务器上，不会出现集中的热点，<strong>避免高I/O应用导致热点瓶颈；二是具有动态热备功能</strong>，资源池内所有硬盘都可用作资源池的热备盘；<strong>三是结构简单</strong>，通过资源池和Volume二层结构，使服务器直接看到Volume，消除了中间的LUN逻辑存储，提升I/O读写性能。</p><h2 id="FusionStorage的数据路由原理"><a href="#FusionStorage的数据路由原理" class="headerlink" title="FusionStorage的数据路由原理"></a>FusionStorage的数据路由原理</h2><p>如下所示，<strong>FusionStorage数据路由采取分层处理方式：1）VBS通过计算确定数据存放在哪个服务器的哪块硬盘上。2）OSD通过计算确定数据存放在硬盘的具体位置。</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf998fe60e0e62718.jpg"></p><p><strong>Step1：</strong>系统初始化时，FusionStorage将哈希空间（0~2^32）划分为N等份，每一等份是1个分区（Partition），这N等份按照硬盘数量取整除并进行均分。例如：<strong>二副本场景下，系统N默认为3600</strong>，假设当前系统有36块硬盘，则每块硬盘承载100个分区。<strong>上述“分区-硬盘”的映射关系在系统初始化时会分配好，后续会随着系统中硬盘数量的变化会进行调整</strong>。该映射表所需要的空间很小，FusionStorage系统中的节点会在内存中保存该映射关系，用于进行快速路由。</p><p><strong>Step2：</strong>FusionStorage<strong>会对每个LUN在逻辑上按照1MB大小进行切片</strong>，例如1GB的LUN则会被切成1024*1MB分片。当应用侧访问FusionStorage时候，在SCSI命令中会带上LUN ID和LBA ID以及读写的数据内容，OS转发该消息到本节点VBS模块，<strong>VBS根据LUN ID和LBA ID组成一个key，该key会包含LBA ID对1MB的取整计算信息</strong>。通过DHT Hash计算出一个整数(范围在0~2^32内)，并落在指定Partition中；根据内存中记录的“<strong>分区-硬盘</strong>”映射关系确定具体硬盘，VBS将IO操作转发到该硬盘所属的OSD模块。</p><p><strong>Step3：</strong>每个OSD会管理一个硬盘，<strong>系统初始化时，OSD会按照1MB为单位对硬盘进行分片管理，并在硬盘的元数据管理区域记录每个1MB分片的分配信息</strong>。<strong>OSD接收到VBS发送的I/O操作后，根据key查找该数据在硬盘上的具体分片信息，获取数据后返回给VBS</strong>。从而完成整个数据路由过程。</p><p>比如：应用需要访问LUN1+LBA1地址起始的4KB长度的数据，首先构造key=LUN1+LBA1/1M，对该key进行HASH计算得到哈希值，并对N取模，得到partition号，根据内存中记录的“分区-硬盘“映射表可得知数据归属的硬盘。</p><p><strong>总结：</strong>VBS将操作系统的SCSI命令中的key提取出来（Key值的计算方式：Key=LUN ID+LBA ID/1MB），通过哈希运算，确定访问数据内容落到DHT环上的哪块Partition上，根据Partition和Disk的对应关系（系统初始化时形成），确定数据存放在那个服务器上的哪块盘上，再通过OSD通过计算确定数据存放在硬盘的具体位置并将获取的数据返回给VBS。</p><h2 id="FusionStorage的内部组件功能和相互关系"><a href="#FusionStorage的内部组件功能和相互关系" class="headerlink" title="FusionStorage的内部组件功能和相互关系"></a>FusionStorage的内部组件功能和相互关系</h2><h3 id="FusionStorage-VBS模块及处理流程"><a href="#FusionStorage-VBS模块及处理流程" class="headerlink" title="FusionStorage VBS模块及处理流程"></a>FusionStorage VBS模块及处理流程</h3><p>VBS模块作为FusionStorage系统存储功能的接入侧，负责完成两大类业务：<strong>一是卷和快照的管理功能；二是I/O的接入和处理。</strong>VBS模块内部如下图所示，主要由：<strong>VBM、VBP、CLIENT、DATANET、SCSI协议控制（SCSI Initiator和SCSI Target）</strong>和<strong>心跳控制模块HeartBeat</strong>组成。</p><p><img src="https://i.loli.net/2019/06/07/5cf9992d3f1b431081.jpg"></p><p><strong>VBM模块是VBS中的控制管理模块，主要负责完成卷和快照的管理功能。</strong>比如：创建卷、挂载卷、卸载卷、查询卷、删除卷、创建快照、删除快照、基于快照创建卷等。</p><p><strong>I/O数据流在VBS进程中需要经过三个模块的处理，分别为**</strong>SCSI<strong><strong>、</strong></strong>VBP<strong><strong>、</strong></strong>CLIENT<strong>**：</strong></p><p><strong>Step1：</strong>SCSI启动器模块SCSI Initiator负责从内核（VSC.KO）中将I/O引入VBS进程，SCSI目标模块SCSI Target接收到的I/O数据包是<strong>标准SCSI协议格式的I/O请求</strong>，通过<strong>SCSI协议的四元组</strong>（host_id/channel_id/target_id/lun_id）和该I/O数据包在块设备上的偏移地址<strong>offset</strong>，<strong>读写的数据长度len共三个参数标识符，唯一标识一个I/O数据包</strong>，SCSI目标模块SCSI Target将收到的I/O信息交给VBP(Virtual Block Process)模块。</p><p><strong>Step2：</strong>VBP内部将通用块格式的I/O数据包<strong>转换为FusionStorage内部Key-Value</strong>格式的I/O数据包下发给client，其中<strong>KEY的组成为</strong>：<strong>tree_id（4Byte）</strong>+<strong>block_no（4Byte）</strong>+ <strong>branch_id（2Byte）</strong>+<strong>snap_id（2Byte）</strong>，<strong>tree_id/branch_id/snap_id是FusionStorage内部对卷、快照的唯一标识</strong>；<strong>block_no是将卷按照1M的块划分，本次I/O落在哪一个1M块上的编号。（**</strong>block_no对1M取整后与tree_id/branch_id/snap_id求和就是key值，对1M取余后得到的余数就是offset<strong>**）</strong></p><p><strong>Step3：</strong>I/O数据包请求到达client模块后，<strong>client根据KEY中的tree_id/branch_id进行hash计算</strong>，<strong>确定本次I/O发给哪一个OSD进程处理</strong>，确定后将I/O通过DATANET模块发给对应的OSD处理。</p><p><strong>Step4：</strong>OSD完成I/O数据收取后在物理硬盘上执行真正的读写I/O操作，然后将操作结果逐层返回返回给内核VSC.KO模块。</p><p><strong><em>备注：卷和快照的通用属性信息（如卷大小、卷名等）及卷和快照在DSware系统内部的一些私有属性（如用于定位卷和快照数据在系统中存储位置的tree_id/branch_id/snap_id）保存在DSware内部的一个私有逻辑卷中，该卷我们就称为元数据卷。</em></strong></p><h3 id="FusionStorage-OSD模块及处理流程"><a href="#FusionStorage-OSD模块及处理流程" class="headerlink" title="FusionStorage OSD模块及处理流程"></a><strong>FusionStorage OSD模块及处理流程</strong></h3><p>FusionStorage存储池管理的每个物理磁盘对应一个OSD进程，OSD进程作为FusionStorage中读写磁盘I/O的执行进程，主要实现3大功能：一是磁盘的管理；二是I/O数据流的复制；三是I/O数据流的Cache处理。</p><p><img src="https://i.loli.net/2019/06/07/5cf99972273ce79632.jpg"></p><p>如上图所示，OSD进程是一种主备方式部署的进程，由MDC模块实时监控主备OSD进程的状态。当指定Partition所在的主OSD故障时，存储服务会实时自动切换到备OSD，保证了业务的连续性。OSD进程内部主要分为RSM、SNAP、CACHE、AIO和SMIO等子进程。各类子进程的作用的如下：</p><ul><li><strong>RSM：</strong>采用复制协议实现I/O数据流的复制。</li><li><strong>SNAP：</strong>实现卷与快照的I/O功能、磁盘空间的管理。</li><li><strong>CACHE：</strong>实现cache功能。</li><li><strong>AIO：</strong>实现异步I/O数据流下发到底层SMIO模块，并且通过调用SMIO接口来监控介质故障。</li><li><strong>SMIO：**</strong>下发I/O数据流到实际的物理介质、监控物理介质故障、获取磁盘信息。**</li></ul><p>每个OSD会管理一个硬盘，系统初始化时，OSD会按照1MB为单位对硬盘进行分片管理，并在硬盘的元数据管理区域记录每个1MB分片的分配信息。OSD接收到VBS发送的I/O数据流操作后，根据key查找该数据在硬盘上的具体分片信息，获取数据后返回给VBS，从而完成整个数据路由过程。</p><p>对于写请求，OSD根据<strong>分区-主磁盘-备磁盘1-备磁盘2</strong>映射表，通知各个备磁盘的OSD进行写操作，主与备OSD进程都完成写后返回VBS。<strong>（在多副本场景下，备OSD数据由主OSD数据同步写入，避免调用VBS进程占用计算节点资源）</strong></p><p><strong>在OSD内核部分还有有一个VDB子进程（上图中VDL，新版本已改为VDB），也就是Key-Value DB数据库。如下图所示：</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf9999da7c9d70499.jpg"></p><p>磁盘的每一个1M空间都固定的分配给一个key，一定数量连续的key组成一个chunk。所谓的Chunk就是组成Partition的基本单位，一个Partition的存储空间由1个或多个Chunk构成。</p><h3 id="FusionStorage-MDC模块功能"><a href="#FusionStorage-MDC模块功能" class="headerlink" title="FusionStorage MDC模块功能"></a><strong>FusionStorage MDC模块功能</strong></h3><p><strong>MDC（Metadata Controller）是一个高可靠集群，通过HA(High Availability)机制保证整个系统的高可用性和高可靠性，如下图所示：</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf999beef1c284728.jpg"></p><p>MDC模块部署在Zookeeper集群中，通过ZooKeeper集群，实现元数据（如Topology、OSD View、Partition View、VBS View等）的可靠保存。ZK盘的配置原则为：在32台服务器内，默认选择3个独立的ZK盘（HDD）；在32~128台服务器内，默认选择5个独立ZK盘（HDD）；在多于128台服务器，默认选择5个独立ZK盘（SSD）；当使用SSD卡做主存时，选择3个ZK分区。</p><p>### </p><p>MDC模块内部通过Partition分配算法，实现数据多份副本的RAID可靠性。并且，作为FusionStorage的主控制模块，通过与OSD、VBS间的消息交互，实现对OSD、VBS节点的状态变化的获取与通知。</p><p>通过与Agent间的消息交互，MDC实现系统的扩减容、状态查询、维护等。通过心跳检测机制，MDC模块完成对OSD、VBS的状态监控。</p><p><strong>Zookeeper(简称ZK) 分布式服务框架主要用来解决分布式应用中经常遇到的，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等，ZK主要工作包括三项：</strong></p><ul><li><strong>MDC主备管理：</strong> MDC采用一主两备部署模式；在MDC模块进程启动后，各个MDC进程会向ZK注册选主，先注册的为主MDC；运行过程中，ZK记录MDC主备信息，并通过心跳机制监控MDC主备健康状况，一旦主MDC进程故障，会触发MDC重新选主。</li><li><strong>数据存储：</strong>在MDC运行过程中，会生成各种控制视图信息，包括目标视图、中间视图、IO视图信息等，<strong>这些信息的保存、更新、查询、删除操作都通过ZK提供的接口实现</strong>。</li><li><strong>数据同步：</strong>数据更新到主ZK，由主ZK自动同步到两个备ZK，保证主备ZK数据实时同步。一旦ZK发生主备切换，业务不受影响</li></ul><p><strong>在FusionStorage典型部署中，为了保证系统可靠性，ZK采用一主两备部署模式，每个管理节点部署一个ZK进程，ZK主备管理由ZK内部机制保证。</strong></p><p><strong>MDC进程与ZK进程采用C/S模式，通过TCP协议通信</strong>；MDC可以连接到任意一个ZK服务器，并且维持TCP连接。如果这个TCP连接中断，MDC能够顺利切换到另一个ZK服务器。</p><h3 id="FusionStorage中的视图"><a href="#FusionStorage中的视图" class="headerlink" title="FusionStorage中的视图"></a>FusionStorage中的视图</h3><p>如下图所示，FusionStorage中有三种视图最为关键，分别是：<strong>OSD View、IO View和Partition View。</strong></p><p><img src="https://i.loli.net/2019/06/07/5cf999f73062d18561.jpg"></p><p><strong>其中，OSD View</strong>主要记录OSD进程的ID和状态；而<strong>IO View</strong>中记录了主Partition分区ID和对应的OSD节点之间的映射关系；<strong>Partition View</strong>中记录主备Partition与OSD的对应关系。<strong>IO View是Partition View的子集。</strong></p><p><strong>MDC通过心跳感知OSD的状态，</strong>OSD每秒上报给MDC特定的消息（比如：OSD容量等），当MDC连续在特定的时间内（比如：当前系统为5s）没有接收到OSD的心跳信息，则MDC认为该OSD已经出故障（<strong>比如：OSD进程消失或OSD跟MDC间网络中断等</strong>），MDC则会发送消息告知该OSD需要退出，MDC更新系统的OSD视图信息，并给每台OSD发送视图变更通知，OSD根据新收到的视图，来决定后续的操作对象。</p><p><strong>多副本复制取决于MDC的视图</strong>；两副本情况下，当client发送一个写请求到达该OSD的时候，<strong>该OSD将根据Partition视图的信息，将该写请求复制一份到该Partition的备OSD</strong>。多副本情况下，则会复制发送多个写请求到多个备OSD上。</p><h3 id="FusionStorage-主要模块交互关系"><a href="#FusionStorage-主要模块交互关系" class="headerlink" title="FusionStorage 主要模块交互关系"></a>FusionStorage 主要模块交互关系</h3><p><img src="https://i.loli.net/2019/06/07/5cf99a1ac589f26534.jpg"></p><p><strong>Step1：**</strong>系统启动时，MDC与ZK互动决定主MDC**。主MDC与其它MDC相互监控心跳，主MDC决定某MDC故障后接替者。其它MDC发现主MDC故障又与ZK互动升任主MDC。</p><p><strong>Step2：**</strong>OSD启动时向主MDC查询归属MDC,向归属MDC报告状态，归属MDC把状态变化发送给VBS。<strong>当归属MDC故障，主MDC指定一个MDC接管，</strong>最多两个池归属同一个MDC。**</p><p><strong>Step3：**</strong>VBS启动时查询主MDC，向主MDC注册（主MDC维护了一个活动VBS的列表，主MDC同步VBS列表到其它MDC，以便MDC能将OSD的状态变化通知到VBS），向MDC确认自己是否为leader<strong>；</strong>VBS从主MDC获取IO View<strong>，</strong>主VBS向OSD获取元数据，其它VBS向主VBS获取元数据**。</p><p>FusionStorage系统中会存在多个VBS进程，如果多个VBS同时操作元数据卷，会引起数据被写坏等问题。<strong>为避免该问题，FusionStorage系统对VBS引入了主备机制，只有主VBS可操作元数据卷，所有的备VBS不允许操作元数据卷</strong>，<strong>一套FusionStorage系统中只存在一个主VBS</strong>；VBS的主备角色由MDC进程确定，所有VBS通过和MDC间的心跳机制保证系统中不会出现双主的情况。</p><p><strong>只有主VBS能够操作元数据，所以备VBS收到的卷和快照管理类命令需要转发到主VBS处理，对于挂载、卸载等流程，主VBS完成元数据的操作后，还需要将命令转到目标VBS实现卷的挂载、卸载等操作。</strong></p><h2 id="FusionStorage的I-O读写流程"><a href="#FusionStorage的I-O读写流程" class="headerlink" title="FusionStorage的I/O读写流程"></a><strong>FusionStorage的I/O读写流程</strong></h2><h3 id="FusionStorage-Cache读机制"><a href="#FusionStorage-Cache读机制" class="headerlink" title="FusionStorage Cache读机制"></a><strong>FusionStorage Cache读机制</strong></h3><p>FusionStorage的<strong>读缓存采用分层机制</strong>，第一层为内存cache，内存cache采用LRU机制缓存数据。第二层为SSD cache，SSD cache采用热点读机制，系统会统计每个读取的数据，并统计热点访问子，当达到阈值时，系统会自动缓存数据到SSD中，同时会将长时间未被访问的数据移出SSD。FusionStorage预读机制，统计读数据的相关性，读取某块数据时自动将相关性高的块读出并缓存到SSD中。</p><p><img src="https://i.loli.net/2019/06/07/5cf99a60c14b049375.jpg"></p><p><strong>如上图所示，OSD收到VBS发送的读I/O操作的步骤处理：</strong></p><p><strong>Step 1：</strong>从<strong>“内存读cache”</strong>中查找是否存在所需I/O数据，存在则直接返回，并调整该I/O数据到“<strong>读cache”LRU队首</strong>，否则执行Step 2；</p><p><strong>Step 2：</strong>从<strong>“SSD的读cache”</strong>中查找是否存在所需I/O数据，存在则直接返回，并增加该I/O数据的热点访问因子，否则执行Step 3；</p><p><strong>Step 3：</strong>从<strong>“SSD的写cache”</strong>中查找是否存在所需I/O数据，存在则直接返回，并增加该I/O数据的热点访问因子；如果热点访问因子达到阈值，则会被缓存在<strong>“SSD的读cache”</strong>中。如果不存在，执行Step 4；</p><p><strong>Step 4：</strong>从硬盘中查找到所需I/O数据并返回，同时增加该I/O数据的热点访问因子，如果热点访问因子达到阈值，则会被缓存在<strong>“SSD的读cache”</strong>中；</p><p><strong>读修复：</strong>在读数据失败时，系统会判断错误类型，如果是磁盘扇区读取错误，系统会自动从其他节点保存的副本读取数据，然后重新写入该副本数据到硬盘扇区错误的节点，从而保证数据副本总数不减少和副本间的数据一致性。</p><h3 id="FusionStorage-Cache写机制"><a href="#FusionStorage-Cache写机制" class="headerlink" title="FusionStorage Cache写机制"></a>FusionStorage Cache写机制</h3><p>OSD在收到VBS发送的写I/O操作时，会将写I/O缓存在SSD cache后完成本节点写操作。OSD会周期性地将缓存在SSD cache中的写I/O数据批量写入到硬盘，写Cache有一个水位值，未到刷盘周期超过设定水位值也会将Cache中数据写入到硬盘中。</p><p><img src="https://i.loli.net/2019/06/07/5cf99a8a5198479125.jpg"></p><p><strong>FusionStorage支持将服务器部分内存用作读缓存，NVDIMM和SSD用作写缓存。并且支持大块直通，按缺省配置大于256KB的块直接落盘不写Cache，这个配置可以人为修改。</strong></p><h3 id="FusionStorage-读I-O流程"><a href="#FusionStorage-读I-O流程" class="headerlink" title="FusionStorage 读I/O流程"></a><strong>FusionStorage 读I/O流程</strong></h3><p><img src="https://i.loli.net/2019/06/07/5cf99aa4c463820797.jpg"></p><p><strong>Step1：</strong>APP下发读IO请求到OS，OS转发该IO请求到本服务器的VBS模块；VBS根据读I/O信息中的LUN和LBA信息，通过数据路由机制确定数据所在的Primary OSD；如果此时Primary OSD故障，VBS会选择secondary OSD读取所需数据。</p><p><strong>Step2：</strong>Primary OSD接收到读I/O请求后，按照Cache机制中的“<strong>Read cache机制</strong>”获取到读I/O所需数据，并返回读I/O成功给VBS。</p><h3 id="FusionStorage-写I-O流程"><a href="#FusionStorage-写I-O流程" class="headerlink" title="FusionStorage 写I/O流程"></a><strong>FusionStorage 写I/O流程</strong></h3><p><img src="https://i.loli.net/2019/06/07/5cf99aca30dfa92476.jpg"></p><p><strong>Step1：</strong>APP下发写I/O请求到OS，OS转发该I/O请求到本服务器的VBS模块；VBS根据写I/O信息中的LUN和LBA信息，通过数据路由机制确定数据所在的Primary OSD。</p><p><strong>Step2：</strong>Primary OSD接收到写I/O请求后，同时以同步方式写入到本服务器SSD cache以及数据副本所在其他服务器的secondary OSD，secondary OSD也会同步写入本服务器SSD cache。Primary OSD接收到两个都写成功后，返回写I/O成功给VBS；同时，SSD cache中的数据会异步刷入到硬盘。</p><p><strong>Step3：</strong>VBS返回写I/O成功，如果是3副本场景，primary OSD会同时同步写I/O操作到secondary OSD和third OSD。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;华为FusionStorage中的基础概念&quot;&gt;&lt;a href=&quot;#华为FusionStorage中的基础概念&quot; class=&quot;headerlink&quot; title=&quot;华为FusionStorage中的基础概念&quot;&gt;&lt;/a&gt;华为FusionStorage中的基础概念&lt;/h2&gt;&lt;p&gt;FusionStorage采用全分布式DHT架构，将&lt;strong&gt;所有元数据按规则分布在各存储节点，不存在跨节点的元数据访问&lt;/strong&gt;，彻底避免了元数据瓶颈。该核心架构设计保证了FusionStorage系统相比分布式文件系统具备更大规模的线性扩展能力。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-06-03-华为分布式存储FusionStorage概述</title>
    <link href="https://kkutysllb.cn/2019/06/03/2019-06-03-%E5%8D%8E%E4%B8%BA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8FusionStorage%E6%A6%82%E8%BF%B0/"/>
    <id>https://kkutysllb.cn/2019/06/03/2019-06-03-华为分布式存储FusionStorage概述/</id>
    <published>2019-06-03T02:54:41.000Z</published>
    <updated>2019-06-03T03:13:46.998Z</updated>
    
    <content type="html"><![CDATA[<p>分布式存储基于通用的x86服务器，通过分布式的存储软件来构建存储系统，开放丰富灵活的软件义 策略和接口，允许管理员和租户进行自动化的系统管理和资源调度发放。业界的分布式存储，有多种形态，包括<strong>分布式块存储、分布式文件存储、分布式对象存储</strong>。各大存储厂商都由自己的解决方案，而开源的代表的就是ceph。考虑到电信云NFV领域的应用特性和相关设备商分布，我们这里主要介绍华为的分布式存储系统FusionStorage。<a id="more"></a></p><h2 id="传统SAN架构"><a href="#传统SAN架构" class="headerlink" title="传统SAN架构"></a>传统SAN架构</h2><p>在传统的IT行业和电信云早期时候，计算和存储是分离的，计算由各种x86服务器组成计算集群，存储由各种SAN/NAS组成存储集群，这种分离架构虽然通过多个计算实例共享相同存储，在计算节点发生故障后，无须耗时的外存 数据迁移，即可快速在其他计算节点上恢复故障应用。但是，<strong>这种传统存储资源缺乏共享。</strong>因为，传统存储设备和资源往往由不同厂家提供，之间无法进行资源共享，数据中心看到的是一个个孤立的存储资源。如下图所示。</p><p><img src="https://i.loli.net/2019/06/03/5cf48c6cc124549810.jpg"></p><p>而且，SAN机头成为制约系统扩展的单点瓶颈。因为，随着计算集群规模的不断扩展，由于存储资源池集中式控制机头的存在，使得共享存储系统的<strong>扩展性、性能加速、可靠性</strong>受到制约。比如：采用多个SAN系统，单个SAN系统的机头最多由双控扩展到16控，不同的SAN系统独立管理无法组成集群。各计算节点只能依赖于集中式机头内的缓存实现I/O加速，但由于各节点cache有限，且不共享导致cache的I/O缓存加速只能达到GB级别。尽管SAN控制机头自身具有主备机制，但依然存在异常条下主备同时故障的可能性。</p><p><strong>在传统SAN存储系统中，一般采用集中式元数据管理方式</strong>，元数据中会记录所有LUN中不同偏移量的数据在硬盘中的分布，例如LUN1+LBA1地址起始的4KB长度的数据分布在第32块硬盘的LBA2上。<strong>每次I/O操作都需要去查询元数据服务，随着系统规模逐渐变大，元数据的容量也会越来越大，系统所能提供的并发操作能力将受限于元数据服务所在服务器的能力，元数据服务将会成为系统的性能瓶颈。</strong></p><h2 id="什么是Server-SAN"><a href="#什么是Server-SAN" class="headerlink" title="什么是Server SAN?"></a><strong>什么是Server SAN?</strong></h2><p>为了解决上述问题，业界针对大多数企业事务型IT应用而言，提出信息数据的“ 即时处理” 理念，通过计算和存储融合，<strong>引入scale-out存储机制</strong>，也就出现了<strong>Server SAN</strong>的概念。<strong>所谓Server SAN就是由多个独立服务器自带的存储组成一个存储资源池，同时融合了计算和存储资源</strong>。scale-out的存储架构示意图如下：</p><p><img src="https://i.loli.net/2019/06/03/5cf48c994721e73916.jpg"></p><p><strong>以数据中心级资源共享为例，</strong>一个数据中心内可以构建一个很大的存储资源池，如下图所示，满足数据中心内各类应用对存储容量，性能和可靠性的需求，实现资源共享和统一管理。</p><p><img src="https://i.loli.net/2019/06/03/5cf48cae5829479983.jpg"></p><p>通过在各个计算节点引入分布式控制器VBS，这是一种软件控制机头，线性扩展能力最大到4096个节点。而且，利用各个计算节点的cache组成分布式cache集群，满配情况下可达到TB级别的cache缓存能力。同时，各计算节点存储平面的存储网卡可采用专用IB接口卡，可以实现P2P的无阻赛传输网络，可达到100Gbps的数据传输能力。</p><p><strong>最重要的是，采用分布式软件存储方式属于软件定义存储SDS的范畴，通过将控制面数据抽象和解耦，可与厂商的专有存储硬件解耦，底层的专有存储设备变为通用设备，实现简单统一管理和线性扩展。</strong>以华为FusionStorage为例，由于其采用的DHT算法（分布式哈希表结构，后面会详细讲），不仅数据能够尽可能分布到所有的节点中，可以使得所有节点负载均衡，现有节点上的数据不需要做很大调整实现<strong>数据均衡性</strong>，而且当有新节点加入系统中，系统会重新做数据分配，数据迁移仅涉及新增节点，从而实现数据修改的<strong>单调性</strong>。</p><h2 id="分布式存储池的概念"><a href="#分布式存储池的概念" class="headerlink" title="分布式存储池的概念"></a>分布式存储池的概念</h2><p>分布式存储系统把所有服务器的本地硬盘组织成若干个资源池，基于资源池提供创建/删除应用卷（Volume）、创建/删除快照等接口，为上层软件提供卷设备功能。分布式存储系统资源池示意图如下，具有以下特点。</p><p><img src="https://i.loli.net/2019/06/03/5cf48cd17f44718707.jpg"></p><p>每块硬盘分为若干个数据分片<strong>（Partition）</strong>，每个Partition只属于一个资源池，Partition是数据多副本的基本单位，也就是说多个数据副本指的是多个Partition，如上图中的Pn色块。 系统自动保证多个数据副本尽可能分布在不同的服务器上（服务器数大于数据副本数时）。系统自动保证多个数据副本间 的数据强一致性（所谓强一致性是指无论读还是写I/O，都要进行数据一致性检查）。Partition中的数据以Key-Value的方式存储。对上层应用呈现并提供卷设备（Volume），没有LUN的概念，使用简单。系统自动保证每个硬盘上的主用Partition和备用Partition数量相当，避免出现集中的热点。所有硬盘都可以用做资源池的热备盘，单个资源池最大支持数百上千块硬盘。</p><p>分布式存储系统采用<strong>分布式集群控制技术</strong>和<strong>分布式Hash数据路由</strong>技术，提供分布式存储功能特性。这里的概念比价抽象，所以下面结合华为FusionStorage的具体情况进行介绍。</p><h2 id="华为FusionStorage分布式存储概述"><a href="#华为FusionStorage分布式存储概述" class="headerlink" title="华为FusionStorage分布式存储概述"></a>华为FusionStorage分布式存储概述</h2><p>FusionStorage通过创新的架构把分散的、低速的SATA/SAS机械硬盘组织成一个高效的类SAN存储池设备，提供比SAN设备更高的I/O，如下图所示：</p><p><img src="https://i.loli.net/2019/06/03/5cf48ced3ac0154311.jpg"></p><p>集群内各服务器节点的硬盘使用独立的I/O带宽，不存在独立存储系统中大量磁盘共享计算设备和存储设备之间有限带宽的问题。其将服务器部分内存用做读缓存，NVDIMM用做写缓存，数据缓存均匀分布到各个节点 上，所有服务器的缓存总容量远大于 采用外置独立存储的方案。即使采用大容量低成本的SATA硬盘，分布式存储系统仍然可以发挥很高的I/O性能，整体性能提升1～3倍，同时提供更大的有效容量。</p><p>由于其采用<strong>无状态的分布式软件机头</strong>，机头部署在各个服务器上，无集中式机头的性能瓶颈。单个服务器上软件机头只占用较少的CPU资源，提供比集中式机头更高的IOPS和吞吐量。例如：假设系统中有20台服务器需要访问FusionStorage提供的存储资源，每台服务器提供给存储平面的带宽为2<em>10Gb，我们在每台服务器中部署1个VBS模块（相当于在每台服务器中部署1个存储机头），20台服务器意味着可部署20个存储机头，所能获取到的总吞吐量最高可达20</em>2*10Gb=400Gb，随着集群规模的不断扩大，<strong>可以线性增加的存储机头，突破了传统的双控或者多控存储系统集中式机头的性能瓶颈。</strong></p><p>华为FusionStorage是一种软件定义存储SDS技术，将通用X86服务器的本地HDD、SSD等介质通过分布式技术组织成大规模存储资源池。同时，以开放API的方式对非虚拟化环境的上层应用和虚拟机提供工业界标准的SCSI和iSCSI接口。关键一点是，华为官方自己吹牛逼的的口号—-<strong>FusionStorage是目前唯一商用支持PB级数据吞吐/存储能力的Server SAN产品。</strong></p><p>华为FusionStorage主要应用于两种场景，如下图所示，而中国移动的电信云NFV领域的应用属于第一种场景。</p><p><img src="https://i.loli.net/2019/06/03/5cf48d0aa74ae86247.jpg"></p><p><strong>场景一：与主流云平台的集成，构建云资源池中的存储资源池。</strong>可以和各种云平台集成，如华为FusionSphere、VMware、开源Openstack等，按需分配存储资源。</p><p><strong>场景二：提供传统的存储应用，</strong>如各种业务应用(如SQL、Oracle RAC、Web、行业应用等等)。</p><p>因此，华为FusionStorage是一种<strong>开发兼容</strong>的系统，可以兼容各种主流数据库、各种主流虚拟化平台以及各种主流服务器。同时，<strong>支持虚拟化平台和数据库资源池融合部署</strong>，即共用一个数据中心内的FusionStorage存储资源池。<strong>华为FusionStorage的软硬件兼容性总结如下：</strong></p><p><img src="https://i.loli.net/2019/06/03/5cf48d26bece826299.jpg"></p><p><strong>硬件兼容性主要包括：</strong>服务器、各种HDD盘，SSD盘，PCIE SSD卡/盘以及各种RAID卡，以太网卡， Infiniband卡等。</p><p><strong>软件兼容性主要包括：</strong>各种虚拟化平台、各种操作系统以及各种数据库软件。</p><p>而且，FusionStorage支持使用SSD替代HDD作为高速存储设备，支持使用<strong>Infiniband网络</strong>替代GE/10GE网络提供更高的带宽，为对性能要求极高的大数据量实时处理场景提供完美的支持<strong>千万级IOPS</strong>。InfiniBand（直译为“无限带宽”技术，缩写为IB）是一个用于高性能计算的计算机网络通信标准，它具有极高的吞吐量和极低的延迟，用于计算机与计算机之间的数据互连。InfiniBand也用作服务器与存储系统之间的直接或交换互连，以及存储系统之间的互连。硬件接口图如下：</p><p><img src="https://i.loli.net/2019/06/03/5cf48d3c621c526479.jpg"></p><p><strong>inifiniband接口可以实现链路可聚合：</strong>大多数系统使用一个4X聚合。12X链路通常用于计算机集群和超级计算机互连，以及用于内部网络交换器连接。而且，<strong>InfiniBand也提供远程直接内存访问（RDMA）能力以降低CPU负载。除了板式连接，它还支持有源和无源铜缆（最多30米）和光缆（最多10公里）。通过Inifiniband Association可以指定CXP铜连接器系统，</strong>用于通过铜缆或有源光缆达到高达传输速率<strong>120Gbps</strong>的能力。</p><p><strong>FusionStorage的技术规格参数表如下：</strong></p><table><thead><tr><th><strong>集群指标</strong></th><th><strong>规格</strong></th><th><strong>卷规格指标</strong></th><th><strong>规格</strong></th></tr></thead><tbody><tr><td>单集群存储服务器数量</td><td>4,096个</td><td>集群最大卷数量</td><td>1,280,000个</td></tr><tr><td>单集群硬盘数量</td><td>49,152个</td><td>单资源池最大卷数量</td><td>65,000个</td></tr><tr><td>单集群支持的计算节点数量</td><td>10,240个</td><td>卷容量</td><td>64MB～256TB</td></tr><tr><td>单集群最大资源池数量</td><td>128个</td><td>卷最大共享主机数量</td><td>128个</td></tr><tr><td><strong>资源池规格指标</strong></td><td><strong>规格</strong></td><td>每个主机最大挂载卷数量</td><td>512个</td></tr><tr><td>单资源池的硬盘数量</td><td>两副本（HDD或SSD）：12个～96个三副本（HDD或SSD）：12个～2,048个</td><td>共享卷最大数量</td><td>20,000个</td></tr><tr><td>单资源池的存储服务器数量</td><td>两副本（HDD或SSD）：3个～16个三副本（HDD或SSD）：4个～256个</td><td>单个卷最大快照数量</td><td>无限制，快照总数不超过1,280,000个</td></tr><tr><td>单资源池的机柜数量</td><td>非跨机柜数据安全：1个～12个跨机柜数据安全：3个～12个</td><td>单个卷最大链接克隆数量</td><td>2,048个</td></tr><tr><td>单个服务器最多可划分的资源池数量</td><td>3个</td><td>同步复制卷的最大数量</td><td>4,096个</td></tr><tr><td><strong>iSCSI接口协议指标</strong></td><td><strong>规格</strong></td><td>同步复制卷的最大容量</td><td>2TB</td></tr><tr><td>iSCSI CHAP用户最大数量</td><td>1,024个</td><td>每个主机支持的同步复制卷的总容量</td><td>64TB</td></tr><tr><td>iSCSI卷最大扩容容量</td><td>256TB</td><td></td></tr></tbody></table><h2 id="FusionStorage逻辑架构"><a href="#FusionStorage逻辑架构" class="headerlink" title="FusionStorage逻辑架构"></a>FusionStorage逻辑架构</h2><p>在中国移动电信云NFV中，<strong>主要使用分布式块存储</strong>，华为FusionStorage Block的解决方案将通用X86存储服务器池化，建立大规模块存储资源池，提供标准的块存储数据访问接口（SCSI和iSCSI等）。支持各种虚拟化Hypervisor平台和各种业务应用(如SQL、Web、行业应用等等)，可以和各种云平台集成，如华为FusionSphere、VMware、开源Openstack等，按需分配存储资源。如下图所示：</p><p><img src="https://i.loli.net/2019/06/03/5cf48d675d71079948.jpg"></p><p>同时，FusionStorage Block通过及SSD做Cache，构建内存—缓存（SSD)—主存（HDD/SAS/SATA)三级存储等关键技术，将存储系统的性能和可靠性得到极大的提高。</p><p>如下图所示，华为FusionStorage的逻辑架构中，按照管理角色和代理角色分为FSM和FSA两类进程，在代理进程内部按照数据管理、I/O控制和数据读写进一步细分为MDC、VBS和OSD三个子进程，各类软件逻辑模块的功能解释如下：</p><p><img src="https://i.loli.net/2019/06/03/5cf48d7c334b591527.jpg"></p><p><strong>FSM（FusionStorage Manager）：</strong>FusionStorage管理模块，<strong>提供告警、监控、日志、配置</strong>等操作维护功能。一般情况下<strong>FSM通过管理虚机主备节点部署</strong>，不考虑资源利用率的场景下，也可以使用物理服务器主备部署。</p><p><strong>FSA（FusionStorage Agent）：</strong>代理进程，部署在各节点上，实现各节点与FSM通信。FSA包含<strong>MDC、VBS</strong>和<strong>OSD</strong>三类不同的子进程。根据系统不同配置要求，分别在不同的节点上启用不同的进程组合来完成特定的功能。比如：单纯存储节点只需要部署OSD子进程，用于构建虚拟存储池。计算和存储融合节点，不仅需要部署OSD进程，还需部署VBS进程，用于控制数据读写I/O。</p><p><strong>MDC（MetaData Controller）：</strong>负责整个分布式存储集群的的元数据控制，实现对<strong>分布式集群的状态控制</strong>，以及<strong>控制数据分布式规则</strong>、<strong>数据重建规则</strong>等。 MDC是整个分布式存储集群的核心，通过MDC模块才能找到数据的具体存储位置，知悉存储副本的数量，分布和大小。因此，MDC子进程必须采用高可用HA的方式部署，默认情况下，是部署在3个节点的<strong>ZK(Zookeeper)盘上</strong>，形成MDC集群。</p><p><strong>VBS（Virtual Block System）：</strong>虚拟块存储管理组件，负责<strong>卷元数据的管理</strong>，也就是我们俗称的”软件机头“。VBS子进程提供分布式集群接入点服务，使计算资源能够通过VBS访问分布式存储资源。VBS上存储的是虚拟机虚拟磁盘卷的元数据，用于描述虚拟卷在OSD的位置，分布和大小等。凡是融合计算资源的节点，<strong>每个节点上默认部署一个VBS进程，形成VBS集群</strong>，由于VBS从OSD读取数据时可以并发，所以节点上也可以通过部署多个VBS来提升IO性能。</p><p><strong>OSD（Object Storage Device）：</strong>对象存储设备服务子进程，执行具体的I/O操作。<strong>在每个存储节点服务器上可以部署多个OSD进程。一般情况下，存储服务器上的一块本地磁盘默认对应部署一个OSD进程</strong>。如果使用大容量SSD卡作主存，为了充分发挥SSD卡的性能，可以在1张SSD卡上部署多个OSD进程进行管理，例如2.4TB的SSD卡可以部署6个OSD进程，每个OSD进程负责管理400GB存储空间。</p><h2 id="FusionStorage部署方式"><a href="#FusionStorage部署方式" class="headerlink" title="FusionStorage部署方式"></a><strong>FusionStorage部署方式</strong></h2><p>在中国移动电信云NFV解决方案中，无论软件由哪家厂商提供，虚拟化Hypervisor都是采用KVM来实现，区别只是不同厂商在开源KVM中私有增强或加固。华为FusionStorage Block支持XEN/KVM之类的Linux开放体系的Hypervisor场景，包括华为基于XEN/KVM增强的FusionSphere UVP虚拟化平台，和非华为的XEN/KVM虚拟化平台。在XEN/KVM的虚拟化场景下，FusionStorage Block既支持计算存储融合的部署模式，又支持计算存储分离的部署模式。</p><p><strong>所谓融合部署，</strong>就是指计算与存储的融合部署方式，也就是说将应用或虚拟机与存储在集群范围内部署在同一台服务器上。如下图所示：</p><p><img src="https://i.loli.net/2019/06/03/5cf48dabce4eb19183.jpg"></p><p>融合部署对应到FusionStorage的逻辑架构中，就是指的是<strong>将VBS和OSD部署在同一台服务器中</strong>。这种部署方式提升了资源利用率，虽然一定意义上增加了计算节点服务器的CPU开销，但是通过分布式存储软件策略，可以满足数据就近读写，提升I/O转发性能，同时数据副本异地存放，满足数据存储可靠性。在电信云NFV中，<strong>对时延较敏感的业务控制数据应用虚机推荐采用融合部署的方式部署。</strong></p><p><strong>所谓分离部署，顾名思义就是将</strong>计算与存储的分开部署，也就是将业务虚拟机与存储部署在不同的服务器上。如下图所示：</p><p><img src="https://i.loli.net/2019/06/03/5cf48dc0b8e4d39512.jpg"></p><p>分离部署对应到FusionStorage的逻辑架构中，就是将VBS和OSD分别部署在不同的服务器中，其中存储节点服务器只部署OSD子进程，计算节点服务器只部署VBS子进程。计算节点通过存储网络完成存储节点上数据的I/O读写，<strong>一般高性能数据库应用因为需要对数据进行计算，推荐采用分离部署的方式</strong>。但是，这种部署方式在I/O转发性能略差于融合部署。采用分离部署时，<strong>存储节点服务器Host OS可以采用通用的Linux OS操作系统，这就为后续分布式存储解耦提供了基础。</strong></p><h2 id="FusionStorage数据可靠性"><a href="#FusionStorage数据可靠性" class="headerlink" title="FusionStorage数据可靠性"></a>FusionStorage数据可靠性</h2><h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a><strong>集群管理</strong></h3><p>华为分布式存储FusionStorage的分布式存储软件采用集群管理方式，规避单点故障，一个节点或者一块硬盘故障自动从集群内隔离出来，不影响整个系统业务的使用。集群内选举进程Leader，Leader负责数据存储逻辑的处理，当Leader出现故障，系统自动选举其他进程成为新的Leader。</p><p><img src="https://i.loli.net/2019/06/03/5cf48de4e92a242186.jpg"></p><h3 id="多数据副本"><a href="#多数据副本" class="headerlink" title="多数据副本"></a><strong>多数据副本</strong></h3><p>华为分布式存储FusionStorage中没有使用传统的RAID模式来保证数据的可靠性（实际采用的RAID2.0+技术），而是采用了多副本备份机制，即<strong>同一份数据可以复制保存多个副本</strong>。<strong>在数据存储前，对数据打散进行分片，分片后的数据按照一定的规则保存集群节点上。</strong>如下图所，FusionStorage采用数据多副本备份机制来保证数据的可靠性，即同一份数据可以复制保存为2~3个副本。</p><p><img src="https://i.loli.net/2019/06/03/5cf48dfbc9ce645690.jpg"></p><p>FusionStorage针对系统中的每个卷，默认按照<strong>1MB</strong>进行分片，分片后的数据按照DHT算法保存集群节点上。如上图所示，对于服务器Server1的 磁盘Disk1上的数据块P1，它的数据备份为服务器Server2的磁盘Disk2上P1’，P1和P1’构成了同一个数据块的两个副本。当P1所在的硬盘故障时，P1’可以继续提供存储服务。</p><p><strong>数据分片分配算法保证了主用副本和备用副本在不同服务器和不同硬盘上的均匀分布，换句话说，每块硬盘上的主用副本和备副本数量是均匀的。扩容节点或者故障减容节点时，数据恢复重建算法保证了重建后系统中各节点负载的均衡性。</strong></p><p>### </p><h3 id="数据一致性和弹性扩展"><a href="#数据一致性和弹性扩展" class="headerlink" title="数据一致性和弹性扩展"></a><strong>数据一致性和弹性扩展</strong></h3><p><strong>数据一致性的要求是：当应用程序成功写入一份数据时，后端的几个数据副本必然是一致的，当应用程序再次读取时，无论在哪个副本上读取，都是之前写入的数据，这种方式也是绝大部分应用程序希望的。保证多个数据副本之间的数据一致性是分布式存储系统的重要技术点。</strong>华为分布式存储FusionStorage采用<strong>强一致性复制技术确保各个数据副本的一致性，一个副本写入，多个副本读取。</strong> 如下图所示，</p><p><img src="https://i.loli.net/2019/06/03/5cf48e16e330d10346.jpg"></p><p>存储资源池支持多种安全级别，采用强一致性复制协议，冗余策略按需灵活配置、部署。当采用机柜级冗余时，能同时容忍2或3个机柜失效；当采用节点级冗余时，能同时容忍2或3个节点失效。</p><p>FusionStorage还支持Read Repair机制。Read Repair机制是指在读数据失败时，会判断错误类型，如果是磁盘扇区读取错误，可以通过从其他副本读取数据，然后重新写入该副本的方法进行恢复，从而保证数据副本总数不减少。</p><p>同时，FusionStorage的分布式架构具有良好的可扩展性，支持超大容量的存储。如下图所示，<strong>扩容存储节点后不需要做大量的数据搬迁，系统可快速达到负载均衡状态。</strong></p><p><img src="https://i.loli.net/2019/06/03/5cf48e2d58d2b67146.jpg"></p><p>FusionStorage支持灵活扩容方式，不仅支持计算节点、硬盘、存储节点单类性扩容，而且支持同时进行扩容。由于软件机头、存储带宽和Cache都均匀分布到各个节点上，系统IOPS、吞吐量和Cache随着节点扩容线性增加，理论上计算节点和存储节点越多，FusionStorage的性能越强。</p><h3 id="快速数据重建"><a href="#快速数据重建" class="headerlink" title="快速数据重建"></a><strong>快速数据重建</strong></h3><p>分布式存储系统内部需要具备强大的数据保护机制。数据存储时被分片打散到多个节点上，这些分片数据支持分布在不同的存储节点、不同的机柜之间，同时数据存储时采用多副本技术，数据会自动存多份，每一个分片的不同副本也被分散保存到不同的存储节点上。在硬件发生故障导致数据不一致时，分布式存储系统通过内部的自检机制，通过比较不同节点上的副本分片，自动发现数据故障。发现故障后启动数据修复机制，在后台修复数据。如下图所示为华为FusionStorage的数据重建过程示意图。</p><p><img src="https://i.loli.net/2019/06/03/5cf48e4357cce64262.jpg"></p><p>FusionStorage中的<strong>每个硬盘都保存了多个DHT分区（Partition）</strong>，这些分区的副本按照策略分散在系统中的其他节点。当FusionStorage检测到硬盘或者节点硬件发生故障时，自动在后台启动数据修复。</p><p>由于分区的副本被分散到多个不同的存储节点上，数据修复时，<strong>将会在不同的节点上同时启动数据重建，每个节点上只需重建一小部分数据，多个节点并行工作，有效避免单个节点重建大量数据所产生的性能瓶颈，对上层业务的影响做到最小化。</strong></p><p>### </p><h3 id="掉电保护"><a href="#掉电保护" class="headerlink" title="掉电保护"></a><strong>掉电保护</strong></h3><p>分布式存储系统运行过程中可能会出现服务器突然下电的情况，此时在内存中的元数据和写缓存数据会随着掉电而丢失，需要使用非易失存储介质来保存和恢复元数据和缓存数据。 华为FusionStorage支持的保电介质为NVDIMM内存条或SSD。如下图所示，程序运行过程中会把元数据和缓存数据写入保电介质中，节点异常掉电并重启后，系统自动恢复保电介质中的元数据和缓存数据。</p><p><img src="https://i.loli.net/2019/06/03/5cf48e5a8ca0983577.jpg"></p><p>部署FusionStorage时，要求每一台服务器配备NVDIMM内存条或SSD盘，服务器掉电时会把元数据和缓存数据写入NVDIMM的Flash或SSD盘中，上电后又会把Flash中的数据还原到内存中。FusionStorage能够自动识别出系统中的NVDIMM内存，并把需要保护的数据按照内部规则存放在NVDIMM中，用于提供掉电保护功能。</p><h2 id="FusionStorage的特性"><a href="#FusionStorage的特性" class="headerlink" title="FusionStorage的特性"></a>FusionStorage的特性</h2><p>FusionStorage分布式存储软件总体框架如下所示，由<strong>存储管理模块、存储接口层、存储服务层</strong>和<strong>存储引擎层</strong>4类组成。</p><p><img src="https://i.loli.net/2019/06/03/5cf48e853b2db26201.jpg"></p><h3 id="FusionStorage块存储功能-SCSI-iSCSI块接口"><a href="#FusionStorage块存储功能-SCSI-iSCSI块接口" class="headerlink" title="FusionStorage块存储功能 - SCSI/iSCSI块接口"></a>FusionStorage块存储功能 - SCSI/iSCSI块接口</h3><p>FusionStorage通过VBS以SCSI或iSCSI方式提供块接口。当采用SCSI方式时，安装VBS的物理服务器、FusionSphere或KVM等采用SCSI接口（带内方式）；当采用iSCSI方式时，安装VBS以外的虚拟机或主机提供存储访问，VMware、MS SQL Server集群采用iSCSI模式（带外方式）。</p><p><img src="https://i.loli.net/2019/06/03/5cf48e9f11eee84034.jpg"></p><p>使用SCSI存储接口时，支持<strong>快照、快照备份、链接克隆</strong>功能，iSCSI暂不支持前述特性。对于iSCSI协议的支持是通过VBS提供iSCSI Target，块存储使用方通过本机的Initiator与iSCSI Target联接来访问存储。FusionStorage支持以下两种安全访问的标准：<strong>CHAP身份验证</strong>和<strong>LUN MASKING给Host对Lun的访问进行授权。</strong></p><h3 id="FusionStorage精简配置功能"><a href="#FusionStorage精简配置功能" class="headerlink" title="FusionStorage精简配置功能"></a><strong>FusionStorage精简配置功能</strong></h3><p>相比传统方式分配物理存储资源，精简配置可显著提高存储空间利用率。FusionStorage天然支持自动精简配置，和传统SAN相比不会带来性能下降。</p><p><img src="https://i.loli.net/2019/06/03/5cf48eb9d887d74962.jpg"></p><p>当用户对卷进行写操作时，系统才分配实际物理空间，FusionStorage Block仅处理虚拟卷空间和实际物理空间之前的映射关系，对性能无影响。</p><h3 id="FusionStorage快照功能"><a href="#FusionStorage快照功能" class="headerlink" title="FusionStorage快照功能"></a>FusionStorage快照功能</h3><p>FusionStorage快照机制，将用户卷数据在某个时间点的状态保存下来，可用作导出数据、恢复数据之用。FusionStorage Block快照数据基于DHT机制，数据在存储时采用ROW（Redirect-On-Write）机制，快照不会引起原卷性能下降。比如：针对一块容量为2TB的硬盘，完全在内存中构建索引需要24MB空间，通过一次Hash查找即可判断有没有做过快照，以及最新快照的存储位置，效率很高。</p><p><img src="https://i.loli.net/2019/06/03/5cf48ed84814c85259.jpg"></p><ul><li><strong>无限次快照：</strong>快照元数据分布式存储，水平扩展，无集中式瓶颈，理论上可支持无限次快照。</li><li><strong>卷恢复速度快：</strong>无需数据搬迁，从快照恢复卷1S内完成（传统SAN在几小时级别）。</li></ul><h3 id="FusionStorage链接克隆功能"><a href="#FusionStorage链接克隆功能" class="headerlink" title="FusionStorage链接克隆功能"></a><strong>FusionStorage链接克隆功能</strong></h3><p>FusionStorage支持一个卷快照创建多个克隆卷，对克隆卷修改不影响原始快照和其它克隆卷。克隆卷继承普通卷所有功能，即克隆卷可支持创建快照、从快照恢复及作为母卷再次克隆操作。</p><p><img src="https://i.loli.net/2019/06/03/5cf48f00b449b43091.jpg"></p><ul><li><strong>支持批量进行虚拟机卷部署，在1秒时间内创建上百个虚拟机卷。</strong></li><li><strong>支持1:2048的链接克隆比，提升存储空间利用率。</strong></li></ul><h3 id="FusionStorage-Block卷迁移"><a href="#FusionStorage-Block卷迁移" class="headerlink" title="FusionStorage Block卷迁移"></a><strong>FusionStorage Block卷迁移</strong></h3><p>为了存储池之间的容量平衡，FusionStorage支持将容量满的池迁移到一个空闲的池。或者，为了改变卷的性能，FusionStorage支持卷在不同性能的池之间的迁移，从低性能的池向高性能的池迁移。这就是卷迁移使用的场景，在FusionStorage中，由于迁移过程中，源卷不能有写数据的操作，所以这种迁移属于<strong>冷迁移。</strong></p><p><img src="https://i.loli.net/2019/06/03/5cf48f259c14a69801.jpg"></p><p><strong>步骤：</strong></p><p>【创建目标卷】&gt;&gt;&gt;【卷数据复制】&gt;&gt;&gt;【删除源卷】&gt;&gt;&gt;【目标卷改名】&gt;&gt;&gt;【完成】</p><h3 id="FusionStorage-Block双活"><a href="#FusionStorage-Block双活" class="headerlink" title="FusionStorage Block双活"></a><strong>FusionStorage Block双活</strong></h3><p><img src="https://i.loli.net/2019/06/03/5cf48f45d4d4965748.jpg"></p><p>基于AB两个数据中心的两套FusionStorage Block集群构建双活容灾关系，基于两套FusionStorage的卷虚拟出一个双活卷，两数据中心业务的主机能同时进行读写服务。任意数据中心故障，数据零丢失，业务能迅速切换到另外一个站点运行，保证业务连续型。</p><p>在原有基础服务基础上，引入复制集群，按服务化的架构提供双活业务。支持物理部署和虚拟机部署，可以做到独立安装和升级，独立扩展，按卷粒度提供双活服务。且支持优先站点仲裁和第三方仲裁的双仲裁模式，故障自动倒换，无需人工介入。同时，能跟上层Oracle RAC、VMWare等应用形成端到端双活容灾解决方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分布式存储基于通用的x86服务器，通过分布式的存储软件来构建存储系统，开放丰富灵活的软件义 策略和接口，允许管理员和租户进行自动化的系统管理和资源调度发放。业界的分布式存储，有多种形态，包括&lt;strong&gt;分布式块存储、分布式文件存储、分布式对象存储&lt;/strong&gt;。各大存储厂商都由自己的解决方案，而开源的代表的就是ceph。考虑到电信云NFV领域的应用特性和相关设备商分布，我们这里主要介绍华为的分布式存储系统FusionStorage。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-31-PXE批量部署原理及kickstart工具实践</title>
    <link href="https://kkutysllb.cn/2019/05/31/2019-05-31-PXE%E6%89%B9%E9%87%8F%E9%83%A8%E7%BD%B2%E5%8E%9F%E7%90%86%E5%8F%8Akickstart%E5%B7%A5%E5%85%B7%E5%AE%9E%E8%B7%B5/"/>
    <id>https://kkutysllb.cn/2019/05/31/2019-05-31-PXE批量部署原理及kickstart工具实践/</id>
    <published>2019-05-31T02:10:17.000Z</published>
    <updated>2019-06-03T02:56:02.870Z</updated>
    
    <content type="html"><![CDATA[<h2 id="PXE服务器简介"><a href="#PXE服务器简介" class="headerlink" title="PXE服务器简介"></a>PXE服务器简介</h2><p>PXE(preboot execute environment)是由Intel公司开发的最新技术，工作于C/S的网络模式，支持工作站通过网络从远端服务器下载映像，并由此支持来自网络的操作系统的启动过程，其启动过程中，终端要求服务器分配IP地址，再用TFTP（trivial file transfer protocol）或MTFTP(multicast trivial file transfer protocol)协议下载一个启动软件包到本机内存中并执行，由这个启动软件包完成终端基本软件设置，从而引导预先安装在服务器中的终端操作系统。<a id="more"></a></p><p>在Linux中操作系统有多种的安装方式：HDD、USB、CDROM、PXE及远程管理卡等。在系统运维中，经常要批量安装操作系统，一般的企业服务器数量都在几十、几百、几千、甚至上万台。这么多的机器，如果人工的一台一台去安装，那运维人员可能要把大部分时间都花费在了安装系统上，所以，<strong>一般都会建立一个PXE服务器，通过网络来批量部署系统。PXE部署的逻辑图如下图所示：</strong></p><p><img src="https://i.loli.net/2019/05/31/5cf08e302c1a824105.jpg"></p><h2 id="无人值守部署系统流程"><a href="#无人值守部署系统流程" class="headerlink" title="无人值守部署系统流程"></a>无人值守部署系统流程</h2><p><strong>Step1：部署PXE需要的环境。</strong>首先在pxe服务器端需要有一个DHCP服务器，需要有tftp服务器和一个文件服务器，其中文件服务器可以是ftp，http，nfs等文件服务器，如果服务器性能好或者流量不是太大，这些服务器完全可以放在一台服务器上面。pxe启动需要网卡支持这样的功能，现在的绝大部分的网卡已经支持。</p><p><strong>Step2：pex功能的客户端在主机开机启动项为网络启动</strong>，一般默认都此选项，如果没有可自行设置bios启动项。</p><p><strong>Step3：</strong>客户端开机之后进入网络启动，此时客户端没有IP地址需要发送广播报文（<strong>pxe网卡内置dhcp客户端程序</strong>），dhcp服务器响应客户端请求，分配给客户端相应的IP地址与掩码等信息。</p><p><strong>Step4：</strong> 客户端得到IP地址之后，与tftp通信，<strong>下载pxelinux.0，default文件</strong>，<strong>根据default指定的vmlinuz，initrd.img启动系统内核，并下载指定的ks.cfg文件。</strong></p><p><strong>Step5：根据ks.cfg文件去文件共享服务器（http/ftp/nfs）上面下载RPM包开始安装系统</strong>，注意此时的文件服务器是提供yum服务器的功能的。</p><h2 id="部署各功能服务器（整合在一套服务器上）"><a href="#部署各功能服务器（整合在一套服务器上）" class="headerlink" title="部署各功能服务器（整合在一套服务器上）"></a>部署各功能服务器（整合在一套服务器上）</h2><p>由于我们实验环境验证10台以内服务器批量部署，网络接口的流量不是很大，因此将所有功能服务器部署在一台虚拟机上。如果是实际生产环境，应根据部署规模估算网络接口流量，根据流量大小将上述各功能服务器部署在不同的物理服务器上，采用分布式批量部署的方式。</p><h3 id="tftp服务的安装"><a href="#tftp服务的安装" class="headerlink" title="tftp服务的安装"></a>tftp服务的安装</h3><p>tftp的服务器需要安装tftp-server包，<strong>tftp工作在udp 69号端口。</strong>启动服务稍有不同，<strong>在CentOS7需要启动tftpd.socket</strong> ，<strong>而在CentOS6的版本中需要保证服务开机启用，并且重新启动xinetd</strong>。因为，在CentOS7是将所有进程托管给systemd进程，只需启动tftp.socket，打开监听的端口套接字即可，而在CentOS6中则是将不常用的服务统一托管给了xinetd进程，由xinetd进程统一进行管理，所以重启xinetd即可。</p><p><strong>tftp-server默认没有配置文件，直接启用服务，就可以使用</strong>（当然可以手动建立，但是没有必要）。</p><p><strong>Step1：安装tftp-server服务</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y tftp-server tftp xinetd</span></span><br></pre></td></tr></table></figure><p><strong>Step2：配置xinetd.conf文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/xinetd.d/tftp</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># description: The tftp server serves files using the trivial file transfer \</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># protocol.  The tftp protocol is often used to boot diskless \</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># workstations, download configuration files to network-aware printers, \</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># and to start the installation process for some operating systems.</span></span><br><span class="line"></span><br><span class="line">service tftp</span><br><span class="line">&#123;</span><br><span class="line">    socket_type     = dgram</span><br><span class="line">    protocol        = udp</span><br><span class="line">    <span class="built_in">wait</span>            = yes</span><br><span class="line">    user            = root</span><br><span class="line">    server          = /usr/sbin/in.tftpd</span><br><span class="line">    server_args     = -s /var/lib/tftpboot</span><br><span class="line">    <span class="built_in">disable</span>         = no     <span class="comment">#这里默认是yes，改成no                                                                                                                                                                </span></span><br><span class="line">    per_source      = 11</span><br><span class="line">    cps         = 100 2</span><br><span class="line">    flags           = IPv4</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Step3：启用tftp、tftp-server服务</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl enable tftp.socket &amp;&amp; systemctl start tftp.socket</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl enable tftp.service &amp;&amp; systemctl start tftp.service</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl enable xinetd &amp;&amp; systemctl start xinetd</span></span><br></pre></td></tr></table></figure><p>启动完成后，进行服务启动检验，提示active就表示服务启用成功.</p><p><strong>Step4：tftp客户端测试</strong></p><p>由于本机同时是Server端，也是Client端（参见上面第一步安装的软件包tftp），所以本机不需要再次安装tftp软件包，直接测试即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入tftp服务的根目录</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># cd /var/lib/tftpboot/</span></span><br><span class="line">[root@C7-Server01 tftpboot]<span class="comment"># pwd</span></span><br><span class="line">/var/lib/tftpboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个tftp的测试文件</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 tftpboot]<span class="comment"># touch tftp.test</span></span><br><span class="line">[root@C7-Server01 tftpboot]<span class="comment"># ls -l tftp.test </span></span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 12:07 tftp.test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到root用户家目录</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 tftpboot]<span class="comment"># cd</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pwd</span></span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始测试</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># tftp 192.168.101.3</span></span><br><span class="line">tftp&gt; get tftp.test</span><br><span class="line">tftp&gt; quit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 校验文件是否下载成功</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll tft*</span></span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 12:09 tftp.test</span><br></pre></td></tr></table></figure><h3 id="DHCP服务器的安装"><a href="#DHCP服务器的安装" class="headerlink" title="DHCP服务器的安装"></a>DHCP服务器的安装</h3><p>DHCP使用udp的67号端口，使用ss -unl 可以查看到监听的67号端口。</p><p><strong>Step1：安装DHCP服务器包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y dhcp</span></span><br></pre></td></tr></table></figure><p><strong>Step2：因为DHCP默认配置文件为空，如下图，官方建议复制配置示例文件进行替换。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.conf</span></span><br></pre></td></tr></table></figure><p><strong>Step3：编辑配置文件</strong>，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim  /etc/dhcp/dhcpd.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#---------可用最简配置-------------------</span></span><br><span class="line">next-server 192.168.101.3;     <span class="comment">#tftp服务器地址</span></span><br><span class="line">filename <span class="string">"pxelinux.0"</span>;           <span class="comment">#启动文件</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">subnet 192.168.101.0 netmask 255.255.255.0 &#123;</span><br><span class="line">range 192.168.101.110 192.168.101.131;  <span class="comment">#ip地址池</span></span><br><span class="line">option routers 192.168.101.2;        <span class="comment">#网关</span></span><br><span class="line">option domain-name-servers 192.168.101.2; <span class="comment">#DNS                                                           </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Step4：启用dhcp服务，查询监听端口状态。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 etc]<span class="comment"># systemctl enable dhcpd &amp;&amp; systemctl start dhcpd</span></span><br><span class="line">[root@C7-Server01 etc]<span class="comment"># ss -nlu|grep 67</span></span><br><span class="line">UNCONN     0      0            *:67                       *:*</span><br></pre></td></tr></table></figure><p><strong>需要注意一点：如果是多网卡，默认监听eth0，指定DHCP监听eth1网卡方法如下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/sysconfig/dhcpd  在这个文件中，不是/etc/dhcp/dhcpd.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Command line options here</span></span><br><span class="line"></span><br><span class="line">DHCPDARGS=eth1  <span class="comment"># 指定监听网卡</span></span><br></pre></td></tr></table></figure><h3 id="安装并配置HTTP服务器"><a href="#安装并配置HTTP服务器" class="headerlink" title="安装并配置HTTP服务器"></a><strong>安装并配置HTTP服务器</strong></h3><p>我们通过http远程安装，同样也可以配置为ftp、NFS方式安装。</p><p><strong>Step1：安装httpd软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># yum -y install httpd</span></span><br></pre></td></tr></table></figure><p><strong>Step2：启动httpd服务</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># systemctl enable httpd &amp;&amp; systemctl start httpd</span></span><br></pre></td></tr></table></figure><h3 id="ftp服务器安装配置"><a href="#ftp服务器安装配置" class="headerlink" title="ftp服务器安装配置"></a>ftp服务器安装配置</h3><p>ftp可以进行许多安全方面的配置，但是在做一个内网的服务没有必要做许多安全方面的配置，只需要保证能正常使用即可，ftp的默认文件共享路径为：/var/ftp/pub/，需要共享文件只需放在该目录即可，安装系统可以直接将光盘挂载至该共享目录的一个子目录即可。</p><p><strong>Step1：安装软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y vsftpd</span></span><br></pre></td></tr></table></figure><p><strong>Step2：创建挂载目录</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># mkdir -p /var/ftp/pub/centos7/</span></span><br></pre></td></tr></table></figure><p><strong>Step3：启用ftp服务</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]# systemctl enable vsftpd &amp;&amp; systemctl start vsftpd</span><br></pre></td></tr></table></figure><h2 id="配置ks-cfg文件"><a href="#配置ks-cfg文件" class="headerlink" title="配置ks.cfg文件"></a>配置ks.cfg文件</h2><p>Anaconda是RedHat、CentOS、Fedora等Linux的安装管理程序。它可以提供文本、图形等安装管理方式，并支持Kickstart等脚本提供自动安装的功能。该程序的功能是把位于光盘或其他源上的数据包，根据设置安装到主机上。为实现该定制安装，它提供一个定制界面，可以实现交互式界面供用户选择配置（如选择语言，键盘，时区等信息）。</p><p>Anaconda支持的管理模式： <strong>Kickstart提供的自动化安装、 对一个RedHat实施upgrade和Rescuse模式对不能启动的系统进行故障排除。</strong>要进入安装步骤，需要先有一个引导程序引导启动一个特殊的Linux安装环境系统。引导有多种方式： （可用的安装方式：本地CDROM、硬盘驱动器、网络方式（NFS、FTP、HTTP）等等）</p><ol><li>基于网络方式的小型引导镜像，需要提供小型的引导镜像； </li><li>U盘引导，通过可引导存储介质中的小型引导镜像启动安装过程；  </li><li>基于PXE的网络安装方式，要提供PXE的完整安装环境； </li><li>其他bootloder引导（如GRUB）。</li></ol><p><strong>Step1：拷贝ks.cfg模板文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># cp /root/anaconda-ks.cfg  /var/www/html/ks.cfg</span></span><br></pre></td></tr></table></figure><p><strong>Step2：编辑ks.cfg文件（以下是我自己常用的设置）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># cat /var/www/html/ks.cfg </span></span><br><span class="line"><span class="comment">#version=DEVEL</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># System authorization information</span></span><br><span class="line"></span><br><span class="line">auth --enableshadow --passalgo=sha512</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use Network installation media</span></span><br><span class="line"></span><br><span class="line">url --url=http://192.168.101.3/centos7/</span><br><span class="line"></span><br><span class="line"><span class="comment"># Firewall configuration</span></span><br><span class="line"></span><br><span class="line">firewall --<span class="built_in">disable</span></span><br><span class="line">selinux --<span class="built_in">disable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use graphical install</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># graphical</span></span><br><span class="line"></span><br><span class="line">text</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the Setup Agent on first boot</span></span><br><span class="line"></span><br><span class="line">firstboot --<span class="built_in">disable</span></span><br><span class="line">ignoredisk --only-use=sda</span><br><span class="line"></span><br><span class="line"><span class="comment"># Keyboard layouts</span></span><br><span class="line"></span><br><span class="line">keyboard --vckeymap=us --xlayouts=<span class="string">'us'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># System language</span></span><br><span class="line"></span><br><span class="line">lang en_US.UTF-8</span><br><span class="line"></span><br><span class="line"><span class="comment"># Network information</span></span><br><span class="line"></span><br><span class="line">network  --bootproto=dhcp --device=eth0 --onboot=yes</span><br><span class="line">network  --bootproto=dhcp --device=eth1 --onboot=no</span><br><span class="line">network  --bootproto=dhcp --device=eth2 --onboot=no</span><br><span class="line">network  --hostname=CentOS7</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reboot after installation</span></span><br><span class="line"></span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># Root password</span></span><br><span class="line"></span><br><span class="line">rootpw --iscrypted <span class="variable">$6</span><span class="variable">$j</span>/GfiKGObTLP91Om<span class="variable">$02u</span>.tAD0W7dPLs1PIDWebq8AiIHCCZ16h.3unIzeKp75io2PKln.g3T.zlra.Jzd.1wAZ2xmwqnUk7kcbsbh.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># System services</span></span><br><span class="line"></span><br><span class="line">services --enabled=<span class="string">"chronyd"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># System timezone</span></span><br><span class="line"></span><br><span class="line">timezone Asia/Shanghai --isUtc</span><br><span class="line"></span><br><span class="line"><span class="comment"># System bootloader configuration</span></span><br><span class="line"></span><br><span class="line">bootloader --location=mbr --boot-drive=sda</span><br><span class="line"></span><br><span class="line"><span class="comment"># Partition clearing information</span></span><br><span class="line"></span><br><span class="line">clearpart --none --initlabel</span><br><span class="line"></span><br><span class="line"><span class="comment"># Disk partitioning information</span></span><br><span class="line"></span><br><span class="line">part /boot --fstype=<span class="string">"ext4"</span> --ondisk=sda --size=400</span><br><span class="line">part swap --fstype=<span class="string">"swap"</span> --ondisk=sda --size=8192</span><br><span class="line">part / --fstype=<span class="string">"ext4"</span> --ondisk=sda --size=1 --grow</span><br><span class="line"></span><br><span class="line">%packages</span><br><span class="line">@base</span><br><span class="line">@compat-libraries</span><br><span class="line">@debugging</span><br><span class="line">@development</span><br><span class="line">gcc</span><br><span class="line">glibc</span><br><span class="line">gcc-c++</span><br><span class="line">openssl-devel</span><br><span class="line">openssh</span><br><span class="line">tree</span><br><span class="line">nmap</span><br><span class="line">sysstat</span><br><span class="line">lrzsz</span><br><span class="line">vim</span><br><span class="line">ntpdate</span><br><span class="line">net-tools</span><br><span class="line">wget</span><br><span class="line">libffi-devel</span><br><span class="line">git</span><br><span class="line">chrony</span><br><span class="line">bridge-utils</span><br><span class="line">qemu-kvm</span><br><span class="line">libvirt</span><br><span class="line">virt-install</span><br><span class="line"></span><br><span class="line">%end</span><br><span class="line"></span><br><span class="line">%addon com_redhat_kdump --<span class="built_in">disable</span> --reserve-mb=<span class="string">'auto'</span></span><br><span class="line"></span><br><span class="line">%end</span><br></pre></td></tr></table></figure><p><strong>Step3：更改ks.cfg权限</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># chmod +r /var/www/html/ks.cfg</span></span><br></pre></td></tr></table></figure><p><strong>最后生成的配置文件如下：</strong>其中以#开头的行是注释行，其它部分开头是%开头，%end结尾。%packages是系统要安装的包，@开头是软件包组，@^是环境包组开头，以-开头是排除在外的包名或组名，除非必须的依赖性包则会安装，否则不会安装。%pre，%post是脚本，%pre是在任何磁盘分区之前进行，%post是在系统安装之后进行的系统配置。</p><h2 id="复制内核文件"><a href="#复制内核文件" class="headerlink" title="复制内核文件"></a>复制内核文件</h2><p><img src="https://i.loli.net/2019/05/31/5cf090dae198e42736.jpg"></p><p>内核文件、虚拟根文件以及菜单文件，都是通过tftp服务来提供的，由于系统及版本的不同，对于一个比较复制集群来说，需要准备不同系统，不同版本的内核文件，initrd.img文件。菜单文件只需要一份即可。/var/lib/tftpboot/目录规划如下：</p><p><strong>Step1：挂载光驱，虚拟机方式一定要先在连接光驱打上钩</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># ls -l /dev|grep cdrom</span></span><br><span class="line">lrwxrwxrwx. 1 root root           3 May 31 00:53 cdrom -&gt; sr0</span><br><span class="line">crw-rw----. 1 root cdrom    21,   1 May 31 00:53 sg1</span><br><span class="line">brw-rw----. 1 root cdrom    11,   0 May 31 00:53 sr0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建挂载目录</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># mkdir /var/www/html/centos7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于我的镜像文件已上传到linux中，所以通过以下方式挂载</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># mount -o loop /mydata/img/CentOS-7-x86_64-DVD-1804.iso /var/www/html/centos7/</span></span><br></pre></td></tr></table></figure><p><strong>Step2：将镜像中的启动文件COPY到tftp server的根目录中</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7 ~]<span class="comment"># cp /var/www/html/centos7/images/pxeboot/&#123;vmlinuz,initrd.img&#125; /var/lib/tftpboot/</span></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># cp /usr/share/syslinux/menu.c32  /var/lib/tftpboot/</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>vmlinuz</strong>是可引导的、压缩的内核文件，是可执行的Linux内核。</p><p><strong>initrd</strong>是“initial ram disk”的简写，用来临时的引导硬件被vmlinuz接管并继续引导。</p></blockquote><p><strong>Step3：复制pxelinux.0文件到tftp目录下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先安装syslinux，因为pxelinux.0文件由syslinux包提供</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># yum install -y syslinux</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制文件</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/</span></span><br></pre></td></tr></table></figure><p><strong>Step4：编辑pxelinux.cfg菜单文件,即isolinux.cfg</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建pxelinux.cfg目录</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># mkdir /var/lib/tftpboot/pxelinux.cfg</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制菜单文件</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># cp /var/www/html/centos7/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制启动信息文件，可以编辑</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># cp /var/www/html/centos7/isolinux/boot.msg /var/lib/tftpboot</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑default文件</span></span><br><span class="line"></span><br><span class="line">[root@CentOS7 ~]<span class="comment"># cat /var/lib/tftpboot/pxelinux.cfg/default </span></span><br><span class="line">default menu.c32</span><br><span class="line">timeout 600</span><br><span class="line"></span><br><span class="line">menu title CentOS Linux PXE Install</span><br><span class="line">label centos7</span><br><span class="line">    menu label ^Auto Install CentOS Linux 7</span><br><span class="line">    kernel vmlinuz</span><br><span class="line">    append initrd=initrd.img inst.repo=http://192.168.101.3/centos7 ks=http://192.168.101.3/ks.cfg net.ifnames=0 biosdevname=0 ksdevice=eth0</span><br></pre></td></tr></table></figure><h2 id="测试安装"><a href="#测试安装" class="headerlink" title="测试安装"></a>测试安装</h2><p><strong>在Vmware中建立一个空的虚拟机，设置开机启动为网卡启动，启动后出现如下图示，表示pxe安装配置成功。ps：我的系统装了两个版本的CentOS批量安装，大家可以参照上述方法自行添加第二、第三系统的配置。下一篇我们讲述cobbler自动化批量部署系统，与kickstart相比，配置稍简单点儿。但是cobbler是kickstart的升级版，所以理解并掌握cobblerl前必须掌握kickstart。</strong></p><p><img src="https://i.loli.net/2019/05/31/5cf0917d67e7f90362.jpg"></p><p><img src="https://i.loli.net/2019/05/31/5cf0918dd7dfa78629.jpg"></p><p><img src="https://i.loli.net/2019/05/31/5cf091a2367ac55875.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;PXE服务器简介&quot;&gt;&lt;a href=&quot;#PXE服务器简介&quot; class=&quot;headerlink&quot; title=&quot;PXE服务器简介&quot;&gt;&lt;/a&gt;PXE服务器简介&lt;/h2&gt;&lt;p&gt;PXE(preboot execute environment)是由Intel公司开发的最新技术，工作于C/S的网络模式，支持工作站通过网络从远端服务器下载映像，并由此支持来自网络的操作系统的启动过程，其启动过程中，终端要求服务器分配IP地址，再用TFTP（trivial file transfer protocol）或MTFTP(multicast trivial file transfer protocol)协议下载一个启动软件包到本机内存中并执行，由这个启动软件包完成终端基本软件设置，从而引导预先安装在服务器中的终端操作系统。
    
    </summary>
    
      <category term="自动化运维" scheme="https://kkutysllb.cn/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="Linux" scheme="https://kkutysllb.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-29-华为存储虚拟化解决方案</title>
    <link href="https://kkutysllb.cn/2019/05/29/2019-05-29-%E5%8D%8E%E4%B8%BA%E5%AD%98%E5%82%A8%E8%99%9A%E6%8B%9F%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://kkutysllb.cn/2019/05/29/2019-05-29-华为存储虚拟化解决方案/</id>
    <published>2019-05-29T14:53:34.000Z</published>
    <updated>2019-05-29T15:16:11.145Z</updated>
    
    <content type="html"><![CDATA[<p>在前文《存储虚拟化概述》中，我们提到存储虚拟化与软件定义存储SDS的区别就是其控制平面数据和存储平面数据是一种紧耦合的关系，因此各厂商的存储虚拟化解决方案是一种“私有”方案，不仅不同厂商之间不能兼容，甚至通常不同产品之间有可能不兼容。因此，考虑到电信云NFV的应用场景，以及设备商的分布情况，我们这里主要讨论<strong>华为的虚拟化存储解决方案</strong>和<strong>华为的分布式存储Fusion Storage</strong>的情况。<a id="more"></a></p><h2 id="华为存储虚拟化的存储模型"><a href="#华为存储虚拟化的存储模型" class="headerlink" title="华为存储虚拟化的存储模型"></a>华为存储虚拟化的存储模型</h2><p>华为对存储虚拟化的定义：<strong>存储虚拟化是将存储设备抽象为数据存储，虚拟机在数据存储中作为一组文件存储在自己的目录中。而数据存储是逻辑容器，类似于文件系统，它将各个存储设备的特性隐藏起来，并提供一个统一的模型来存储虚拟机文件。同时，存储虚拟化技术可以更好的管理虚拟基础架构的存储资源，使系统大幅提升存储资源利用率和灵活性，提高应用的正常运行时间。</strong></p><p><img src="https://i.loli.net/2019/05/29/5cee9d428946a52708.jpg"></p><p><strong>能够封装为数据存储的存储单元包括：</strong></p><ul><li>SAN存储（包括iSCSI或光纤通道的SAN存储）上划分的LUN；</li><li>NAS存储上划分的文件系统共享目录；</li><li>华为分布式存储FusionStorage上的存储池；</li><li>主机的本地硬盘以及主机的本地内存盘；</li></ul><p><strong>数据存储可支持文件系统格式：</strong></p><ul><li>华为私有的虚拟镜像管理系统（VIMS），为存储虚拟机而优化的高性能文件系统，主机可以将虚拟镜像管理系统数据存储部署在任何基于SCSI的本地或联网存储设备上，包括光纤通道、以太网光纤通道和iSCSI SAN设备。</li><li>网络文件系统（NFS），NAS设备上的文件系统。FusionSphere支持NFS V3协议，可以访问位于NFS服务器上制定的NFS磁盘，挂载该磁盘并满足任何存储需求。</li><li>EXT4，FusionSphere支持服务器的本地磁盘虚拟化。</li></ul><p>从上面华为存储虚拟化的定义可以看出，主要涉及三个概念：<strong>存储资源、存储设备</strong>和<strong>数据存储。</strong>华为的这些基本概念定义的比较奇葩，从我个人理解来看是一种反人类的定义，如下图所示。按照正常人的理解，存储设备指的是真实物理存储，存储资源指的是抽象化后逻辑存储，但是它的定义正好是相反的。</p><p><img src="https://i.loli.net/2019/05/29/5cee9d89ef79033740.jpg"></p><p><strong>华为存储虚拟化模型中，存储概念的定义如下：</strong></p><p><strong>存储资源：</strong>表示物理存储设备，例如IPSAN、Advanced SAN、NAS等，其中，Advance SAN是不支持虚拟化的。一个存储资源可以包含多个物理存储。<strong>主机访问存储资源时，先需要添加存储资源，再选定主机关联存储资源。</strong>如下所示：</p><p><img src="https://i.loli.net/2019/05/29/5cee9dc14243863228.jpg"></p><p><strong>存储设备：</strong>表示存储资源中的管理单元，包括本地磁盘、LUN、 Advanced SAN存储池、Fusion Storage存储池、NAS共享目录等。多个存储设备可以归属在一个存储资源中，且<strong>存储设备必须被添加为数据存储才能使用</strong>。其中，<strong>LUN在使用前需要在存储侧或者交换机侧进行配置</strong>，该配置根据不同的厂家会不一样，具体需要参照相关厂家的技术文档。<strong>存储设备需要通过主机探测的方式进行扫描来发现：</strong>主机需要链接存储资源后才能扫描存储资源所包含的存储设备，而且每个主机都能发现各自的存储设备，也能发现共享的存储设备。如下所示：</p><p><img src="https://i.loli.net/2019/05/29/5cee9dfea5d6515965.jpg"></p><p><strong>数据存储：</strong>表示在存储设备上创建的逻辑管理单元，需要创建在指定的存储设备上，且<strong>一个存储设备只能创建一个数据存储，数据存储和存储设备一一对应，且数据存储大小依赖于存储设备的大小</strong>。数据存储和主机关联，为主机提供资源，数据存储可以关联到多个主机，一个主机也可以使用多个数据存储。数据存储承载了具体的虚拟机业务，例如创建磁盘等。对于SAN存储上的LUN，也可以作为数据存储直接供虚拟机使用，而不再创建虚拟磁盘，此过程称为<strong>裸设备映射</strong>，目前仅支持部分操作系统的虚拟机使用，用于搭建数据库服务器等对磁盘空间要求较大的场景。如果使用裸设备部署应用集群服务（如 Oracle RAC等），建议不要使用虚拟机的快照、快照恢复功能，快照恢复后，会导致应用集群服务异常。数据存储映射的示意图如下：</p><p><img src="https://i.loli.net/2019/05/29/5cee9e1f26a4b48820.jpg"></p><p>比如：裸设备映射方式可以将一个SAN设备【<strong>存储资源</strong>】分配的一个LUN【<strong>存储设备</strong>】接入到FusionCompute环境成为一个数据存储【<strong>数据存储</strong>】，可以在该数据存储上创建运行业务的虚拟机，对外提供服务。</p><p>在华为的FusionCompute中配置数据存储时，首先需要完成存储接口的设置，然后可以通过以下流程接入和使用存储资源，如下图所示：</p><p><img src="https://i.loli.net/2019/05/29/5cee9e3b7dc7412851.jpg"></p><ol><li>在FusionCompute界面上首先添加存储资源（如：IPSAN等等），并在存储设备上进行主机启动器的配置。</li><li>主机关联存储资源后，执行“<strong>扫描存储设备</strong>”动作，将IPSAN上的LUN扫描到主机。</li><li>主机选择存储设备，执行“<strong>添加数据存储</strong>”动作，并选择“<strong>虚拟化</strong>”，存储配置完成。</li><li>随后，可以在数据存储上可以进行创建卷、创建快照等行为。</li></ol><blockquote><p><strong>所谓存储接口，是指主机与存储设备连接所用的端口。</strong>可以将主机上的一个物理网卡，或者多个物理网卡的绑定设置为存储接口。当使用iSCSI存储时，一般使用主机上两个物理网卡与存储设备多个存储网卡相连，组成存储多路径，此时不需要绑定主机存储平面的物理网卡；当使用NAS存储时，为保证可靠性，建议将<strong>主机的存储平面网卡以主备模式进行绑定设置为存储接口</strong>与NAS设备连接。</p><p>同时，在存储接口设置还有个<strong>存储多路径</strong>的概念，主要指存储设备通过多条链路与主机一个或多个网卡连接，<strong>通过存储设备的控制器控制数据流的路径，实现数据流的负荷分担</strong>，保证存储设备与主机连接的可靠性。一般情况下，iSCSI存储和光纤通道存储（如IP SAN存储设备、FC SAN存储设备、OceanStor 18000系列存储）均支持存储多路径。而且在华为的解决方案中，存储多路径包含<strong>华为多路径</strong>与<strong>通用多路径</strong>两种模式，<strong>通用多路径下虚拟机采用裸设备映射的磁盘时，不支持Windows Server操作系统的虚拟机搭建MSCS集群。</strong></p></blockquote><h2 id="华为虚拟化存储的链接"><a href="#华为虚拟化存储的链接" class="headerlink" title="华为虚拟化存储的链接"></a>华为虚拟化存储的链接</h2><p><strong>FC-SAN：</strong>存储区域网络(Storage Area Networks，SAN)是一个用在服务器和存储资源之间的、专用的、高性能的网络体系。 <strong>SAN是独立于LAN的服务器后端存储专用网络</strong>。 SAN采用<strong>可扩展的网络拓扑结构</strong>连接服务器和存储设备，每个存储设备不隶属于任何一台服务器，所有的存储设备都可以在全部的网络服务器之间作为对等资源共享。SAN主要利用Fibre Channel protocol（光纤通道协议），通过FC交换机建立起与服务器和存储设备之间的直接连接，因此我们通常也称这种利用FC连接建立起来的SAN为FC-SAN。如下图所示，FC特别适合这项应用，原因在于一方面它可以传输大块数据，另一方面它能够实现较远距离传输。SAN主要应用在对于性能、冗余度和数据的可获得性都有很高的要求高端、企业级存储应用上。</p><p><img src="https://i.loli.net/2019/05/29/5cee9e85176dd28733.jpg"></p><p><strong>SAN架构中常用的三种协议：</strong></p><ul><li><strong>FC 协议 (Fibre Channel)</strong> ，使用该种协议的SAN架构，称为FC-SAN。</li><li><strong>iSCSI 协议 (Internet SCSI)，</strong>使用该种协议的SAN架构，称为IP-SAN。</li><li><strong>FCoE 协议(Fibre Channel over Ethernet)，</strong>FC 协议通常和iSCSI协议用于现代的SAN架构中，而FCoE协议在服务器需要融合SAN和LAN业务时，也是用得越来越多。</li></ul><p><strong>IP-SAN：</strong>以TCP/IP协议为底层传输协议，采用以太网作为承载介质构建起来的存储区域网络架构。</p><p>实现IP-SAN的典型协议是iSCSI，它定义了<strong>SCSI指令集在IP中传输的封装</strong>方式。IP-SAN把SCSI指令集封装在了TCP/IP上。类似于不管我们是选择哪家快递公司，最终都是把我们想要发送的东西发送至目的地，都是由我们发起寄送请求，快递公司进行响应，差别只在于快递公司不同而已。<strong>iSCSI是全新建立在TCP/IP和SCSI指令集的基础上的标准协议，所以其开放性和扩展性更好。</strong>如下图所示，IP-SAN具备很好的扩展性、灵活的互通性，并能够突破传输距离的限制，具有明显的成本优势和管理维护容易等特点。</p><p><img src="https://i.loli.net/2019/05/29/5cee9ea90c8d696515.jpg"></p><p><strong>IP-SAN典型组网方式有：</strong></p><ul><li><strong>直连：</strong>主机与存储之间直接通过以太网卡、TOE卡或iSCSI HBA卡连接，这种组网方式简单、经济，但较多的主机分享存储资源比较困难；</li><li><strong>单交换：</strong>主机与存储之间由一台以太网交换机，同时主机安装以太网卡或TOE卡或iSCSI HBA卡实现连接。这种组网结构使多台主机能共同分享同一台存储设备，扩展性强，但交换机处是一个故障关注点；</li><li><strong>双交换：</strong>同一台主机到存储阵列端可由多条路径连接，扩展性强，避免了在以太网交换机处形成单点故障。</li></ul><p>IP-SAN是基于IP网络来实现数据块传输的网络存储形态，与传统FC SAN的最大区别在于传输协议和传输介质的不同。目前常见的IP-SAN协议有iSCSI、FCIP、iFCP等，其中iSCSI是发展最快的协议标准，大多时候我们所说的IP-SAN就是指基于iSCSI实现的SAN。</p><p><strong>NAS：</strong>网络附加存储，<strong>是一种将分布、独立的数据进行整合，集中化管理，以便于对不同主机和应用服务器进行访问的技术</strong>。如下图所示，NAS和SAN最大的区别就在于<strong>NAS有文件操作和管理系统</strong>，而SAN却没有这样的系统功能，其功能仅仅停留在文件管理的下一层，即数据管理。</p><p><img src="https://i.loli.net/2019/05/29/5cee9ec9bb0ac50848.jpg"></p><p>SAN和NAS并不是相互冲突的，是可以共存于一个系统网络中的，但NAS通过一个公共的接口实现空间的管理和资源共享，SAN仅仅是为服务器存储数据提供一个专门的快速后方存储通道。NAS文件共享功能有点儿类似FTP文件服务，但是两者是完全不同的。FTP只能将文件传输到本地的目录之后才能执行，而网络文件系统NAS可以允许直接访问源端的文件，不需要将数据复制到本地再访问。</p><h2 id="华为存储虚拟化的原理"><a href="#华为存储虚拟化的原理" class="headerlink" title="华为存储虚拟化的原理"></a>华为存储虚拟化的原理</h2><p>存储虚拟化技术可以将不同存储设备进行格式化，屏蔽存储设备的能力、接口协议等差异性，将各种存储资源转化为统一管理的数据存储资源，可以用来存储虚拟机磁盘、虚拟机配置信息、快照等信息，使得用户对存储的管理更加同质化。华为的虚拟化存储栈示意图如下所示，其实现存储虚拟化的关键的就是<strong>中间的文件系统</strong>那一层。</p><p><img src="https://i.loli.net/2019/05/29/5cee9ef00c5b983694.jpg"></p><p><strong>华为虚拟化存储栈中文件系统作用就是提供文件操作接口，屏蔽底层存储设备的差异，并且为虚拟化卷文件提供存放空间。</strong>当前FusionCompute所支持的文件系统格式有：VIMS、EXT4、NFS。它们在应用场景，虚拟化特性支持方面的差异如下：</p><table><thead><tr><th></th><th><strong>所需存储**</strong>设备**</th><th><strong>是否创建**</strong>文件系统**</th><th><strong>是否支持**</strong>共享**</th><th><strong>是否支持**</strong>延迟置零卷**</th></tr></thead><tbody><tr><td>VIMS</td><td>LUN</td><td>是</td><td>是</td><td>是</td></tr><tr><td>EXT4</td><td>本地磁盘</td><td>是</td><td>否</td><td>是</td></tr><tr><td>NFS</td><td>共享目录</td><td>否</td><td>是</td><td>否</td></tr></tbody></table><p>其中，NFS不支持创建文件系统是因为NFS本身就具备文件系统功能，而且NFS是以共享目录的方式提供数据存储，如果采用延迟置零卷的分配方式，容易造成数据丢失。EXT4主要用于服务器本地硬盘，如果要支持共享，需要在存储I/O通道上通过锁机制来避免竞争，目前方案不支持。上述的三个文件系统中，VIMS是华为自研的文件系统，其余两个都是标准文件系统类型。</p><p><strong>VIMS (Virtual Image Manage System)虚拟镜像管理系统</strong>，属于华为自研的一种文件系统，是一种高性能集群文件系统。在华为存储虚拟化解决方案中，它是实现是<strong>自动精简置备磁盘、快照、存储迁移等高级特性的技术基础。</strong>如下图所示，VIMS使虚拟化技术的应用超出了单个存储系统的限制，其设计、构建和优化针对虚拟服务器环境，可让多个虚拟机共同访问一个整合的集群式存储池，从而显著提高了资源利用率。</p><p><img src="https://i.loli.net/2019/05/29/5cee9f18639fe69372.jpg"></p><p>VIMS兼容FC SAN、IPSAN、NAS、本地磁盘，支持建立<strong>固定空间磁盘、动态空间磁盘、差分磁盘</strong>等。主要应用于需要<strong>存储迁移、快照、链接克隆</strong>等高级存储特性虚拟机。</p><h2 id="虚拟磁盘的类型"><a href="#虚拟磁盘的类型" class="headerlink" title="虚拟磁盘的类型"></a>虚拟磁盘的类型</h2><p>一个虚拟机在虚拟化计算节点文件系统上表现为一个或多个虚拟磁盘文件，也就是说，一个虚拟机磁盘体现为一个或多个虚拟磁盘文件。在华为存储虚拟化解决方案中，虚拟磁盘的格式为VHD镜像格式。它是FusionCompute实现精简卷、快照等功能的基本载体，实现了FusionCompute虚拟机镜像数据的基本储存功能。如下所示，虚拟机的一个虚拟磁盘对应一个VHD文件。</p><p><img src="https://i.loli.net/2019/05/29/5cee9f3d9238019790.jpg"></p><p>在华为存储虚拟化解决方案中，虚拟机的虚拟磁盘类型分为三种：<strong>固定空间磁盘、动态空间磁盘</strong>和<strong>差分磁盘。</strong></p><p><strong>固定空间磁盘：</strong>创建时需要将磁盘文件对应的存储块空间全部进行初始化成”0”，创建速度慢，但是IO性能最佳，适用于对IOPS要求较高的场景。如下图所示，磁盘大小恒定，<strong>创建后使用空间和预留空间相等。</strong></p><p><img src="https://i.loli.net/2019/05/29/5cee9f61b2d8415270.jpg"></p><p>数据区主要用来存放虚拟机业务数据，未写满的时候内部空间包含大量0，数据冗余度很高。最后一个扇区用来存放磁盘的元数据，也就是虚拟磁盘的大小、块的个数，位于物理存储的位置等数据，固定空间的磁盘主要应用于系统中的普通卷。</p><p><strong>动态空间磁盘：</strong>创建时只需写头和结束块，<strong>创建速度块，IO性能较差，适用于应用于精简磁盘和普通延迟置零磁盘。</strong>如下图所示，磁盘大小会随着用户写入数据而增长，但不会随着用户删除数据而缩减，只能通过磁盘空间回收来手动缩减应用在系统中的精简磁盘空间。</p><p><img src="https://i.loli.net/2019/05/29/5cee9f8543c1a89829.jpg"></p><p>前面和后面共m+1个扇区用来存放虚拟磁盘的元数据信息，其余扇区用来存放虚拟机业务数据。当用来建立精简磁盘时，首次创建只建立头和尾共m+1扇区的元数据区，后续随着虚拟机业务数据的增加逐渐增加数据区的大小，因此在一些IOPS要求不高的场景可以节省物理存储空间。动态空间磁盘通过工具可以和固定空间磁盘互相转换，例如，可以用一个精简磁盘的模板部署一个普通磁盘的虚拟机。</p><p><strong>差分磁盘：</strong>差分磁盘的结构和动态磁盘一模一样，只是<strong>文件头中会记录它的父文件路径，因此差分卷不能独立存在，必须能够访问到父文件才能正常工作</strong>，如下图所示，主要用于链接克隆场景。</p><p><img src="https://i.loli.net/2019/05/29/5cee9fa68710a98959.jpg"></p><p>前m个扇区和最后一个扇区存放虚拟磁盘自身的元数据信息，从m+1到k扇区之间存储父文件的元数据信息，数据区存放相对于父文件数据的增量业务数据，所以被称为差分磁盘。差分卷也可以成为父文件，在此场景下，差分卷不仅集成自身父文件的数据，还要向其子卷提供数据，类似祖孙三代中父亲的角色。</p><p>差分磁盘的特性和动态盘类似，但是很多业务有限制。差分磁盘以块为单位记录相对于父文件的修改。配合快照、非持久化磁盘、链接克隆等功能被使用，起到保护源盘不被修改，并可以跟踪虚拟机磁盘差异数据的作用。</p><h2 id="华为存储虚拟化特性"><a href="#华为存储虚拟化特性" class="headerlink" title="华为存储虚拟化特性"></a>华为存储虚拟化特性</h2><p>华为存储虚拟化提供基于磁盘的RAID 2.0+、基于虚拟磁盘的精简置备和空间回收、快照、连接克隆、存储热迁移等特性，适用于各类不同业务场景下的虚拟机。</p><h3 id="RAID-2-0"><a href="#RAID-2-0" class="headerlink" title="RAID 2.0+"></a>RAID 2.0+</h3><p>我们在了解华为RAID2.0+技术原理之前，可以先了解一下我们的传统RAID技术。我们传统的RAID技术是一种<strong>盘级虚拟化</strong>的技术，有RAID0 RAID1 RAID5 RAID10等常见的RAID技术，如下图所示，是一个RAID 50的组合。</p><p><img src="https://i.loli.net/2019/05/29/5cee9fd00b97698132.jpg"></p><p>传统RAID的状态主要有几种：<strong>创建RAID 、RAID组正常工作 、RAID组降级、 RAID组失效</strong> 。传统RAID技术热备方式主要是通过<strong>固定的盘</strong>来进行数据的恢复。</p><p>在传统的RAID技术中，是将几块小容量廉价的磁盘组合成一个大的逻辑磁盘给大型机使用。后来硬盘的容量不断增大，组建RAID的初衷不再是构建一个大容量的磁盘，而是利用RAID技术实现数据的可靠性和安全性，以及提升存储性能。如下图所示，由于单个容量硬盘都已经较大了，数据硬盘组建的RAID容量更大，然后再把RAID划分成一个一个的LUN映射给服务器使用。</p><p><img src="https://i.loli.net/2019/05/29/5cee9fefc02e591366.jpg"></p><p>随着硬盘技术的发展，单块硬盘的容量已经达到数T，传统RAID技术在重建的过程中需要的时间越来越长，也增加了在重构过程中其它硬盘再坏掉对数据丢失造成的风险，为了解决这一问题，块虚拟化技术应运而生，将以前以单块硬盘为成员盘的RAID技术再细化，将硬盘划分成若干的小块，再以这些小块为成员盘的方式构建RAID,也就是现在业界所说的RAID2.0+技术。</p><p><img src="https://i.loli.net/2019/05/29/5ceea008f34e382625.jpg"></p><p><strong>RAID2.0+是一种块级的虚拟化技术</strong>，如下图所示。</p><p><img src="https://i.loli.net/2019/05/29/5ceea025ef0ec28574.jpg"></p><p>它由不同类型的硬盘组成硬盘域，把硬盘域内<strong>每个硬盘切分为固定64MB的块（CK）</strong>，硬盘域内同种类型的硬盘被划分为一个个的<strong>Disk Group（DG）</strong>，从同一个DG上随机选择多个硬盘，每个硬盘选取CK按照RAID算法组成<strong>Chunk Group（CKG）</strong>，CKG被划分为固定大小的<strong>Extent</strong>，Thick LUN以Extent为单位映射到LUN（上图上半部分），也可以采用Grain在Extent的基础上进行更细粒度的划分，Thin LUN以Grain 为单位映射到LUN（上图下半部分）。</p><p>为了进一步说明RAID 2.0+各类逻辑概念以及相互之间的关系，通过下图RAID 2.0+的软件逻辑架构进行说明。</p><p><img src="https://i.loli.net/2019/05/29/5ceea048c4eaa30278.jpg"></p><p><strong>Disk Domain（磁盘域）：</strong>一个硬盘域上可以创建多个存储池（Storage Pool）一个硬盘域的硬盘可以选择SSD、SAS、NL-SAS中的一种或者多种，不同硬盘域之间是完全隔离的，包括故障域、性能和存储资源等。　</p><p><strong>Storage Pool（存储池）&amp; Tier：</strong>一个存储池基于指定的一个硬盘域创建，可以从该硬盘域上动态的分配Chunk（CK）资源，并按照<strong>每个存储层级（Tier）</strong>的“<strong>RAID策略</strong>”组成Chunk Group（CKG）向应用提供具有RAID保护的存储资源。</p><p><strong>Disk Group（DG）：</strong>由硬盘域内相同类型的多个硬盘组成的集合，硬盘类型包括SSD、SAS和NL-SAS三种。</p><p><strong>LD（逻辑磁盘）：</strong>是被存储系统所管理的硬盘，和物理硬盘一一对应。</p><p><strong>Chunk（CK）：</strong>是存储池内的硬盘空间切分成若干固定大小的物理空间，每块物理空间的大小为64MB，是组成RAID的基本单位。</p><p><strong>Chunk Group（CKG）：</strong>是由来自于同一个DG内不同硬盘的CK按照RAID算法组成的逻辑存储单元，是存储池从硬盘域上分配资源的最小单位。</p><p><strong>Extent：</strong>是在CKG基础上划分的固定大小的逻辑存储空间，大小可调，是热点数据统计和迁移的最小单元（数据迁移粒度），也是存储池中申请空间、释放空间的最小单位。</p><p><strong>Grain：</strong>在Thin LUN模式下，Extent按照固定大小被进一步划分为更细粒度的块，这些块称之为Grain。</p><p><strong>Volume &amp; LUN：</strong>Volume即卷，是存储系统内部管理对象；LUN是可以直接映射给主机读写的存储单元，是Volume对象的对外体现。</p><p>RAID2.0+ 优秀性能主要体现在<strong>负载均衡优、数据重构时间短</strong>和<strong>提升单卷（LUN）的读写性能</strong>等几个方面。</p><p><strong>1）RAID2.0+的负载均衡更优，</strong>如下图所示，数据在存储池中硬盘上的自动均衡分布，避免了硬盘的冷热不均，从而降低了存储系统整体的故障率。</p><p><img src="https://i.loli.net/2019/05/29/5ceea074399ec47928.jpg"></p><p>RAID 2.0+的负载均衡方式主要有两种：<strong>第一种是根据crush算法</strong>，在创建CKG的时候选择CK，保证硬盘被选中的概率与硬盘剩余容量成正比；<strong>第二种就是smartmotion</strong>，主要用于数据迁移发生在DG层次。当有新盘加入硬盘域的时候，会触发smartmotion，查出待均衡的原CKG，然后给该CKG分配一个目标CKG，该CKG包含来源于新盘的CK，如果原CKG和目标CKG中对应位置的CK落在不同的盘，就会触发实现均衡。那么有数据的原CKG迁移到目标CKG中，没有数据的只需要改变CKG的映射关系即可。</p><p><strong>2）RAID2.0+的数据重构时间短</strong>，如下图所示，相较传统RAID重构数据流串行写入单一热备盘的方式，RAID2.0+采用多对多的重构，重构数据流并行写入多块磁盘，极大缩短数据重构时间，1TB数据仅需30分钟。</p><p><img src="https://i.loli.net/2019/05/29/5ceea09166f4349338.jpg"></p><p>RAID2.0+的数据重构方式主要有三种：<strong>第一种是全盘重构</strong>，就是当一块盘故障或者被拔出之后进行数据恢复；<strong>第二种是局部重构</strong>，就是硬盘上出现坏块，通过RAID算法将上面的数据重构到热备CK中；<strong>第三种是恢复重构</strong>，就是在某块硬盘正常访问期间的写操作无法完成，只能处于降级写状态，会在系统上记录相关的日志并且更新校验值，待硬盘恢复后，将故障期间的数据根据RAID算法计算之后更新数据。</p><p><strong>3）提升单卷（LUN）的读写性能</strong>，如下图所示，RAID2.0+的热备采用的是空间的形式，每个盘上面的CK都可以作为磁盘热点，这种条块化的分割极大提升单卷（LUN）的读写IOPS。</p><p><img src="https://i.loli.net/2019/05/29/5ceea0b1be3f817902.jpg"></p><p>传统存储的RAID通常是以单个磁盘为粒度来建立RAID，RAID被限制在有限的几个磁盘上，所以当主机对一个较小的卷进行密集访问时，只能访问到有限的几个磁盘，这就造成磁盘访问瓶颈，导致磁盘热点。 而RAID2.0+技术基于Chunk而非物理磁盘构成RAID。一个物理磁盘上的不同CK可以用于构成不同RAID类型的卷。对于HVS阵列而言，即使是很小的卷也可以通过CK的方式分布到很多磁盘上。宽条带化技术使得小的卷不再需要额外的大容量即可获得足够的高性能，且避免了磁盘热点。物理磁盘上剩余的CK还可以用于其它的卷。</p><p>在使用RAID 2.0+ 技术时，首先创建硬盘域，指定该硬盘域使用的硬盘类型和每种类型硬盘的数量；另外还要指定针对不同类型的硬盘，使用其上的CK创建CKG时采取的RAID算法，不同类型的硬盘可以使用不同的RAID算法，比如针对故障率高的SATA硬盘采用可靠性更高的RAID 6算法等。接下来创建存储池，一个存储池是基于一个硬盘域的，创建存储池时可以设置该存储池所使用的Extent大小，设置后不能更改。然后在存储池内创建LUN，只需要指定LUN的容量大小即可，系统会根据事先定义的规则（数据分层、自动迁移等）选择适当的Extent完成创建。最后将创建好的LUN映射给需要的主机，主机在使用LUN时RAID 2.0+ 技术就会在后台发挥作用。</p><p><strong>由此可以看出，当一块硬盘损坏时，只会影响该硬盘域上的存储池中的CKG，对于其它硬盘域上的CKG无影响，因此可以实现故障隔离。</strong></p><h2 id="精简磁盘和空间回收"><a href="#精简磁盘和空间回收" class="headerlink" title="精简磁盘和空间回收"></a>精简磁盘和空间回收</h2><p>华为存储虚拟化支持创建精简磁盘，可以随着用户使用而自动分配空间。但是，后续膨胀的精简磁盘不会随着用户删除数据而缩小，必须使用空间回收工具可以将用户删除的数据空间释放到数据存储。如下图所示，创建虚拟机可以选择精简磁盘模式，提高磁盘使用率，增加虚拟机部署密度。</p><p><img src="https://i.loli.net/2019/05/29/5ceea0daed68148460.jpg"></p><p><strong>精简磁盘可应用于局点运行初期，用户磁盘使用率低的情况。</strong>能够降低初始存储投资及维护成本，存储设备只保存有效数据，不保存预留空间，可以提高存储资源利用率。</p><p>在FusionCompute中，选择“存储池”。 进入“存储池”页面。在左侧导航树，选择“站点名称 &gt; 数据存储名称”。 显示“入门”页签。单击“磁盘”。 显示磁盘信息列表。单击“创建磁盘”。 弹出“创建磁盘”对话框，如图所示。</p><p><img src="https://i.loli.net/2019/05/29/5ceea0f29ec5f50184.jpg"></p><p><strong>配置模式：</strong></p><ul><li><strong>普通：</strong>根据磁盘容量为磁盘分配空间，在创建过程中会将物理设备上保留的数据置零。这种格式的磁盘性能要优于其他两种磁盘格式，但创建这种格式的磁盘所需的时间可能会比创建其他类型的磁盘长，且预留空间和实际占用空间相等，建议系统盘使用该模式。</li><li><strong>精简：</strong>该模式下，系统首次仅分配磁盘容量配置值的部分容量，后续根据使用情况，逐步进行分配，直到分配总量达到磁盘容量配置值为止。数据存储类型为“<strong>FusionStorage</strong>”或“<strong>本地内存盘</strong>”时，只支持该模式；数据存储类型为“<strong>本地硬盘</strong>”或“<strong>SAN存储</strong>”时，不支持该模式。</li><li><strong>普通延迟置零：</strong>根据磁盘容量为磁盘分配空间，创建时不会擦除物理设备上保留的任何数据，但后续从虚拟机首次执行写操作时会按需要将其置零。<strong>创建速度比“普通”模式快；IO性能介于“普通”和“精简”两种模式之间。</strong>只有数据存储类型为“<strong>虚拟化本地硬盘</strong>”、“<strong>虚拟化SAN存储</strong>”或版本号为<strong>V3的“Advanced SAN存储</strong>”时，支持该模式。</li></ul><p><strong>磁盘模式：</strong></p><ul><li><strong>从属：</strong>快照中包含该从属磁盘，默认选项。</li><li><strong>独立-持久：</strong>更改将立即并永久写入磁盘，持久磁盘不受快照影响。即对虚拟机创建快照时，不对该磁盘的数据进行快照。使用快照还原虚拟机时，不对该磁盘的数据进行还原。</li><li><strong>独立-非持久：</strong>关闭电源或恢复快照后，丢弃对该磁盘的更改。</li></ul><h3 id="快照和快照链"><a href="#快照和快照链" class="headerlink" title="快照和快照链"></a>快照和快照链</h3><p>虚拟机快照记录了虚拟机在某一时间点的内容和状态，通过恢复虚拟机快照使虚拟机多次快速恢复到这一时间点，比如我们初次手动安装OpenStack服务时，每安装一个服务都会创建一个快照，这样当后续出现错误且无法恢复时，可以通过前面快照恢复这一步安装前的状态，而不用从头再来。虚拟机快照包含磁盘内容、虚拟机配置信息、内存数据，多次快照之间保存差量数据，节约存储空间。主要适用于虚拟机用户在执行一些重大、高危操作前，例如系统补丁，升级，破坏性测试前执行快照，可以用于故障时的快速还原。</p><p>虚拟机快照的创建、恢复和删除都是由用户手动触发的，系统并不会自动执行。如下图所示，创建快照时会生成一个新的差分卷，创建的方式一般包括COW（写时拷贝）、ROW（写时重定向）和WA（随机写），一般都是写时重定向ROW方式创建。</p><p><img src="https://i.loli.net/2019/05/29/5ceea11807a6c40312.jpg"></p><p>当创建快照采用了ROW方式时，快照虚拟机会挂载这个差分卷，快照创建后的写操作会进行重定向，所有的写IO都被重定向到新卷中，所有旧数据均保留在只读的源卷中。</p><p>当用户对一个虚拟机进行多次快照操作，可以形成快照链，如下图所示，一个虚拟机生成快照的数量不能超过<strong>32个</strong>，也是快照链的最大长度。</p><p><img src="https://i.loli.net/2019/05/29/5ceea13a9c1d752467.jpg"></p><p>SNAP1是基于源卷的第一次差分卷，SNAP2是基于SNAP2的第二次差分卷，且虚拟机源卷始终挂载在快照链的最末端。用户可以将虚拟机从当前状态恢复到快照链中的某个状态，且快照链中任意一个快照都可以删除而不影响其余快照。</p><h2 id="链接克隆"><a href="#链接克隆" class="headerlink" title="链接克隆"></a>链接克隆</h2><p>链接克隆在桌面云解决方案里面有重要的地位，在电信云NFV领域目前暂时没有应用，因此只需要了解链接克隆特性以及与快照的区别即可。</p><p>链接克隆技术是一种通过将源卷和差分卷组合映射为一个链接克隆卷，提供给虚拟机使用的技术。如下图所示，一个链接克隆模板可以创建多个链接克隆差分卷，对应创建多个链接克隆虚拟机。</p><p><img src="https://i.loli.net/2019/05/29/5ceea190153f728001.jpg"></p><p>上图中黄色部分为虚拟机源卷，VM1和VM2两个虚拟机是基于源卷+各自差分卷创建出来的链接克隆虚拟机。链接克隆虚拟机新创建的差分卷初始占用空间很小，随着虚拟机的使用，空间会逐渐膨胀。</p><p><strong>与快照相同的是，链接克隆虚拟机的写IO操作也只会更新到差分卷中，且创建数量和创建时间不限。不同的是，链接克隆虚拟机可以和源虚拟机同时运行，且能同时处于同一网络，但是快照与源虚拟机不能同时运行，自然也就不能处于同一网路。而且，快照主要用于记录源虚拟机某一时间的状态，链接克隆虚拟机主要用于同质业务虚拟机多拷贝分发。虚拟机快照可以在源虚拟机运行时创建，但是链接克隆虚拟机必须在源虚拟机关闭时才能创建。</strong></p><h2 id="存储热迁移"><a href="#存储热迁移" class="headerlink" title="存储热迁移"></a>存储热迁移</h2><p>华为存储虚拟化解决方案支持将虚拟机的磁盘从一个数据存储迁移到另一个数据存储。当需要对数据存储空间进行减容时，这时我们需要将源数据存储上的虚拟机磁盘进行迁移，如下如所示，可以将虚拟机的所有磁盘整体迁移，也可以单个磁盘分别迁移。</p><p><img src="https://i.loli.net/2019/05/29/5ceea204ed9dd83008.jpg"></p><p>在迁移虚拟机虚拟磁盘文件时，虚拟机的快照可以一起迁移（<strong>但只支持关机状态下冷迁移</strong>），且无论虚拟机是开启或者关闭状态，都可以迁移。当虚拟机为关机状态时，这种数据存储间的迁移称为冷迁移，数据存储冷迁移前后性能对比如下：</p><table><thead><tr><th><strong>源存储类型（源配置模式）</strong></th><th><strong>目的存储类型</strong></th><th><strong>配置模式是否变化</strong></th><th><strong>迁移后模式</strong></th><th><strong>是否支持带**</strong>快照迁移**</th></tr></thead><tbody><tr><td>虚拟化存储（普通，延迟置零，精简）</td><td>虚拟化存储（非NAS）</td><td>否</td><td>保持不变</td><td>是</td></tr><tr><td>虚拟化存储（延迟置零）</td><td>虚拟化存储（NAS）</td><td>是</td><td>精简</td><td>是</td></tr><tr><td>虚拟化存储（延迟置零，精简）</td><td>块存储</td><td>是</td><td>普通</td><td>否</td></tr><tr><td>虚拟化存储（普通）</td><td>块存储</td><td>否</td><td>普通</td><td>否</td></tr><tr><td>块存储</td><td>虚拟化存储</td><td>否</td><td>保持不变</td><td>否</td></tr><tr><td>块存储</td><td>块存储</td><td>否</td><td>保持不变</td><td>否</td></tr></tbody></table><p>当虚拟机为开机状态时，这种迁移就称为<strong>存储热迁移</strong>。数据存储冷迁移前后性能对比如下：</p><table><thead><tr><th><strong>源存储类型（源配置模式）</strong></th><th><strong>目的存储类型</strong></th><th><strong>配置模式是否变化</strong></th><th><strong>迁移后模式</strong></th></tr></thead><tbody><tr><td>块存储</td><td>虚拟化存储</td><td>是</td><td>迁移时可以选择为普通延迟置零（NAS不支持）或者精简</td></tr><tr><td>虚拟化存储（普通卷）</td><td>虚拟化存储</td><td>是</td><td>迁移时可以选择为普通延迟置零（NAS不支持）或者精简</td></tr><tr><td>虚拟化存储（延迟置零卷）</td><td>虚拟化存储（非NAS）</td><td>否</td><td>保持不变</td></tr><tr><td>虚拟化存储（延迟置零卷）</td><td>虚拟化存储（NAS）</td><td>是</td><td>精简</td></tr><tr><td>虚拟化存储（精简卷）</td><td>虚拟化存储</td><td>否</td><td>保持不变</td></tr></tbody></table><p><strong>当发生存储热迁移时，同时需迁移虚拟机磁盘镜像和系统内存状态，也就说存储热迁移一般和虚拟机热迁移同步进行。</strong>存储热迁移的示意图如下所示：</p><p><img src="https://i.loli.net/2019/05/29/5ceea2289543282397.jpg"></p><p>在存储热迁移场景下，华为的解决方案并不完美，仍然受以下条件限制：<strong>不支持迁移已挂载为“共享”类型的磁盘</strong>和<strong>链接克隆虚拟机的磁盘</strong>。当虚拟机为“运行中”时，不支持<strong>非持久化磁盘、带快照虚拟机磁盘</strong>和<strong>开启iCache功能虚拟机磁盘</strong>的迁移，可将虚拟机关闭后迁移；当虚拟机为“已停止”时，<strong>如果目标数据存储为块存储，不支持非持久化磁盘、带快照虚拟机磁盘的迁移。</strong></p><p>根据上图，华为存储虚拟化解决方案中存储热迁移的步骤如下：</p><p><strong>Step1：</strong>在目的存储上创建一个与源相同的空镜像文件。</p><p><strong>Step2：</strong>将目的存储的镜像文件设置为源镜像文件的mirror，使虚拟机的I/O写也能落盘在目的存储上，保证了脏块数据的同步。</p><p><strong>Step3：</strong>通过迭代迁移的技术，将源镜像的数据迁移到目的镜像中，保证了基线数据的同步。</p><p><strong>Step4：</strong>在基线数据同步完成后，短暂的时间内暂停虚拟机的I/O请求，将虚拟机的存储文件从源镜像切换到目的镜像上，这样就完成了存储的迁移。</p><p><strong>而且，在华为存储虚拟化解决方案中，可以通过界面设置3种不同热迁移速率，应对不同的业务场景：</strong></p><ul><li><strong>适中</strong>  （迁移速率不高于20M/s，用于存储IO压力较大场景，缓解迁移操作对用户虚拟机的影响）</li><li><strong>快速</strong>   （迁移速率不高于30M/s，用于存储IO压力正常场景，在保证迁移速度的同时可以适当减少对用户虚拟机的影响）</li><li><strong>不限</strong>   （迁移速率不高于1024M/s，用于用户虚拟机业务优先级很低的场景）</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前文《存储虚拟化概述》中，我们提到存储虚拟化与软件定义存储SDS的区别就是其控制平面数据和存储平面数据是一种紧耦合的关系，因此各厂商的存储虚拟化解决方案是一种“私有”方案，不仅不同厂商之间不能兼容，甚至通常不同产品之间有可能不兼容。因此，考虑到电信云NFV的应用场景，以及设备商的分布情况，我们这里主要讨论&lt;strong&gt;华为的虚拟化存储解决方案&lt;/strong&gt;和&lt;strong&gt;华为的分布式存储Fusion Storage&lt;/strong&gt;的情况。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-27-5G：看起来很美，任重而道远</title>
    <link href="https://kkutysllb.cn/2019/05/27/2019-05-27-5G%EF%BC%9A%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%BE%88%E7%BE%8E%EF%BC%8C%E4%BB%BB%E9%87%8D%E8%80%8C%E9%81%93%E8%BF%9C/"/>
    <id>https://kkutysllb.cn/2019/05/27/2019-05-27-5G：看起来很美，任重而道远/</id>
    <published>2019-05-27T14:57:50.000Z</published>
    <updated>2019-05-27T15:11:37.756Z</updated>
    
    <content type="html"><![CDATA[<p><strong>5G：第五代移动通信技术的简称</strong> ，4G技术的延伸，弥补了4G技术的不足，在吞吐率、时延、连接数量、能耗等方面进一步提升系统性能。 5G致力于应对2020年后多样化差异化业务的巨大挑战，满足超高速率、超低时延、高速移动、高能效和超高流量与连接数密度等多维能力指标。 <a id="more"></a></p><h2 id="5G的总体愿景"><a href="#5G的总体愿景" class="headerlink" title="5G的总体愿景"></a>5G的总体愿景</h2><p>5G网络就是第五代移动通信网络。 5G将通信的作用从人与人之间的连接扩展到各行各业、万事万物之间的互相连接，形成崭新的数字化社会、物联网世界新格局。5G将渗透到未来社会的各个领域，以用户为中心构建全方位的信息生态系统。5G将使信息突破时空限制，提供极佳的交互体验，为用户带来身临其境的信息盛宴；5G将拉近万物的距离，通过无缝融合的方式，便捷地实现人与万物的智能互联。5G将为用户提供光纤般的接入速率，“零”时延的使用体验，千亿设备的连接能力，超高流量密度、超高连接数密度和超高移动性等多场景的一致服务，业务及用户感知的智能优化，同时将为网络带来超百倍的能效提升和超百倍的比特成本降低，最终实现“<strong>信息随心至，万物触手及</strong>”的总体愿景。</p><p><img src="https://i.loli.net/2019/05/27/5cebfb9ad46f316989.jpg"></p><p>在最近几年里，普通人了解到 的5G特征往往是速度快。 当前，4G LTE网络服务传输速率实际仅为75Mbps。 而在5G网络中，最早三星电子利用64个天线单元的自适应阵列传输技术，成功地在28GHz波段下达到1Gbps的传输速率，实现了新的突破。 未来5G网络的传输速率可达到10Gbps，这意味着手机用户在不到1s时间内即可下载一部高清电影。</p><p>在通信业内人士眼里，<strong>5G网络的主要目标是让终端用户始终处于联网状态</strong>。5G网络将来支持的设备远远不止是智能手机和平板电脑，它还要承载个人智能通信工具、可穿戴设备等。5G网络将是4G网络的颠覆性升级版，它的基本要求并不仅仅体现在无线网络上，还有为实现5G功能而搭建的核心网、承载网以及接入网。</p><h2 id="5G概念提出的背景"><a href="#5G概念提出的背景" class="headerlink" title="5G概念提出的背景"></a>5G概念提出的背景</h2><p><strong>移动互联网</strong>和<strong>物联网</strong>是推进未来移动通信网络发展的两大驱动力。移动互联网颠覆了传统移动通信业务模式，为用户提供前所未有的、多样化的使用体验，深刻影响着人们工作生活的方方面面。物联网扩展了移动通信的服务范围，从人与人通信延伸到物与物、人与物智能互联，使移动通信技术渗透至更加广阔的行业和领域。2014年到2019年全球IMT流量将进一步快速增长，总的流量上涨倍数达到几十到100倍。中国国内由国家技术创新委员会、工信部和发改委组织的IMT-2020（5G推进组）于2014年发布的《 5G愿景与需求白皮书》中预计，2010~2020年全球移动数据流量增长将超过200倍，2010~2030年 将增长近20000倍。中国的移动数据流量增速高于全球平均水平，预计2010~2020年将增长300倍上，2010~2030年将增长超过40000倍。发达城市及热点地区的移动数据流量增速更快，2010~2020 年上海移动数据流量的增长率可达原来的600倍，北京热点区域移动数据流量的增长率可达原来的1000 倍。</p><p><img src="https://i.loli.net/2019/05/27/5cebfbc6bfc7272260.jpg"></p><p>另外，<strong>我国“互联网+”国家战略需求中明确指出：未来电信基础设施和信息服务要在国民经济中下沉，满足农业、医疗、金融、交通、流通、制造、教育、生活服务、公共服务、教育和能源等垂直行业的信息化需求，改变传统行业，促生跨界创新</strong>。因此，未来5G网络不仅需要继续面对移动互联网业务带来的挑战，例如：频谱效率和用户体验速率的提升，时延的减少，移动性的增强等，同时还需要满足物联网多样化的业务需求。</p><p>从信息交互对象不同的角度出发，目前5G应用分为三大类场景：<strong>增强移动宽带（eMBB）、海量机器类通信（mMTC）</strong>和<strong>超可靠低时延通信（uRLLC）</strong>。eMBB 场景是指在现有移动宽带业务场景的基础上， 对于用户体验等性能的进一步提升，主要还是追求人与人之间极致的通信体验。mMTC 和 uRLLC都是物联网的应用场景，但各自侧重点不同。mMTC 主要是人与物之间的信息交互，而 uRLLC 主要体现物与物之间的通信需求。未来全球移动通信网络连接的设备总量将达到千亿规模。预计到2020年，全球移动终端（不含物联网设备）数量将超过100 亿，其中中国将超过20亿。全球物联网设备连接数也将快速增长， 2020年将接近全球人口规模达到70亿，其中中国将接近15亿。</p><p><img src="https://i.loli.net/2019/05/27/5cebfbe93d9b616173.jpg"></p><h2 id="5G的三大业务模式"><a href="#5G的三大业务模式" class="headerlink" title="5G的三大业务模式"></a>5G的三大业务模式</h2><p>为了更好的面向数字化的世界，服务数字化的社会，全球范围内的运营商都在进行数字化转型。<strong>运营商数字化转型的目标在于为企业客户、消费者提供 ROADS (Real- time, On-Demand, All online, DIY, Social) 体验</strong>，这需要通过端到端协同整体架构才能够实现，需要在各个环节都实现敏捷，自动化和智能化。<strong>运营商的网络、运营系统、业务的全面云化是必要条件和实现手段。</strong></p><p>5G 时代将以一张物理的基础网络支撑多种不同的商业需求，<strong>云化的端到端网络架构</strong>通过以下几个方面实现上述需求：</p><p><img src="https://i.loli.net/2019/05/27/5cebfc0d0c78552089.jpg"></p><ul><li>在同一套物理基础设上基于不同的业务需求生成逻辑隔离的独立运行的网络切片，通过基于数据中心的云化架构支撑多种应用场景。</li><li>利用CloudRAN对无线接入网络进行重构，满足5G时代多技术连接以及RAN功能按需部署的需求。</li><li>通过控制面和用户面（C/U）分离，功能模块化以及统一的数据库管理技术简化核心网络架构，实现网络功能的按需配置。</li><li>基于应用驱动来自动的生成，维护，终止网络切片服务， 利用敏捷的网络运维降低运营商的运营成本。</li></ul><p>5G时代新的通信需求对现有网络提出了包括<strong>技术上的，商业模式上</strong>的种种挑战，需要下一代移动网络来满足。ITU将5G时代的主要移动网络业务划分为三 类：<strong>eMBB（Enhanced Mobile Broadband）, uRLLC(Ultra-reliable and Low-latency Communications)</strong> 以 及 <strong>mMTC（Massive Machine Type Communications）</strong>。</p><p><img src="https://i.loli.net/2019/05/27/5cebfc3b4bb4399954.jpg"></p><p><strong>eMBB 聚焦对带宽有极高需求的业务</strong>，例如高清视频，虚拟现实/增强现实等等，满足人们对于数字化生活的需求。比如：移动的环境中，网联无人机对大带宽、低时延的需求，将会引爆众多高价值创新行业应用。初期可以采用4G拓展应用，后续随着5G引入业务体验更好、创新应用更多。</p><p><img src="https://i.loli.net/2019/05/27/5cebfc611a93087287.jpg"></p><p><strong>uRLLC 聚焦对时延极其敏感的业务</strong>，例如自动驾驶/辅助驾驶，远程控制等，满足人们对于数字化工业的需求。比如：5G技术可满足车联网低时延、高速、高可靠性的业务需求，可以重新定义汽车安全，促使车联网创新应用成为现实。</p><p><img src="https://i.loli.net/2019/05/27/5cebfc83729d444773.jpg"></p><p><strong>mMTC 则覆盖对于联接密度要求较高的场景</strong>，例如智慧城市，智能农业，满足人们对于数字化社会的需求。比如：奠基国家工业互联网，助力中国制造2025，采用授权频率，使用4G/5G及有线网络等技术，基于运营商的泛在网络，为工业互联网工厂内外数据应用提供连接服务，主要包含<strong>采集类、控制类、监测类</strong>等应用。</p><p><img src="https://i.loli.net/2019/05/27/5cebfc9f0e9bf32000.jpg"></p><h2 id="5G的技术定义"><a href="#5G的技术定义" class="headerlink" title="5G的技术定义"></a>5G的技术定义</h2><p>5G（第五代移动通信）是IMT（国际移动通信）的下一阶段，ITU（国际电信联盟）将其正式命名为IMT-2020。目前，ITU正在对IMT-2020进行初步的规划。此外，端到端系统的大多数其他变革（既包括核心网络内的，又包括无线接入网络内的）也将会成为未来5G系统的一部分。在移动通信市场中，IMT-Advanced（包括LTE-Advanced与WMAN-Advanced）系统之后的系统即为“<strong>5G</strong>”。</p><p>在大力研发5G潜在“候选技术”的同时，全球移动通信行业对于5G技术研发驱动的理解也逐步达成了共识。<strong>ITU-R（国际电信联盟无线电通信局）确定未来的5G具有以下三大主要的应用场景：1）增强型移动宽带；2）超高可靠与低延迟的通信；3）大规模机器类通信。</strong>具体包括吉比特每秒移动宽带数据接入、智慧家庭、智能建筑、语音通话、智慧城市、三维立体视频、超高清晰度视频、云工作、云娱乐、增强现实、行业自动化、紧急任务应用、自动驾驶汽车等。</p><p>一项技术创新可以分为<strong>渐进式创新、模块创新、架构创新</strong>和<strong>彻底创新</strong>4类。从2G到4G是频谱效率和安全性等逐步提升的渐进式创新，也是在维持集中式网络构架下的模块式创新，还有从网络构架向扁平化和分离化演进的架构创新。但到了5G时代，除了网络能力以外，还必须面向各种新的行业服务，提供随时需要的、高质量的连接服务，这也要求5G网络的建设是多方位的、彻底的创新。</p><p>移动网络架构架主要包括<strong>核心网</strong>和<strong>无线接入网</strong>，到了5G时代，移动网络按循序渐进的方式引入5G网元设备。 </p><p><img src="https://i.loli.net/2019/05/27/5cebfcd038b5b25267.jpg"></p><blockquote><p><strong>Step1：</strong>5G NR（新无线）先行， 5G基站（gNodeB）与4G基站（eNodeB）以双连接的方式共同接入4G核心 网。 </p><p><strong>Step2：</strong>5G基站独立接入5G核心网（NGCN，下一代核心网）。</p><p><strong>Step3：</strong>5G基站和4G基站统统接入5G核心网，4G核心网退出历史舞台。</p></blockquote><p>以上5G网络架构演进看似整体一致，实际上，我们把核心网和无线接入网分开来看，其内部架构发生了颠覆性的改变。核心网的网元由4G时代的MME/SAE-GW变为5G时代的AMF/UPF（AMF/UPF是由中国移动牵头提出的SBA 5G核心网基础架构）。</p><ul><li><strong>AMF（Mobility Management Function）</strong>负责控制面的移动性和接入管理，代替了MME的功能。 </li><li><strong>UPF（User Plane Function）</strong> 负责用户面，它代替了原来4G中执行路由和转发功能的SGW和PGW。 </li></ul><p>另外一个概念是<strong>5G系统服务架构</strong>，这<strong>是一个基于云原生设计原则的架构，不仅要对传统4G核心网网元NFV虚拟化，网络功能还将进一步软件模块化，实现从驻留于云到充分利用云的跨越</strong>，以实现未来以软件化、模块化的方式灵活、快速地组装和部署业务应用。</p><p><img src="https://i.loli.net/2019/05/27/5cebfd065352515880.jpg"></p><p>为了灵活应对智慧城市、车联网、物联网等多样化的服务，使能网络切片，核心网基于云原生构架设计，面临毫秒级时延、海量数据存储与计算等挑战，云化的C-RAN构架和实时的移动边缘计算（MEC）应运而生。 从核心网到接入网，未来5G网络将分布式部署巨量的计算和存储于云基础设施之中，<strong>核心数据中心和分布式云数据中心构成网络拓扑的关键节点</strong>。这是一场由海量数据引发的从量变到质变的数据革命，是一场由技术创新去推动社会进步的革命，因此，5G需广泛地与各行业深入合作，共同激发创新，从而持续为社会创造价值。</p><p>无线接入网发生的主要改变是<strong>分离</strong>，首先是控制面和用户面的分离，其次是基站被分离为AAU、DU和CU这3个部分。</p><p><img src="https://i.loli.net/2019/05/27/5cebfd26baf2c95934.jpg"></p><p>5G无线关键技术有<strong>微基站（Small Cell）</strong>和<strong>Massive MIMO</strong>。 5G的容量需求是4G的1000倍，峰值速率10～20Gbps，要提升容量和速率无非就是<strong>增大频谱带宽、提升频谱效率</strong>和<strong>增加小区数量</strong>“三板斧”操作。 首先是频谱带宽，高频段的频率资源丰富，同时，目前小于3GHz的低频段基本被2G/3G/4G占用（中国移动的5G目前规划为2.6G整频段，电联需要退出目前4G的占用），所以，5G必然要向高频段3.5～30GHz（甚至更高）扩展。那么如何解决频段越高，穿透能力越差，覆盖范围越小的问题就引出了 5G的两大关键技术—<strong>Massive MIMO</strong>和<strong>微基站</strong>。 </p><p><strong>微基站已成为未来解决网络覆盖和容量的关键。</strong>未来城市路灯、广告牌、电杆等各种街道设施都将成为微基站挂靠的地方。<strong>Massive MIMO就是在基站侧配置远多于现有系统的大规模天线阵列的MU-MIMO，来同时服务多个用户。</strong>它可以大幅提升无线频谱效率，增强网络覆盖和系统容量，简言之， 就是通过分集技术提升传输可靠性、空间复用提升数据速率、波束赋形提 覆盖范围。 MU-MIMO将多个终端联合起来空间复用，同时使用多个终端的天线，这样一来，大量的基站天线和终端天线形成一个大规模的、虚拟的MIMO信道系统。这是从整个网络的角度更宏观地去思考提升系统容量。</p><p><strong>波束赋形</strong>是指大规模多天线系统可以控制每一个天线单元的发射（或接收）信号的相位和信号幅度，产生具有指向性的波束，消除来自四面八方的干扰，增强波束方向的信号。它可以补偿无线传播损耗。</p><p>国家政策驱动下，<strong>“企业上云”</strong>的进程将进一步加快。云业务的发展，对网络需求自内生而建，使两者从独立走向融合。5G超高速上网和万物互联将产生呈指数级上升的海量数据，这些数据需要云存储和云计算，并通过大数据分析和人工智能产出价值。与此同时，为了面向未来多样化和差异化的5G服务，<strong>一场基于虚拟化、云化的ICT融合技术革命正在推动着网络重构与转型。</strong></p><p><img src="https://i.loli.net/2019/05/27/5cebfd5335d1f73825.jpg"></p><p>引入新的组件： <strong>编排器和网络控制器</strong>，地市城域网实现互连、地市PTN网络实现互连、新增云专线网关，最终实现“云+专线” 融合业务的自动化发放。</p><h2 id="关于5G的标准"><a href="#关于5G的标准" class="headerlink" title="关于5G的标准"></a>关于5G的标准</h2><h3 id="ITU和3GPP"><a href="#ITU和3GPP" class="headerlink" title="ITU和3GPP"></a>ITU和3GPP</h3><p><strong>5G最重要的标准化组织有ITU和3GPP</strong>。其中，<strong>ITU是联合国负责国际电信事务的专业机构</strong>，其下分为电信标准化部门（ITU-T）、无线电通信部门（ITU-R）和电信发展部门（ITU-D），每个部门下设多个研究组，每个研究组下设多个工作组，<strong>5G的相关标准化工作是在ITU-R WPSD 下进行的</strong>。ITU-R WPSD是专门研究和制订移动通信标准IMT（包括IMT-2000和IMT-Advanced）的组织，根据ITU的工作流程，<strong>每一代移动通信技术国际标准的制订过程包括业务需求、频率规划和技术方案3个部分</strong>，当前对5G的时间表已经确定了3个阶段：</p><ul><li>第一个阶段截至2015年底，完成IMT-2020国际标准前期研究，重点是完成5G宏观描述，包括5G的愿景、5G的技术趋势和ITU的相关决议，并在2015年世界无线电大会上获得必要的频率资源；</li><li>第二个阶段是2016~2017年底，主要完成5G性能需求、评估方法研究等内容；</li><li>第三个阶段是收集5G的候选方案。 </li></ul><p><strong>而3GPP是一个产业联盟，其目标是根据ITU的相关需求，制订更加详细的技术规范与产业标准，规范产业行为。</strong>3GPP（the 3rd Generation Partnership Project）是领先的3G技术规范机构，是由欧洲的ETSI、日本的ARIB和TTC、韩国的TTA、美国的T1和中国的无线通信组CWTS共6个标准化组织伙伴组成。3GPP的会员包括组织伙伴、市场代表伙伴和个体会员3类。3GPP市场代表伙伴不是官方的标准化组织，它们是向3GPP提供市场建议和统一意见的机构组织。</p><h3 id="5G的几个3GPP阶段性标准"><a href="#5G的几个3GPP阶段性标准" class="headerlink" title="5G的几个3GPP阶段性标准"></a>5G的几个3GPP阶段性标准</h3><p>根据3GPP此前公布的5G网络标准制订过程，5G整个网络标准分几个阶段完成，如下图所示。</p><p><img src="https://i.loli.net/2019/05/27/5cebfd8e8fe7f16722.jpg"></p><p><strong>2017年12月21日，在国际电信标准组织3GPP RAN第78次全体会议上，5G NR（New Radio）首发版本正式发布，这是全球第一个可商用部署的5G标准。</strong> 非独立组网的NSA 5G标准被冻结，但这只是一种过渡方案，仍然依托4G基站和网络，只是空口采用5G，算不上真正的5G标准。 非独立组网标准的确立，可以让一些运营商在已有的4G网络上进行改造，在不进行大规模设备替换的前提下，将移动 网速提升到5G网络，即1Gbps速率。</p><p><strong>R15阶段重点满足增强移动宽带（eMBB）和低时延高可靠（uRLLC）应用需求</strong>，该阶段又分为两个子阶段：<strong>第一个子阶段，5G NR非独立组网特性已于2017年12月完成，2018年3月冻结</strong>；<strong>第二个子阶段，5G NR独立组网标准于2018年6月14日冻结。</strong>2018年6月，已经完成了5G独立组网（SA）标准，支持增强移动宽带和低时延高可靠物联网，完成了网络接口协议定义。现在的R15 5G标准只能算是第一阶段，重点满足增强移动宽带（eMBB）和低时延高可靠（uRLLC）应用需求，可用于设计制造专业5G设备以及网络建设，单独建立一张全新的5G网络，可以满足超高视频、VR直播等对移动带宽需求大的业务，而无人驾驶、工业自动化等需要高可靠连接的业务也有了网络保证。</p><p>5G第二个标准版本R16计划于2019年12月完成，2020年3月冻结，全面满足eMBB、uRLLC、大连接低功耗场景mMTC 等各种场景的需求。可以说，预计2020年3月形成的5G标准才是完整的5G标准。<strong>5G技术标准由3GPP确定之后，还需要经过ITU认定。</strong></p><h3 id="解读3GPP-R15"><a href="#解读3GPP-R15" class="headerlink" title="解读3GPP R15"></a>解读3GPP R15</h3><p><strong>2018年6 月14日， 3GPP 全会批准了首个5G独立组 网（SA）标准，这意味着3GPP首个完整的5G标准R15正式落地，5G产业链进入商用阶段。</strong>3GPP正式最终确定5G第二阶段标准（R16）的15个研究方向。</p><table><thead><tr><th>序号</th><th>研究方向</th><th>研究内容</th></tr></thead><tbody><tr><td>1</td><td>MIMO的进一步演进</td><td>多用户MU-MIMO、Mutil-TRP和波束管理增强。</td></tr><tr><td>2</td><td>52.6GHz以上的新空口</td><td>将对5G系统使用 52. 6GHz 以上的频谱资源进行研究。</td></tr><tr><td>3</td><td>5G NR双链接完善</td><td>新增异步NR-NR双链接方案研究。</td></tr><tr><td>4</td><td>无线接入/无线回传一体化</td><td>3GPP将在R16阶段继续研究并考虑无线接入/无线回传一体化设计。</td></tr><tr><td>5</td><td>工业物联网</td><td>5G第二阶段标准（R16）将进一步研究URLLC（超高可靠与低时延信）增强来满足诸如“工业制造”“电力控制” 等更多的5G工业物联网应用场景。</td></tr><tr><td>6</td><td>5G新空口移动性增强</td><td>包括提高移动过程的可靠性、缩短由移动导致的中断时间。</td></tr><tr><td>7</td><td>基于5G新空口的V2X</td><td>研究基于5G新空口的V2X技术，使得其满足由SA1定义的“高级自动驾驶”应用场景，与LTE V2X形成“互补”。</td></tr><tr><td>8</td><td>5G新空口的新型定位方式</td><td>研究更精确的定位技术，包括“RAT-dependent” 以及混合定位技术。</td></tr><tr><td>9</td><td>非正交多址接入NOMA</td><td>面向5G的NOMA有多种候选技术。而R16将研究潜在的技术方案并完成标准化工作。</td></tr><tr><td>10</td><td>5G NR-U</td><td>在5G第二阶段标准（R16）中，5G NR-U需可利用非授权频谱提升5G系统容量。</td></tr><tr><td>11</td><td>非地面5G网络</td><td>研究面向“非地面5G网络”的物理层的控制机制、随机接入和HARQ切换、系统架构等。</td></tr><tr><td>12</td><td>远程干扰管理+交叉链路干扰抑制</td><td>5G第二阶段标准（R16）将研究如何识别造成强干扰的远端5G基站，以及如何进行干扰抑制。</td></tr><tr><td>13</td><td>5G终端能力</td><td>5G第二阶段标准（R16）将研究5G终端上报“终端能力”并降低5G终端上报信令开销的方法。</td></tr><tr><td>14</td><td>5G新空口以无线接入网为中心的数据收集与利用</td><td>5G第二阶段标准（R16）将研究SON、MDT等技术。</td></tr><tr><td>15</td><td>5G新空口终端功耗</td><td>5G第二阶段标准（R16）将研究5G终端工作在“CONNECTED”模式下如何降低功耗。</td></tr></tbody></table><p>2018年6月发布的SA标准完成了5G核心网架构，实现了5G独立组网。<strong>此次独立组网标准的冻结，让5G确定了全新的网络架构和核心网组网方式，让网络向IT化、互联网化、极简化、服务化转变。</strong></p><p><strong>在IT化方面，全软件化的核心网实现了统一的IT基础设施和调度。功能软件化、计算和数据分离是代表性的技术。</strong>传统“网元”重构为5G的“网络功能”，以“软件”的形式部署，充分发挥云化、虚拟化技术的 优势。将处理逻辑和数据存储分离，更便于提升系统的可靠性、动态性、大数据分析的能力。</p><p><strong>在互联网化方面，从固定网元、固定连接的刚性网络到动态调整的柔性网络。服务化架构（SBA，Service- based Architecture）、新一代核心网协议体系（基于HTTP2. 0/JSON）是其代表性技术。</strong>SBA的设计是由模块化、可独立管理的“服务”来构建的。服务可灵活调用、灰度发布，实现网络能力的按需编排和快速升级。传统电信特有的接口协议代之以互联网化的API调用，使得5G网络更加开放、灵活。</p><p><strong>在极简化方面，极简的转发面提高性能，集中灵活的控制面提升效率。C/U分离（控制面和用户面离）、新型移动性及会话管理是其代表性技术。</strong>通过C/U分离，一方面实现控制面集中部署、集中管控、集中优化，另一方面实现用户面功能简化，实现高效、低成本、大流量的数据转发。移动性管理和会话管理解耦，使得终端可以按需建立会话连接，节省了网络地址和存储资源。同时，针对不同的终端类型定义了多种类型的移动性管理，简化了终端和网络的状态。</p><p><strong>在服务化方面，从通用化服务到个性化、定制化服务。网络切片、边缘计算是其代表性技术。</strong>网络切片提供定制化、逻辑隔离、专用的端到端虚拟移动络（包括接入网、核心网），是5G面向垂直行业、实现服务可保障的基本技术形式。而边缘计算将网络的功能应用靠近用户部署，使得极致的低时延、本地特色应用成为可能，是5G满足如智能工厂等垂直行业业务需求的重要基础。</p><p>同时，在无线侧，5G NR为<strong>设计、架构、频段、天线</strong>4个方面带来新变化。</p><p><strong>在设计上，与以往通信系统不同，通信行业和垂直行业的跨界融合是5G发展的关键之一</strong>。为满足垂直行业的各种差异性需求，并应对部署场景的多样性与复杂性，5G在帧结构等方面提出了全新的设计。与4G相比，5G提供了更多可选择的帧结构参数，可根据5G基础通信业务、物联网和车联网等多样化应用场景，以及宏基站、小基站等不同网络部署需求灵活地配置，通过“软件定义空口”的设计理念使无线信号“量体裁衣”，通过同一个空口技术来满足5G多样化的业务需求，大幅提升5G网络部署的效率。</p><p><strong>在架构上，为了使组网方式更加灵活并提升网络效率，5G引入了接入网CU/DU分离的无线接入网架构，</strong>可将基站的功能分成实时处理的DU部分和非实时处理的CU部分，从而使得中心单元CU可以部署到集中的物理平台，以承载更多的小区和用户，提升了小区间协作和切换的效率。</p><p><strong>在频段上，5G系统需要不同频段来共同满足其覆盖、容量、连接数密度等关键性能指标要求。因此，与4G不同的是，5G通过灵活的参数设计（子载波间隔和CP长度等），可支持更大范围的频率部署，</strong>包括6GHz以下以及6GHz以上的毫米波频段。其中，6GHz以下频段主要用于实现5G系统的连续广域覆盖，保证高移动性场景下的用户体验以及海量设备的连接；而6GHz以上频段能够提供连续较大宽，可满足城市热点、郊区热点与室内场景极高的用户体验速率和极高容量需求。</p><p><strong>在天线上，5G支持大规模天线大幅度提升系统效率。</strong>大规模天线实现三维的波束赋形，形成能量更集中、覆盖更立体、方向更精准的波束。在大规模天线的架构下，波束扫描与波束管理等多个5G先进技术成为可能，网络覆盖及用户体验的顽健性可得到进一步的提升，实现更好的控制信道和业务信道的覆盖平衡。</p><h2 id="我国提出的5G目标"><a href="#我国提出的5G目标" class="headerlink" title="我国提出的5G目标"></a>我国提出的5G目标</h2><p>随着IMT-2020（5G）推进组发布5G试验第三阶段规范，5G预商用开始进入倒计时。此前在2017年12月1日，3GPP的5G第一个标准冻结，打响了全球5G市场竞赛的发令枪。在全球产业链的共同推动下，5G商用时间点不断被提前。</p><p>我们移动通信领域在经历了“<strong>2G追赶，3G突破，4G并进</strong>”的进阶之后，在即将到来的5G时代，我国通信业正在酝酿一出更加精彩的大戏—“<strong>5G引领</strong>”，这是中国移动通信产业提出的新目标。要实现5G引领，从2017年年底到今年年初各方面的一系列动作看，我国正在政策引导、频率规划和技术创新等多方面协同发力。</p><p><img src="https://i.loli.net/2019/05/27/5cebfddf65c7e50019.jpg"></p><p>当前，全球多国正积极筹备5G试商用。日前，美国运营商AT＆T已经明确宣布：“2018年将会在十余个美国城市首先推出5G服务，其部署的5G将是3GPP不久前刚刚批准的5G标准。”亚洲其他国家也已经宣布5G商用时间表，其中，韩国将于2018年平昌冬奥会期间实现5G预商用，而日本预计将于2020年为东京奥运会提供5G商用服务。</p><p>目前，国内布局5G的步伐还在不断加快，中国5G第三阶段试验大幕已经拉开。<strong>第三阶段的重点是面向5G商用前的产品研发、验证和产业协同，开展商用前的设备单站、组网、互操作，及系统、芯片、仪表等产业链上下游的互联互通测试，全面推进产业链主要环节基本达到预商用水平。</strong>目前，根据国内三大运营商规划，2018年已经开始陆续在主要城市进行5G试验，2019年则进行规模试商用，2020年正式开始商用部署。中国移动前期预计在若干城市建设每城20个基站的预商用试验网，中国电信表示将在2018年之前完成原型无线组网的验证阶段，目前在广东深圳、成都、兰州、江苏苏州、上海、河北雄安六地启动中国电信5G示范网试验。中国联通目前正在加快推进相关研究工作，计划2018年在多个城市启动5G外场试验工作，2019年进一步扩大试验规模。</p><p><strong>作为5G发展的基础性资源，频谱对5G商用进展有至关重要的作用。</strong>2017年11月，我国率先发布了5G系统在中频段频谱使用规划，明确将3300-3400MHz（原则上限室内使用）、3400-3600MHz和4800-5000MHz频段作为5G系统的工作频段。与之前2G、3G、4G相比，5G具备远超以往的带宽、更高的速率，且同时支持千亿级物联网设备的连接，5G所需频谱数量也远超之前几代移动通信之和。与此同时，为了实现移动宽带、低时延、超大规模组网三大应用场景，5G系统在规划之初就确定了“<strong>全频段”，需要从高频、中频、低频统筹规划。</strong></p><p>在低频段大多为现有2G、3G和4G占用的情况下，在中频段上，3.5GHz频段因为有利于信号覆盖，被全球多个国家视为5G网络的先锋频段。目前，<strong>我国已为IMT分配522MHz，低频段频谱需求808-1078MHz，频谱缺口300-500MHz。</strong></p><p>在中国IMT-2020（5G）推进组的领导下，以中国移动为代表的中国企业发挥了重要的作用，贡献的文稿数占整个项目文稿数的半壁江山。<strong>5G系统架构（5GS）项目由中国移动担任报告人主导完成，并得到全球超过67家合作伙伴的大力支持，是中国人首次牵头设计新一代移动网络的系统架构。</strong>在全球运营商中，中国移动的文稿贡献数和通过数都排在第一位。</p><p><img src="https://i.loli.net/2019/05/27/5cebfe022ec7763508.jpg"></p><p>还有，华为在5G核心技术上作出了与其市场体量相匹配的创新贡献，在5G编码技术、多址技术、空口技术、天线技术、网络架构、物联网接入、用户体验保证上都有原创型技术，这些原创技术在3GPP前一阶段的5G关键技术“选美”中获选，随着标准的冻结，固化为国际标准。</p><p>中兴近年来也一直致力于对包括Massive MIMO、MUSA（多用户共享接入）、FB-OFDM（滤波器组OFDM）、虚拟和网络分片等在内的核心5G技术进行研发，并携手产业链合作伙伴，共同推动5G研发进程。</p><p><strong>从2G到5G，中国实现了从追赶走向引领，在通信领域前所未有地接近世界大格局的中央。5G引领，符合国家“强国战略，中华民族伟大复兴”的战略目标，需要政府、运营商、设备商以及社会各行各业发生共振效应，共同努力才能实现。整个过程任重而道远，需要我们不忘初心，砥砺前行。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;5G：第五代移动通信技术的简称&lt;/strong&gt; ，4G技术的延伸，弥补了4G技术的不足，在吞吐率、时延、连接数量、能耗等方面进一步提升系统性能。 5G致力于应对2020年后多样化差异化业务的巨大挑战，满足超高速率、超低时延、高速移动、高能效和超高流量与连接数密度等多维能力指标。
    
    </summary>
    
      <category term="5G解决方案" scheme="https://kkutysllb.cn/categories/5G%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
    
      <category term="5G" scheme="https://kkutysllb.cn/tags/5G/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-27-存储虚拟化概述</title>
    <link href="https://kkutysllb.cn/2019/05/27/2019-05-27-%E5%AD%98%E5%82%A8%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A6%82%E8%BF%B0/"/>
    <id>https://kkutysllb.cn/2019/05/27/2019-05-27-存储虚拟化概述/</id>
    <published>2019-05-27T01:50:25.000Z</published>
    <updated>2019-05-27T02:03:13.178Z</updated>
    
    <content type="html"><![CDATA[<h2 id="存储虚拟化概述"><a href="#存储虚拟化概述" class="headerlink" title="存储虚拟化概述"></a><strong>存储虚拟化概述</strong></h2><p>存储虚拟化（StorageVirtualization）最通俗的理解就是对<strong>存储硬件资源进行抽象化表现</strong>。这种虚拟化可以将用户与存储资源中大量的物理特性隔绝开来，就好像我们去仓库存放或者提取物品一样，只要跟仓库管理员打交道，而不必关心我们的物品究竟存放在仓库内的哪一个角落。对于用户来说，虚拟化的存储资源就像是一个巨大的“<strong>存储池</strong>”，用户不会看到具体的存储磁盘、磁带，也不必关心自己的数据经过哪一条路径通往哪一个具体的存储设备。<a id="more"></a></p><p><img src="https://i.loli.net/2019/05/27/5ceb42a15d14167158.jpg"></p><p>存储虚拟化减少了物理存储设备的配置和管理任务，同时还能够充分利用现有的存储资源。存储虚拟化的方式是将整个云系统的存储资源进行统一整合管理，为用户提供一个统一的存储空间。如下图所示：</p><p><img src="https://i.loli.net/2019/05/27/5ceb42c95607517538.jpg"></p><h2 id="传统存储面临的挑战"><a href="#传统存储面临的挑战" class="headerlink" title="传统存储面临的挑战"></a>传统存储面临的挑战</h2><p>传统的数据中心里，存储的类型大致可分为以下几种：<strong>服务器内置磁盘、直接附加存储、存储区域网络</strong>及<strong>网络附加存储。</strong></p><p><strong>服务器内置磁盘</strong>包括SCSI、SATA及IDE磁盘等，这些磁盘可能直接由操作系统管理，也可能通阵列卡等RAID管理器进行配置使用（常见的有RAID 1、RAID 10、RAID 5、RAID 6等）。内置磁盘作为最简单直接的存储方式，在目前数据中心里仍然到处可见。服务器磁盘RAID阵列数据组织模式如下：</p><p><img src="https://i.loli.net/2019/05/27/5ceb4313377ef19877.jpg"></p><p><strong>直接附加存储（Directed Attached Storage，DAS）</strong>作为一种最简单的外接存储方式，通过数据线接连接在各种服务器或客户端扩展接口上。它本身是硬件的堆叠，不带有任何存储操作系统，因而也不能独立于服务器对外提供存储服务。DAS常见的形式是外置磁盘阵列，通常的配置就是RAID控制器+一堆磁盘。DAS安装方便、成本较低的特性使其特别适合于对存储容量要求不高、服务器数量较少的中小型数据中心。如下图所示：</p><p><img src="https://i.loli.net/2019/05/27/5ceb4329ab8ae55789.jpg"></p><p><strong>存储区域网络（Storage Area Network，SAN）</strong>是一种高速的存储专用网络，通过专用的网络交换术连接数据中心里的所有存储设备和服务器。在这样的存储网络中，<strong>存储设备与服务器是多对多的服务关系</strong>：一台存储设备可以为多台服务器同时提供服务，一台服务器也可以同时使用来自多台存储设备的存储服务。不同于DAS，SAN中的存储设备通常配备智能管理系统，能够独立对外提供存储服务。SAN存储网络系统结构图如下：</p><p><img src="https://i.loli.net/2019/05/27/5ceb434b6c2f940368.jpg"></p><p>典型的 SAN利用光纤通道（Fiber Channel，FC）技术连接节点，并使用光纤通道交换机（FC Switch）提供网络交换。<strong>不同于通用的数据网络，存储区域网络中的数据传输基于FC协议栈。在FC协议栈之上运行的SCSI协议提供存储访问服务。</strong>与之相对的iSCSI存储协议，则提供了一种低成本的替代方式 即将SCSI协议运行于TCP/IP协议栈之上。为了区别这两种存储区域网络，前者通常称为FC SAN，后者称为IP SAN。由于SAN存储采用网络架构和光纤传输，使它具有易部署、扩展强、传输快等优势，传输速率可达8~16Gbps。数据中心常见的SAN交换机如下图所示：</p><p><img src="https://i.loli.net/2019/05/27/5ceb436dddc3837134.jpg"></p><p><strong>网络附加存储（Network Attached Storage，NAS）</strong>提供了另一种独立于服务器的存储设备访问方（相对于内置存储与DAS）。类似于SAN，NAS也是通过网络交换的方式连接不同的存储设备与服务器。同样，<strong>存储设备与服务器之间也一种多对多的服务关系</strong>。NAS服务器通常也具有智能管理系统，能够独立对外提供服务。与SAN不同的是，NAS基于现有的企业网络（即TCP/IP网络），不需要额外搭建昂贵的专用存储网络（FC）。此外<strong>NAS通过文件I/O的方式提供存储，这点也不同于SAN的块 I/O访问方式。</strong>NAS存储的架构示意图如下：</p><p><img src="https://i.loli.net/2019/05/27/5ceb43961ff6b63941.jpg"></p><p><strong>常见的NAS访问协议有NFS（Network File System）和CIFS（Common Internet File System）</strong>，因此允许多台服务器以共享的方式访问同一个数据存储单元LUN。而且，由于<strong>NAS内部嵌入了一个精简的专门用于存储的操作系统，集成了网络传输和I/O访问等协议</strong>，因此NAS存储独立于用户操作系统，可在线扩展，且部署容易，管理成本低（相对SAN存储）。实际中的常见的NAS产品，比如群晖NAS产品实物图如下：</p><p><img src="https://i.loli.net/2019/05/27/5ceb43aedb34851404.jpg"></p><p>随着云计算与软件定义数据中心的出现，对存储管理有了更高的要求，传统存储也面临着诸多前所未有的挑战：</p><p>对于服务器内置磁盘和DAS来说，单一磁盘或阵列的容量与性能都是有限的，而且也很难对其进行扩展。另外这两种存储方式也缺乏各种数据服务，例如数据保护、高可用性、数据去重等。最大的麻烦在于这样的存储使用方式<strong>导致了一个个的信息孤岛，这对于数据中心的统一管理来说无疑是一个噩梦。</strong></p><p>对于SAN和NAS来说，目前的解决方案首先存在一个<strong>厂商绑定的问题</strong>。与服务器的标准化趋势不同，存储产品的操作系统（或管理系统）仍然是封闭的。不仅不同厂商之间的系统互不兼容，而且一家厂商的不同产品系列之间也不具有互操作性，这必然导致高价和技术壁垒。此外，<strong>管理孤岛的问题依旧存在</strong>，相对于DAS来说只是岛大一点，数量少一点而已。最后，<strong>SAN与NAS的扩展性</strong>也仍然是个问题。</p><p>另外，一些全新的需求，比如：对多租户（Multi-Tenancy）模式一致性支持、云弹性（Cloud-Scale）的动态迁移服务支持、动态定制的数据服务（Data Service）以及直接服务虚拟网络的应用等。这些需求并不是通过对传统存储架构的简单修修补补就可以满足的。</p><h2 id="存储虚拟化的定义"><a href="#存储虚拟化的定义" class="headerlink" title="存储虚拟化的定义"></a>存储虚拟化的定义</h2><p>为了解决上述挑战，存储虚拟化和软件定义存储SDS的概念日趋火热，但是需要注意一点—<strong>存储虚拟化并不等于软件定义存储SDS，准确点讲存储虚拟化是软件定义存储的一个具体实现。</strong>存储虚拟化的本质是存储整合的一个重要组成部分，它能减少管理问题，而且能够提高存储利用率，这样可以降低新增存储的费用。权威机构SNIA（存储网络工业协会）给出的定义为：<strong>通过将存储系统/子系统的内部功能从应用程序、计算服务器、网络资源中进行抽象、隐藏或隔离，实现独立于应用程序、网络的存储与数据管理。</strong></p><p>总结起来就是：<strong>存储虚拟化技术将底层存储设备进行抽象化统一管理，向服务器层屏蔽存储设备硬件的特殊性，而只保留其统一的逻辑特性，从而实现了存储系统的集中、统一、方便的管理。</strong></p><p>与传统存储相比，虚拟化存储的优点主要体现在：</p><p><strong>磁盘利用率高，</strong>传统存储技术的磁盘利用率一般只有30－70%，而采用虚拟化技术后的磁盘利用率高达70－90%；</p><p><strong>存储灵活，</strong>可以适应不同厂商、不同类别的异构存储平台，为存储资源管理提供了更好的灵活性；</p><p><strong>管理方便，</strong>提供了一个大容量存储系统集中管理的手段，避免了由于存储设备扩充所带来的管理方面的麻烦；</p><p><strong>性能更好，</strong>虚拟化存储系统可以很好地进行负载均衡，把每一次数据访问所需的带宽合理地分配到各个存储模块上，提高了系统的整体访问带宽。</p><p>如下图所示为华为存储虚拟化的解决方案架构图。</p><p><img src="https://i.loli.net/2019/05/27/5ceb43dbee02512952.jpg"></p><p>在华为的存储虚拟化解决方案中，有三个概念，分别是：<strong>存储资源、存储设备</strong>和<strong>数据存储。</strong></p><p><strong>存储资源：</strong>表示物理存储设备，例如IPSAN、Advanced SAN、NAS等。</p><p><strong>存储设备：</strong>表示存储资源中的管理单元，类似LUN、 Advanced SAN存储池、NAS共享目录等。</p><p><strong>数据存储：</strong>表示虚拟化平台中可管理、操作的存储逻辑单元。</p><p>各类存储资源的特性对比如下，其中，<strong>存储卸载是指将部分存储操作（模板部署、删除清零等操作）下移到存储侧进行，这样做可以不浪费主机侧资源，同时也可以提升操作效率</strong></p><table><thead><tr><th><strong>存储资源类型</strong></th><th><strong>底层协议</strong></th><th><strong>存储设备类型</strong></th><th><strong>是否支持虚拟化</strong></th><th><strong>是否支持存储卸载</strong></th></tr></thead><tbody><tr><td><strong>IPSAN</strong></td><td>TCP/IP</td><td>LUN</td><td>是</td><td>否</td></tr><tr><td><strong>FCSAN</strong></td><td>光纤</td><td>LUN</td><td>是</td><td>否</td></tr><tr><td><strong>NAS</strong></td><td>TCP/IP</td><td>共享目录</td><td>是</td><td>否</td></tr><tr><td><strong>本地磁盘</strong></td><td>本地连接</td><td>本地磁盘</td><td>是</td><td>否</td></tr><tr><td><strong>AdvancedSAN</strong></td><td>TCP/IP</td><td>存储池</td><td>否</td><td>是</td></tr><tr><td><strong>FusionStorage</strong></td><td>TCP/IP</td><td>存储池</td><td>是</td><td>是</td></tr></tbody></table><p>华为的虚拟化存储栈全景图如下，可以将不同存储设备进行格式化，屏蔽存储设备的能力、接口协议等差异性，将各种存储资源转化为统一管理的数据存储资源，可以用来存储虚拟机磁盘、虚拟机配置信息、快照等信息，使得用户对存储的管理更加同质化。</p><p><img src="https://i.loli.net/2019/05/27/5ceb43ff15c3725844.jpg"></p><h2 id="存储虚拟化的技术实现分类"><a href="#存储虚拟化的技术实现分类" class="headerlink" title="存储虚拟化的技术实现分类"></a>存储虚拟化的技术实现分类</h2><p>虚拟化存储有多种分类方法，从大的方面可以分为：<strong>根据在I/O路径中实现虚拟化的位置不同进行分类和根据控制路径和数据路径的不同进行分类。</strong></p><p>根据在I/O路径中实现虚拟化的位置不同，虚拟化存储可以分为<strong>主机的虚拟存储、网络的虚拟存储、存储设备的虚拟存储。</strong>根据控制路径和数据路径的不同，虚拟化存储分为<strong>对称虚拟化</strong>与<strong>不对称虚拟化</strong>。</p><p><strong>1）基于主机的虚拟存储</strong></p><p>基于主机的虚拟存储完全依赖存储管理软件，无需任何附加硬件。基于主机的存储管理软件，在系统和应用级上，实现多机间的共享存储、存储资源管理（存储媒介、卷、文件管理）、数据复制和数据迁移、远程备份、集群系统、灾难恢复等存储管理任务。</p><p>基于主机的虚拟存储又可分为<strong>数据块以上虚拟层</strong>和<strong>数据块存储虚拟层</strong>：数据块以上虚拟层（ViAualizationaboveBlock）它是存储虚拟化的最顶层，通过文件系统和数据库给应用程序提供一个虚拟数据视图，屏蔽了底层实现。数据块存储虚拟层（BlockStorageVirtualzation）通过基于主机的卷管理程序和附加设备接口，给主机提供一个整合的存储访问视图。卷管理程序为虚拟存储设备创建逻辑卷，井负责数据I/O请求的路由。如下图所示，为基于主机的虚拟化存储示意图，<strong>主要应用于服务器的存储空间可以跨越多个异构的磁盘阵列场景，常用于在不同磁盘阵列之间做数据镜像保护。</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb442eda30f46624.jpg"></p><p>一般由操作系统下的逻辑卷管理软件完成（安装客户端软件），不同操作系统的逻辑卷管理软件也不相同。<strong>优点是：</strong>支持异构的存储系统。<strong>缺点是：</strong>占用主机资源，转发性能差，与主机OS兼容性差，数据迁移复杂。</p><p><strong>2）基于存储设备的虚拟存储</strong> </p><p>基于存储设备的存储虚拟化方法依赖于提供相关功能的存储模块。如果没有第三方的虚拟软件，基于存储的虚拟化经常只能提供一种不完全的存储虚拟化解决方案。对于包含多厂商存储设备的SAN存储系统，这种方法的运行效果并不是很好。利用这种方法意味着最终将锁定某一家单独的存储厂商。如下图所示，为基于存储设备的虚拟化示意图，<strong>主要应用于在同一存储设备内部，进行数据保护和数据迁移的场景。</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb444810a8344557.jpg"></p><p>通过在存储控制器上添加虚拟化功能实现，只有中高端存储设备具备此功能。<strong>优点是：</strong>与主机无关，不占用主机资源，数据管理功能丰富。<strong>缺点是：</strong>只能对本设备内的磁盘虚拟化，厂商绑定不能异构，多套存储设备软件不兼容，需多部署，成本高。</p><p>比较常见的基于设备的存储虚拟化应用就是<strong>精简配置虚拟磁盘</strong>，能够提供远远大于物理磁盘容量的虚拟空间。不管虚拟机磁盘分配了多少空间，如果没有数据写到虚拟磁盘上，就不会占用任何物理磁盘空间。精简配置虚拟磁盘的示意图如下所示，可以用小的物理容量为操作系统提供超大容量的虚拟存储空间。并且，随着应用数据量的增长，实际存储空间也可以及时扩展，而无须手动扩展。总之，<strong>自动精简配置提供的是“运行时空间”，可以显著减少已分配但是未使用的存储空间。</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb446b00c5735992.jpg"></p><p>如果采用传统的磁盘分配方法，如上图左边。需要用户对当前和未来业务发展规模进行正确的预判，提前做好空间资源的规划。在实际中，由于对应用系统规模估计得不准确，往往会造成容量分配的浪费。</p><p>自动精简配置磁盘，如上图右边。有效地解决了存储资源的空间分配难题，提高了资源利用率。采用自动精简配置技术的数据卷分配给用户的是一个逻辑的虚拟磁盘，而不是一个固定的物理空间，只有当用户真正向该逻辑资源写数据时，才按照预先设定好的策略从物理空间分配实际空间容量。</p><p><strong>3）基于网络的虚拟存储</strong>  </p><p>网络虚拟层包括了绑定管理软件的存储服务器和网络互联设备。基于网络的虚拟化是在网络设备之间实现存储虚拟化功能，它将类似于卷管理的功能扩展到整个存储网络，负责管理Host视图、共享存储资源、数据复制、数据迁移及远程备份等，并对数据路径进行管理避免性能瓶颈。如下图所示，基于网络的虚拟存储示意图，<strong>主要用应用与异构存储系统的整合和统一管理场景。</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb4497df8e120691.jpg"></p><p>通过在存储域网（SAN）中添加虚拟化引擎实现。<strong>优点是：</strong>与主机无关，性能好、能够异构主机和存储设备、管理统一、功能丰富。<strong>缺点是：</strong>各厂商产品品质参差不齐，部分厂商产品想能差，兼容性差。</p><p>基于网络的虚拟存储可采用<strong>对称</strong>或<strong>非对称</strong>的虚拟存储架构。在非对称架构中，虚拟存储控制器处于系统数据通路之外，不直接参与数据的传输。服务器可以直接经过标准的交换机对存储设备进行访问。虚拟存储控制器对所有存储设备进行配置，并将配置信息提交给所有服务器，如下图所示，服务器在访问存储设备时，不再经过虚拟存储控制器，而是直接访问存储设备并发工作，同样达到了增大传输带宽的目的，这种架构也称为存储虚拟化的<strong>带外虚拟引擎</strong>（out-of-band）。</p><p><img src="https://i.loli.net/2019/05/27/5ceb44cb1b60a87719.jpg"></p><p><strong>一般用于不同存储设备之间的数据复制。优点是：</strong>虚拟化设备发生故障，整个系统将不会中断。<strong>缺点是：</strong>主机资源占用大，数据配置、同步复杂，缺乏统一管理。</p><p>而对称式架构中，虚拟存储控制设备直接位于服务器与存储设备之间，利用运行其上的存储管理软件来管理和配置所有存储设备，组成一个大型的存储池，其中的若干存储设备以一个逻辑分区的形式，被系统中所有服务器访问，这种架构也称为<strong>带内存储虚拟化引擎（in-band）</strong>。如下图所示，虚拟存储控制设备有多个数据通路与存储设备连接，多个存储设备并发工作，所以系统总的存储设备访问效率可达到较高水平。</p><p><img src="https://i.loli.net/2019/05/27/5ceb44e4060ec92829.jpg"></p><p><strong>主要用于异构存储系统整合，统一数据管理，在业务运行同时完成复制、镜像、CDP等各种数据管理功能。优点是：</strong>兼容性好，不占主机资源，配置简单，功能丰富。<strong>缺点是：</strong>虚拟化设备发生故障，整个系统将中断。</p><h2 id="软件定义存储SDS"><a href="#软件定义存储SDS" class="headerlink" title="软件定义存储SDS"></a>软件定义存储SDS</h2><p>上面提到过存储虚拟化并不等于软件定义存储SDS，其实存储虚拟化也可以归入软件定义存储的类别，实际上很多虚拟化存储厂商也是这么做的。但是严格意义上来说，这两者又略有不同，存储虚拟化一般只能在专门的硬件设备上使用，它的控制平面和存储数据平面是紧耦合的，很多厂商都要使用专门量身定做的设备才能实现存储虚拟化，而软件定义存储则没有设备限制，其控制平面和存储数据平面是松耦合，其本质上只定义控制平面的“软化”，而存储数据平面仍由各厂商去各自实现。可以简单理解成就是一个存储的管理程序。</p><p>软件定义存储实际上存在更大的适用范围，它的目标是从存储硬件中分离出存储控制功能和服务并提供编程接口，如 OpenStack Cinder， EMC ViPR，华为的Fusion Sphere和Fusion Storage都是这个范畴。如下图所示：</p><p><img src="https://i.loli.net/2019/05/27/5ceb4501611b596861.jpg"></p><p>再具体一点，软件定义存储是把存储硬件或软件提供的控制能力抽象出来，并与数据层面的能力(数据访问)分开，这些控制能力包括卷管理，RAID，QoS，数据复制，监控，快照和备份等等，这个举动意义在于这些控制能力抽象出来以后，任何厂商提供的存储能力控制都是接近的，避免对厂商的绑定。</p><p>然后它通过这些控制能力进一步为管理员提供自定义、基于策略的虚拟存储层，这些策略可以是基于空间、性能、费用等等因素。它的优势在于与存储虚拟化相比更加轻量，通常可以保留底层存储系统如SAN，阵列的特性并仍然发挥作用，而且部署和实现难度都大幅度下降，可以采用更小的代价实现管理存储基础设施的能力，如下图所示：</p><p><img src="https://i.loli.net/2019/05/27/5ceb451ede6a036106.jpg"></p><p>OpenStack Cinder是一个典型的软件定义存储产品，它目前支持大量的存储厂商设备，它定义了一些卷管理，快照，备份，简单统计等特性，用户可以使用Cinder提供的接口来获得不同存储设备提供的相似能力。</p><p><img src="https://i.loli.net/2019/05/27/5ceb453a6687d81104.jpg"></p><p>而Ceph可以看作一个典型的存储虚拟化产品，它将大量的通用存储设备联合起来提供一个存储池，并实现了一般存储厂商产品的能力。而Ceph的块存储能力使得它成为了Cinder的一个Driver。同时Cinder通过了这些基本API进行扩展，可以定义出不同的存储池，智能化的存储区域等等。</p><p><img src="https://i.loli.net/2019/05/27/5ceb455b5ab5057548.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;存储虚拟化概述&quot;&gt;&lt;a href=&quot;#存储虚拟化概述&quot; class=&quot;headerlink&quot; title=&quot;存储虚拟化概述&quot;&gt;&lt;/a&gt;&lt;strong&gt;存储虚拟化概述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;存储虚拟化（StorageVirtualization）最通俗的理解就是对&lt;strong&gt;存储硬件资源进行抽象化表现&lt;/strong&gt;。这种虚拟化可以将用户与存储资源中大量的物理特性隔绝开来，就好像我们去仓库存放或者提取物品一样，只要跟仓库管理员打交道，而不必关心我们的物品究竟存放在仓库内的哪一个角落。对于用户来说，虚拟化的存储资源就像是一个巨大的“&lt;strong&gt;存储池&lt;/strong&gt;”，用户不会看到具体的存储磁盘、磁带，也不必关心自己的数据经过哪一条路径通往哪一个具体的存储设备。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-27-Linux系统命令-第十篇《系统管理命令》</title>
    <link href="https://kkutysllb.cn/2019/05/27/2019-05-27-Linux%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4-%E7%AC%AC%E5%8D%81%E7%AF%87%E3%80%8A%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E3%80%8B/"/>
    <id>https://kkutysllb.cn/2019/05/27/2019-05-27-Linux系统命令-第十篇《系统管理命令》/</id>
    <published>2019-05-27T01:11:32.000Z</published>
    <updated>2019-05-27T02:15:25.580Z</updated>
    
    <content type="html"><![CDATA[<h2 id="lsof：查看进程打开的文件"><a href="#lsof：查看进程打开的文件" class="headerlink" title="lsof：查看进程打开的文件"></a>lsof：查看进程打开的文件</h2><p>lsof全名为list open files，也就是列举系统中已经被打开的文件，通过lsof命令，就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。<a id="more"></a></p><p><strong>语法格式：lsof [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb398a4a0c461158.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示使用文件的进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示使用/var/log/message文件的进程信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof /var/log/messages </span></span><br><span class="line">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF      NODE NAME</span><br><span class="line">rsyslogd 1039 root    6w   REG    8,3   782990 101157938 /var/<span class="built_in">log</span>/messages</span><br></pre></td></tr></table></figure><blockquote><p><strong>如果想知道文件是被哪个进程所使用，直接lsof+文件名就可以查询。</strong></p><p><strong>上述结果的说明如下：</strong></p><p><strong>COMMAND：</strong>命令，进程的名称。</p><p><strong>PID：</strong>进程号。</p><p><strong>USER：</strong>进程的所有者。</p><p><strong>FD：</strong>文件描述符，它又包含如下内容。</p><p>​    <strong>0：</strong>表示标准输出。</p><p>​    <strong>1：</strong>表示标准输入。</p><p>​    <strong>2：</strong>表示标准错误。</p><p>​    <strong>u：</strong>表示该文件被打开并处于读取/写入模式。</p><p>​    <strong>r：</strong>表示该文件被打开并处于只读模式。</p><p>​    <strong>w：</strong>表示该文件被打开并处于写入模式。</p><p><strong>TYPE：</strong>文件类型，REG（regular）为普通文件。</p><p><strong>DEVICE：</strong>指定磁盘的标识。</p><p><strong>SIZE/OFF：</strong>文件的大小。</p><p><strong>NODE：</strong>索引节点。</p><p><strong>NAME：</strong>文件名称。进程号。</p><p><strong>USER：</strong>进程的所有者。</p><p><strong>FD：</strong>文件描述符，它又包含如下内容。</p><p>​    <strong>0：</strong>表示标准输出。</p><p>​    <strong>1：</strong>表示标准输入。</p><p>​    <strong>2：</strong>表示标准错误。</p><p>​    <strong>u：</strong>表示该文件被打开并处于读取/写入模式。</p><p>​    <strong>r：</strong>表示该文件被打开并处于只读模式。</p><p>​    <strong>w：</strong>表示该文件被打开并处于写入模式。</p><p><strong>TYPE：</strong>文件类型，REG（regular）为普通文件。</p><p><strong>DEVICE：</strong>指定磁盘的标识。</p><p><strong>SIZE/OFF：</strong>文件的大小。</p><p><strong>NODE：</strong>索引节点。</p><p><strong>NAME：</strong>文件名称。</p></blockquote><p><strong>2）显示指定进程所打开的文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-c选项指定进程名</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -c crond</span></span><br><span class="line">COMMAND PID USER   FD      TYPE             DEVICE  SIZE/OFF      NODE NAME</span><br><span class="line">crond   671 root  cwd       DIR                8,3       224        64 /</span><br><span class="line">crond   671 root  rtd       DIR                8,3       224        64 /</span><br><span class="line">crond   671 root  txt       REG                8,3     70128    462795 /usr/sbin/crond</span><br><span class="line">crond   671 root  mem       REG                8,3     62184      1900 /usr/lib64/libnss_files-2.17.so</span><br><span class="line">crond   671 root  mem       REG                8,3 106070960 100665267 /usr/lib/locale/locale-archive</span><br><span class="line">crond   671 root  mem       REG                8,3    144792      1908 /usr/lib64/libpthread-2.17.so</span><br><span class="line">crond   671 root  mem       REG                8,3     23968      2361 /usr/lib64/libcap-ng.so.0.0.0</span><br><span class="line">crond   671 root  mem       REG                8,3    402384      2006 /usr/lib64/libpcre.so.1.2.0</span><br><span class="line">crond   671 root  mem       REG                8,3   2173512      1882 /usr/lib64/libc-2.17.so</span><br><span class="line">crond   671 root  mem       REG                8,3    127184      2359 /usr/lib64/libaudit.so.1.0.0</span><br><span class="line">crond   671 root  mem       REG                8,3     19776      1888 /usr/lib64/libdl-2.17.so</span><br><span class="line">crond   671 root  mem       REG                8,3     61672      3998 /usr/lib64/libpam.so.0.83.1</span><br><span class="line">crond   671 root  mem       REG                8,3    155784    190119 /usr/lib64/libselinux.so.1</span><br><span class="line">crond   671 root  mem       REG                8,3    164240      1875 /usr/lib64/ld-2.17.so</span><br><span class="line">crond   671 root    0r      CHR                1,3       0t0      1028 /dev/null</span><br><span class="line">crond   671 root    1u     unix 0xffff9fd574eca800       0t0     23970 socket</span><br><span class="line">crond   671 root    2u     unix 0xffff9fd574eca800       0t0     23970 socket</span><br><span class="line">crond   671 root    3uW     REG               0,20         4     23971 /run/crond.pid</span><br><span class="line">crond   671 root    4u     unix 0xffff9fd574e3f800       0t0     25637 socket</span><br><span class="line">crond   671 root    5r  a_inode               0,10         0      8261 inotify</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过-p选项指定进程号</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -p 1105</span></span><br><span class="line">COMMAND  PID   USER   FD      TYPE             DEVICE SIZE/OFF      NODE NAME</span><br><span class="line">httpd   1105 apache  cwd       DIR                8,3      224        64 /</span><br><span class="line">httpd   1105 apache  rtd       DIR                8,3      224        64 /</span><br><span class="line">httpd   1105 apache  txt       REG                8,3   523672   5947365 /usr/sbin/httpd</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    62184      1900 /usr/lib64/libnss_files-2.17.so</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    27808  68422763 /usr/lib64/httpd/modules/mod_cgi.so</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    68192      2275 /usr/lib64/libbz2.so.1.0.6</span><br><span class="line">httpd   1105 apache  mem       REG                8,3   157424      2265 /usr/lib64/liblzma.so.5.2.2</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    99944      2264 /usr/lib64/libelf-0.170.so</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    19896      1993 /usr/lib64/libattr.so.1.1.0</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    88720        84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1</span><br><span class="line">httpd   1105 apache  mem       REG                8,3   297360    193704 /usr/lib64/libdw-0.170.so</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    20032      1998 /usr/lib64/libcap.so.2.22</span><br><span class="line">httpd   1105 apache  mem       REG                8,3    44448      1912 /usr/lib64/librt-2.17.so</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><p><strong>3）监听指定的协议、端口和主机等信息，显示符合条件的网络服务进程</strong></p><p><strong>语法格式：lsof -i [46] [protocol][@hostname][:service|port]</strong></p><blockquote><p><strong>说明如下：</strong></p><p>46：4代表IPv4，6代表IPv6。</p><p>protocol：传输协议，可以是TCP或UDP。</p><p>hostname：主机名称或者IP地址。</p><p>service：进程的服务名，例如NFS、SSH和FTP等。</p><p>port：系统中与服务对应的端口号。例如HTTP服务默认对应的端口号为80，SSH服务默认对应的端口号为22。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有网络服务进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -i</span></span><br><span class="line">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">systemd      1   root   48u  IPv6  42537      0t0  TCP *:telnet (LISTEN)</span><br><span class="line">chronyd    645 chrony    1u  IPv4  22341      0t0  UDP localhost:323 </span><br><span class="line">chronyd    645 chrony    2u  IPv6  22342      0t0  UDP localhost:323 </span><br><span class="line">sshd      1038   root    3u  IPv4  26920      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">sshd      1038   root    4u  IPv6  26929      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">httpd     1042   root    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1101 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1102 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1103 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1104 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1105 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">master    1310   root   13u  IPv4  24294      0t0  TCP localhost:smtp (LISTEN)</span><br><span class="line">master    1310   root   14u  IPv6  24295      0t0  TCP localhost:smtp (LISTEN)</span><br><span class="line">docker-pr 1648   root    4u  IPv6  24517      0t0  TCP *:terabase (LISTEN)</span><br><span class="line">sshd      1736   root    3u  IPv4  29038      0t0  TCP C7-Server01:ssh-&gt;192.168.101.1:servicetags (ESTABLISHED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有tcp连接进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -i tcp</span></span><br><span class="line">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">systemd      1   root   48u  IPv6  42537      0t0  TCP *:telnet (LISTEN)</span><br><span class="line">sshd      1038   root    3u  IPv4  26920      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">sshd      1038   root    4u  IPv6  26929      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">httpd     1042   root    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1101 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1102 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1103 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1104 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1105 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">master    1310   root   13u  IPv4  24294      0t0  TCP localhost:smtp (LISTEN)</span><br><span class="line">master    1310   root   14u  IPv6  24295      0t0  TCP localhost:smtp (LISTEN)</span><br><span class="line">docker-pr 1648   root    4u  IPv6  24517      0t0  TCP *:terabase (LISTEN)</span><br><span class="line">sshd      1736   root    3u  IPv4  29038      0t0  TCP C7-Server01:ssh-&gt;192.168.101.1:servicetags (ESTABLISHED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示端口号为22的网络服务进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -i :22</span></span><br><span class="line">COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">sshd    1038 root    3u  IPv4  26920      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">sshd    1038 root    4u  IPv6  26929      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">sshd    1736 root    3u  IPv4  29038      0t0  TCP C7-Server01:ssh-&gt;192.168.101.1:servicetags (ESTABLISHED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示所有支持ipv6的进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -i 6</span></span><br><span class="line">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">systemd      1   root   48u  IPv6  42537      0t0  TCP *:telnet (LISTEN)</span><br><span class="line">chronyd    645 chrony    2u  IPv6  22342      0t0  UDP localhost:323 </span><br><span class="line">sshd      1038   root    4u  IPv6  26929      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">httpd     1042   root    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1101 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1102 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1103 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1104 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd     1105 apache    4u  IPv6  27020      0t0  TCP *:http (LISTEN)</span><br><span class="line">master    1310   root   14u  IPv6  24295      0t0  TCP localhost:smtp (LISTEN)</span><br><span class="line">docker-pr 1648   root    4u  IPv6  24517      0t0  TCP *:terabase (LISTEN)</span><br></pre></td></tr></table></figure><p><strong>3）显示指定用户使用的文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-u选项，显示chrony用户使用的文件</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -u chrony</span></span><br><span class="line">COMMAND PID   USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME</span><br><span class="line">chronyd 645 chrony  cwd    DIR                8,3      224     64 /</span><br><span class="line">chronyd 645 chrony  rtd    DIR                8,3      224     64 /</span><br><span class="line">chronyd 645 chrony  txt    REG                8,3   261024 466082 /usr/sbin/chronyd</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   547568   1239 /usr/lib64/libfreeblpriv3.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    68192   2275 /usr/lib64/libbz2.so.1.0.6</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   157424   2265 /usr/lib64/liblzma.so.5.2.2</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    90248 190122 /usr/lib64/libz.so.1.2.7</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    99944   2264 /usr/lib64/libelf-0.170.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    88720     84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   297360 193704 /usr/lib64/libdw-0.170.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    44448   1912 /usr/lib64/librt-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    86544 193707 /usr/lib64/libnss_myhostname.so.2</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   106848   1910 /usr/lib64/libresolv-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    31824   1898 /usr/lib64/libnss_dns-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    62184   1900 /usr/lib64/libnss_files-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    19896   1993 /usr/lib64/libattr.so.1.1.0</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    19776   1888 /usr/lib64/libdl-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3  2173512   1882 /usr/lib64/libc-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   144792   1908 /usr/lib64/libpthread-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   266680  86207 /usr/lib64/libseccomp.so.2.3.1</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    20032   1998 /usr/lib64/libcap.so.2.22</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3    11464   1237 /usr/lib64/libfreebl3.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3  1139680   1890 /usr/lib64/libm-2.17.so</span><br><span class="line">chronyd 645 chrony  mem    REG                8,3   164240   1875 /usr/lib64/ld-2.17.so</span><br><span class="line">chronyd 645 chrony    0u  unix 0xffff9fd57f8d7000      0t0  22339 socket</span><br><span class="line">chronyd 645 chrony    1u  IPv4              22341      0t0    UDP localhost:323 </span><br><span class="line">chronyd 645 chrony    2u  IPv6              22342      0t0    UDP localhost:323 </span><br><span class="line">chronyd 645 chrony    3r   CHR                1,9      0t0   1033 /dev/urandom</span><br><span class="line">chronyd 645 chrony    5u  unix 0xffff9fd57f8d6c00      0t0  22347 /var/run/chrony/chronyd.sock</span><br></pre></td></tr></table></figure><p><strong>4）显示所有socket文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-U选项可以显示所有socket文件</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># lsof -U</span></span><br><span class="line">COMMAND    PID    USER   FD   TYPE             DEVICE SIZE/OFF  NODE NAME</span><br><span class="line">systemd      1    root   12u  unix 0xffff9fd375ba5800      0t0 10700 /run/systemd/private</span><br><span class="line">systemd      1    root   14u  unix 0xffff9fd56b38ec00      0t0 42422 socket</span><br><span class="line">systemd      1    root   20u  unix 0xffff9fd577436400      0t0    31 /run/systemd/notify</span><br><span class="line">systemd      1    root   21u  unix 0xffff9fd577436800      0t0    33 /run/systemd/cgroups-agent</span><br><span class="line">systemd      1    root   22u  unix 0xffff9fd375ba1800      0t0 18449 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   23u  unix 0xffff9fd5717e5c00      0t0 19070 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   24u  unix 0xffff9fd3fb00f800      0t0 17293 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   25u  unix 0xffff9fd3fbb68800      0t0 17326 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   26u  unix 0xffff9fd5733cec00      0t0 19182 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   28u  unix 0xffff9fd3fbb7fc00      0t0 19185 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   29u  unix 0xffff9fd574eca400      0t0 24785 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   30u  unix 0xffff9fd574e38000      0t0 24108 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   31u  unix 0xffff9fd376117000      0t0 26054 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   32u  unix 0xffff9fd3fbb74400      0t0 26904 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   33u  unix 0xffff9fd375bec800      0t0 26905 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   34u  unix 0xffff9fd376116c00      0t0 26908 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   35u  unix 0xffff9fd3fb8f5800      0t0 14396 /run/systemd/shutdownd</span><br><span class="line">systemd      1    root   36u  unix 0xffff9fd5733c9000      0t0 22337 socket</span><br><span class="line">systemd      1    root   37u  unix 0xffff9fd375be8800      0t0 22569 /var/run/docker.sock</span><br><span class="line">systemd      1    root   38u  unix 0xffff9fd37612d800      0t0 22571 /run/dbus/system_bus_socket</span><br><span class="line">systemd      1    root   41u  unix 0xffff9fd3fb8f5000      0t0 14401 /run/udev/control</span><br><span class="line">systemd      1    root   42u  unix 0xffff9fd577437800      0t0    41 /run/systemd/journal/stdout</span><br><span class="line">systemd      1    root   43u  unix 0xffff9fd577437c00      0t0    44 /run/systemd/journal/socket</span><br><span class="line">systemd      1    root   45u  unix 0xffff9fd577436000      0t0    46 /dev/<span class="built_in">log</span></span><br><span class="line">systemd-j  462    root    3u  unix 0xffff9fd577437800      0t0    41 /run/systemd/journal/stdout</span><br><span class="line">systemd-j  462    root    4u  unix 0xffff9fd577437c00      0t0    44 /run/systemd/journal/socket</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><h2 id="uptime：显示系统的运行时间及负载"><a href="#uptime：显示系统的运行时间及负载" class="headerlink" title="uptime：显示系统的运行时间及负载"></a>uptime：显示系统的运行时间及负载</h2><p>uptime命令可以输出当前系统时间、系统开机到现在的运行时间、目前有多少用户在线和系统平均负载等信息。</p><p><strong>语法格式：uptime</strong></p><p><strong>【使用示例】</strong></p><p><strong>显示系统的运行时间及负载信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># uptime </span></span><br><span class="line">18:56:22 up  2:59,  1 user,  load average: 0.00, 0.01, 0.05</span><br></pre></td></tr></table></figure><h2 id="free：查看系统内存信息"><a href="#free：查看系统内存信息" class="headerlink" title="free：查看系统内存信息"></a>free：查看系统内存信息</h2><p>free命令用于显示系统内存状态，具体包括系统物理内存、虚拟内存、共享内存和系统缓存等。</p><p><strong>语法格式：free [option]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3b0dcbba119224.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）查看系统内存</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不加任何参数使用free命令，结果是以字节为单位显示，很难看懂</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># free</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:        7992344      243632      259960       12084     7488752     7369040</span><br><span class="line">Swap:       8388604           0     8388604</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-m选项以MB为单位显示，但是可能不是很精确</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># free -m</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7805         238         253          11        7313        7196</span><br><span class="line">Swap:          8191           0        8191</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-h选项，以人类可读的方式显示</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># free -h</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        238M        253M         11M        7.1G        7.0G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br></pre></td></tr></table></figure><p><strong>Linux系统的特性是将不用的物理内存缓存起来，因此253MB不是系统的真实剩余内存，系统真正可用的内存为7.0G。buffers为写入数据的缓冲区，cache为读取数据的缓冲区。</strong></p><p><strong>2）定时查询内存</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-s选项设定每10秒刷新一次内存</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># free -h -s 10</span></span><br><span class="line">total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        236M        7.1G         11M        327M        7.1G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br><span class="line">total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        236M        7.1G         11M        327M        7.1G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br><span class="line">total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        237M        7.1G         11M        327M        7.1G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br><span class="line">total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        237M        7.1G         11M        327M        7.1G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br></pre></td></tr></table></figure><h2 id="iftop：动态显示网络接口流量信息"><a href="#iftop：动态显示网络接口流量信息" class="headerlink" title="iftop：动态显示网络接口流量信息"></a>iftop：动态显示网络接口流量信息</h2><p>iftop是一款实时流量监控工具，可用于监控TCP/IP连接等，必须以root用户的身份运行。一般最小化安装系统都是没有这个命令的，需要使用yum命令额外安装，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装iftop</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum list | grep iftop</span></span><br><span class="line">iftop.x86_64                            1.0-0.14.pre4.el7              epel    </span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y iftop</span></span><br></pre></td></tr></table></figure><p><strong>语法格式：iftop [option]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3b7b2821539240.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）不使用任何选项启动iftop命令监控流量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认监听系统的第一块网卡，可以使用-i选项指定网卡</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iftop</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/27/5ceb3ba4db46537601.jpg"></p><blockquote><p><strong>上图说明如下：</strong></p><p>界面上显示的是类似刻度尺的刻度范围，是以标尺的形式显示流量图形的长条。</p><p>中间的&lt;=或=&gt;这两个左右箭头，表示的是流量的方向。</p><p>TX：发送流量。</p><p>RX：接收流量。</p><p>TOTAL：总流量。</p><p>Cum：运行iftop到目前时间的总流量。</p><p>peak：流量峰值。</p><p>rates：分别表示过去2s、10s、40s的平均流量。</p></blockquote><p><strong>2）常用命令组合</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -nNBP用于显示各服务端口号的流量情况，单位为byte</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认显示第一块网卡的流量，可以通过-i选项指定网卡</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iftop -nNBP</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/27/5ceb3bdb6a02c59773.jpg"></p><h2 id="vmstat：虚拟内存统计"><a href="#vmstat：虚拟内存统计" class="headerlink" title="vmstat：虚拟内存统计"></a>vmstat：虚拟内存统计</h2><p>vmstat是Virtual Memory Statistics（虚拟内存统计）的缩写，利用vmstat命令可以对操作系统的内存信息、进程状态和CPU活动等进行监视。但是只能对系统的整体情况进行统计，无法对某个进程进行深入分析。</p><p><strong>语法格式：vmstat [option] [delay [ count]]，delay表示两次输出之间的间隔时间。count表示按照delay指定的时间间隔统计的次数。</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3bfc5d87271319.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示虚拟内存的使用情况</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果省略间隔时间和次数选项，则仅显示最后一次报告就退出</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat </span></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line"> 1  0      0 7267600   2076 479564    0    0    79     4   55   57  0  0 100  0  0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用delay选项，可以每隔n秒显示一次，直到ctrl+c退出</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat 5</span></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line"> 1  0      0 7267436   2076 479652    0    0    75     4   53   56  0  0 100  0  0</span><br><span class="line"> 1  0      0 7267412   2076 479652    0    0     0     0   95  104  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   84  101  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   87  106  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   88   99  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   91  102  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   83  100  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   90  105  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   85   95  0  0 100  0  0</span><br><span class="line">^C </span><br><span class="line"></span><br><span class="line"><span class="comment"># 加上count选项，可以按照指定次数显示，完成后自动退出</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat 5 6</span></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line"> 1  0      0 7267312   2076 479652    0    0    70     3   51   54  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0  102  110  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   85   95  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   85   97  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   90   98  0  0 100  0  0</span><br><span class="line"> 0  0      0 7267288   2076 479652    0    0     0     0   89   97  0  0 100  0  0</span><br></pre></td></tr></table></figure><blockquote><p><strong>上面输出的结果说明：</strong></p><p>第1列：procs。</p><p>​    r列表示运行和等待CPU时间片的进程数。</p><p>​    b列表示正在等待资源的进程数。</p><p>第2列：memory。</p><p>​    swpd列表示使用虚拟内存的大小。</p><p>​    free列表示当前空闲的物理内存数量。</p><p>​    buff列表示buffers的内存数量。</p><p>​    cache列表示cache的内存数量。</p><p>第3列：swap。</p><p>​    si（swap in）列表示由磁盘调入内存，也就是磁盘读入内存交换区的数量。</p><p>​    so（swap out）列表示由内存调入磁盘，也就是内存交换区写入磁盘的数量。</p><p>第4列：I/O项显示磁盘读写状况。</p><p>​    bi列表示从块设备读入数据的总量（即读磁盘）（块/s）。</p><p>​    bo列表示写入块设备的数据总量（即写磁盘）（块/s）。</p><p>第5列：system显示采集间隔内发生的中断数。</p><p>​    in列表示在某一时间间隔中观测到的每秒设备中断数。</p><p>​    cs列表示每秒产生的上下文切换次数。</p><p>第6列：CPU项显示了CPU的使用状态。</p><p>​    us列显示了用户进程消耗的CPU时间百分比。</p><p>​    sy列显示了系统（内核）进程消耗的CPU时间百分比。</p><p>​    id列显示了CPU处在空闲状态的时间百分比。</p><p>​    wa列显示了I/O等待所占用的CPU时间百分比。</p><p>​    st列显示了虚拟机占用的CPU时间的百分比。</p></blockquote><p><strong>2）显示活跃和非活跃内存</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每2秒刷新一次，共刷新5此，通过-a选项显示系统活跃和非活跃内存</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat -a 2 5</span></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line">r  b   swpd   free  inact active   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line">1  0      0 7266764 244696 250212    0    0    57     3   45   48  0  0 100  0  0</span><br><span class="line">0  0      0 7266648 244696 250168    0    0     0     0   98  104  0  0 100  0  0</span><br><span class="line">0  0      0 7266648 244696 250168    0    0     0     0   81   93  0  0 100  0  0</span><br><span class="line">0  0      0 7266648 244696 250168    0    0     0     0   82   93  0  0 100  0  0</span><br><span class="line">0  0      0 7266648 244696 250168    0    0     0     0  114  135  0  0 100  0  0</span><br></pre></td></tr></table></figure><ul><li><strong>inact：表示非活跃内存的大小。</strong></li><li><strong>active：表示活跃内存的大小。</strong></li></ul><p><strong>3）查看内存使用的详细信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-s选项可以查看内存使用的详细信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这些信息来自/proc/meminfo、/proc/stat和/proc/vmstat等内存映射文件</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat -s </span></span><br><span class="line">7992344 K total memory</span><br><span class="line">243984 K used memory</span><br><span class="line">250216 K active memory</span><br><span class="line">244696 K inactive memory</span><br><span class="line">7266392 K free memory</span><br><span class="line">2076 K buffer memory</span><br><span class="line">479892 K swap cache</span><br><span class="line">8388604 K total swap</span><br><span class="line">0 K used swap</span><br><span class="line">8388604 K free swap</span><br><span class="line">390 non-nice user cpu ticks</span><br><span class="line">0 nice user cpu ticks</span><br><span class="line">1466 system cpu ticks</span><br><span class="line">812275 idle cpu ticks</span><br><span class="line">229 IO-wait cpu ticks</span><br><span class="line">0 IRQ cpu ticks</span><br><span class="line">52 softirq cpu ticks</span><br><span class="line">0 stolen cpu ticks</span><br><span class="line">411934 pages paged <span class="keyword">in</span></span><br><span class="line">20492 pages paged out</span><br><span class="line">0 pages swapped <span class="keyword">in</span></span><br><span class="line">0 pages swapped out</span><br><span class="line">348908 interrupts</span><br><span class="line">371812 CPU context switches</span><br><span class="line">1556980554 boot time</span><br><span class="line">2038 forks</span><br></pre></td></tr></table></figure><p><strong>4）查看磁盘的读写信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-d可以查看所有磁盘的读写信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这些信息主要来自/proc/diskstats文件，merged表示合并写/读请求次数</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat -d</span></span><br><span class="line">disk- ------------reads------------ ------------writes----------- -----IO------</span><br><span class="line">total merged sectors      ms  total merged sectors      ms    cur    sec</span><br><span class="line">sr0       18      0    2056      28      0      0       0       0      0      0</span><br><span class="line">sda    10037      2  821813    7396   2986    132   40987    1497      0      4</span><br></pre></td></tr></table></figure><p><strong>5）查看指定分区的读写信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-p选项可以指定分区查看读写信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vmstat -p /dev/sda3</span></span><br><span class="line">sda3          reads   <span class="built_in">read</span> sectors  writes    requested writes</span><br><span class="line">8008     771194        931      36850</span><br></pre></td></tr></table></figure><blockquote><p><strong>这些信息主要来自于/proc/diskstats，输出结果各列的说明具体如下：</strong></p><p>reads：来自于该分区的读的次数。</p><p>read sectors：来自于该分区的读扇区的次数。</p><p>writes：来自于该分区的写的次数。</p><p>requested writes：来自于该分区的写请求次数。</p></blockquote><h2 id="mpstat：CPU信息统计"><a href="#mpstat：CPU信息统计" class="headerlink" title="mpstat：CPU信息统计"></a>mpstat：CPU信息统计</h2><p>mpstat是Multiprocessor Statistics的缩写，是一种实时系统监控工具。mpstat命令会输出CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPU的系统里，此命令不但能用来查看所有CPU的平均状况信息，而且还能够用来查看特定CPU的信息。mpstat命令的最大特点是：可以查看多核心CPU中每个计算核心的统计数据，而类似命令vmstat只能查看系统整体的CPU情况。</p><p><strong>语法格式：mpstat [option] [delay [ count]]，delay和count的含义同vmstat。</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3ccb675ce10702.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示CPU信息统计</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不加任何选项，默认显示所有CPU信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 省却delay和count，仅显示最后一次报告就退出</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mpstat </span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line"></span><br><span class="line">11:26:00 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">11:26:00 PM  all    0.05    0.00    0.15    0.02    0.00    0.00    0.00    0.00    0.00   99.77</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每2秒刷新一次，共刷新5次</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mpstat 2 5</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line"></span><br><span class="line">11:27:09 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">11:27:11 PM  all    0.00    0.00    0.12    0.00    0.00    0.00    0.00    0.00    0.00   99.88</span><br><span class="line">11:27:13 PM  all    0.00    0.00    0.12    0.00    0.00    0.00    0.00    0.00    0.00   99.88</span><br><span class="line">11:27:15 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00</span><br><span class="line">11:27:17 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00</span><br><span class="line">11:27:19 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00</span><br><span class="line">Average:     all    0.00    0.00    0.05    0.00    0.00    0.00    0.00    0.00    0.00   99.95</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果的说明如下：</strong></p><p>第1列：11：27：09 PM，表示当前时间。</p><p>第2列：CPU，all表示所有CPU，0表示第一个CPU……</p><p>后面9列的含义分别如下。</p><p>％usr：用户进程消耗的CPU时间百分比。</p><p>％nice：改变过优先级的进程占用的CPU时间百分比。</p><p>％sys：系统（内核）进程消耗的CPU时间百分比。</p><p>％iowait：IO等待所占用的CPU时间百分比。</p><p>％irq：硬中断占用的CPU时间百分比。</p><p>％soft：软中断占用的CPU时间百分比。</p><p>％steal：虚拟机强制CPU等待的时间百分比。</p><p>％guest：虚拟机占用CPU时间的百分比。</p><p>％idle：CPU处在空闲状态的时间百分比。</p></blockquote><p><strong>2）显示指定CPU的信息统计</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 系统有4个cpu，通过-P选项指定显示第二个CPU的信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mpstat -P 1</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">11:30:31 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">11:30:31 PM    1    0.06    0.00    0.22    0.02    0.00    0.01    0.00    0.00    0.00   99.70</span><br></pre></td></tr></table></figure><p>注意：这里的CPU指的是逻辑CPU，也就是超线程。</p><h2 id="iostat：I-O信息统计"><a href="#iostat：I-O信息统计" class="headerlink" title="iostat：I/O信息统计"></a>iostat：I/O信息统计</h2><p>iostat是I/O statistics（输入/输出统计）的缩写，其主要功能是对系统的磁盘I/O操作进行监视。它的输出主要是显示磁盘读写操作的统计信息，同时也会给出CPU的使用情况。同vmstat命令一样，iostat命令也不能对某个进程进行深入分析，仅会对系统的整体情况进行分析。</p><p><strong>语法格式：iostat [option] [ interval [ count ] ]，interval同delay。</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3d27f0cb984707.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示所有设备的负载情况</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认不接任何选项，显示所有设备的负载情况</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 省略时间间隔和次数，仅显示最后一次报告就退出</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iostat </span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">0.05    0.00    0.13    0.02    0.00   99.80</span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">scd0              0.01         0.29         0.00       1028          0</span><br><span class="line">sda               3.86       115.53         8.72     411970      31087</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果的说明如下：</strong></p><p>第1～2行中各列的含义具体如下：</p><p>％user：用户进程消耗的CPU时间百分比。</p><p>％nice：改变过优先级的进程占用的CPU时间百分比。</p><p>％system：系统（内核）进程消耗的CPU时间百分比。</p><p>％iowait：IO等待所占用的CPU时间百分比。</p><p>％steal：虚拟机强制CPU等待的时间百分比。</p><p>％idle：CPU处在空闲状态的时间百分比。</p><p>第3～4行中各列的含义如下：</p><p>tps：表示该设备每秒的传输次数，“一次传输”的意思是“一次I/O请求”，多个逻辑请求可能会被合并为“一次I/O请求”，“一次传输”请求的大小是未知的。</p><p>kB_read/s：表示每秒读取的数据块数。</p><p>kB_wrtn/s：表示每秒写入的数据块数。</p><p>kB_read：表示读取的所有块数。</p><p>kB_wrtn：表示写入的所有块数。</p></blockquote><p><strong>3）只显示磁盘统计信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-d选项直线磁盘的统计信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iostat -d</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">scd0              0.00         0.27         0.00       1028          0</span><br><span class="line">sda               3.63       108.57         8.20     411970      31124</span><br></pre></td></tr></table></figure><p><strong>4）查看扩展信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-x选项可以查看扩展信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iostat -d -x</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">scd0              0.00     0.00    0.00    0.00     0.27     0.00   114.22     0.00    1.56    1.56    0.00   1.11   0.00</span><br><span class="line">sda               0.00     0.05    2.63    0.93   106.63     8.06    64.38     0.00    0.68    0.74    0.54   0.33   0.12</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果说明如下：</strong></p><p>rrqm/s：每秒进行merge的读操作数目。</p><p>wrqm/s：每秒进行merge的写操作数目。</p><p>r/s：每秒完成的读I/O设备次数。</p><p>w/s：每秒完成的写I/O设备次数。</p><p>rkB/s：每秒读入的千字节数。</p><p>wkB/s：每秒写入的千字节数。</p><p>avgrq-sz：设备平均每次进行I/O操作的数据大小（扇区）。</p><p>avgqu-sz：平均I/O队列长度。</p><p>await：设备平均每次I/O操作的等待时间（毫秒）。</p><p>svctm：设备平均每次I/O操作的服务时间（毫秒）。</p><p>％util：每秒钟用于I/O操作的百分比。</p></blockquote><p><strong>5）只查看CPU的统计信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-c选项可以产看CPU的统计信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iostat -c</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">0.04    0.00    0.12    0.02    0.00   99.82</span><br></pre></td></tr></table></figure><h2 id="iotop：动态显示磁盘I-O统计信息"><a href="#iotop：动态显示磁盘I-O统计信息" class="headerlink" title="iotop：动态显示磁盘I/O统计信息"></a>iotop：动态显示磁盘I/O统计信息</h2><p>iotop命令是一款实时监控磁盘I/O的工具，但必须以root用户的身份运行。使用iotop命令可以很方便地查看每个进程使用磁盘I/O的情况。最小化安装系统一般是没有这个命令的，需要使用yum命令额外安装，安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install iotop</span><br></pre></td></tr></table></figure><p><strong>语法格式：iotop [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3dd50f76288111.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>不使用任何参数</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过iotop指令启动服务，类似top指令，不过它只显示磁盘io的使用情况</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># iotop</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/27/5ceb3dfba05f727072.jpg"></p><blockquote><p><strong>命令显示结果的说明如下：</strong></p><p>Total DISK READ：总的磁盘读取速度。</p><p>Total DISK WRITE：总的磁盘写入速度。</p><p>TID：进程pid值。</p><p>PRIO：优先级。</p><p>USER：用户。</p><p>DISK READ：磁盘读取速度。</p><p>DISK WRITE：磁盘写入速度。</p><p>SWAPIN：从swap分区读取数据占用的百分比。</p><p>IO：I/O占用的百分比。</p><p>COMMAND：消耗I/O的进程名。</p></blockquote><h2 id="sar：收集系统信息"><a href="#sar：收集系统信息" class="headerlink" title="sar：收集系统信息"></a>sar：收集系统信息</h2><p>通过sar命令，可以全面地获取系统的CPU、运行队列、磁盘I/O、分页（交换区）、内存、CPU中断和网络等性能数据。</p><p><strong>语法格式：sar [option] [ interval [ count ] ]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3e2aa200578443.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）查看系统CPU的负载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-u选项只显示系统CPU的负载情况</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -u 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">11:55:12 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle</span><br><span class="line">11:55:14 PM     all      0.00      0.00      0.00      0.00      0.00    100.00</span><br><span class="line">11:55:16 PM     all      0.00      0.00      0.12      0.00      0.00     99.88</span><br><span class="line">11:55:18 PM     all      0.00      0.00      0.00      0.00      0.00    100.00</span><br><span class="line">Average:        all      0.00      0.00      0.04      0.00      0.00     99.96</span><br></pre></td></tr></table></figure><p><strong>2）显示运行队列的大小</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-q选项，只显示运行队列大小</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -q 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">11:56:26 PM   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15   blocked</span><br><span class="line">11:56:28 PM         0       248      0.00      0.01      0.05         0</span><br><span class="line">11:56:30 PM         0       248      0.00      0.01      0.05         0</span><br><span class="line">11:56:32 PM         1       248      0.00      0.01      0.05         0</span><br><span class="line">Average:            0       248      0.00      0.01      0.05         0</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果说明如下：</strong></p><p>runq-sz：运行队列的长度（等待运行的进程数）。</p><p>plist-sz：进程列表中进程（process）和线程（thread）的数量。</p><p>ldavg-1：最后1分钟的系统平均负载（system load average）。</p><p>ldavg-5：过去5分钟的系统平均负载。</p><p>ldavg-15：过去15分钟的系统平均负载。</p></blockquote><p><strong>3）只显示系统内存的使用情况</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-r选项，只显示系统内存的使用</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -r 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/04/2019 _x86_64_(4 CPU)</span><br><span class="line">11:59:34 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty</span><br><span class="line">11:59:36 PM   7258452    733892      9.18      2076    390608    558672      3.41    268816    230800         0</span><br><span class="line">11:59:38 PM   7258452    733892      9.18      2076    390608    558672      3.41    268816    230800         0</span><br><span class="line">11:59:40 PM   7258452    733892      9.18      2076    390608    558672      3.41    268824    230800         0</span><br><span class="line">Average:      7258452    733892      9.18      2076    390608    558672      3.41    268819    230800         0</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果说明如下：</strong></p><p>kbmemfree：空闲物理内存量。</p><p>kbmemused：使用中的物理内存量。</p><p>％memused：物理内存量的使用率。</p><p>kbbuffers：内核中作为缓冲区使用的物理内存容量。</p><p>kbcached：内核中作为缓存使用的物理内存容量。</p><p>kbcommit：应用程序当前使用的内存大小。</p><p>％commit：应用程序当前使用的内存大小占总大小的使用百分比。</p></blockquote><p><strong>4）显示缓冲区的使用情况</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-b选项，只显示缓冲区的使用情况</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -b 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/05/2019 _x86_64_(4 CPU)</span><br><span class="line">12:01:59 AM       tps      rtps      wtps   bread/s   bwrtn/s</span><br><span class="line">12:02:01 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:02:03 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:02:05 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果如下：</strong></p><p>tps：每秒钟物理设备的I/O传输总量。</p><p>rtps：每秒钟从物理设备读入的数据总量。</p><p>wtps：每秒钟向物理设备写入的数据总量。</p><p>bread/s：每秒钟从物理设备读入的数据量，单位为块/s。</p><p>bwrtn/s：每秒钟向物理设备写入的数据量，单位为块/s。</p></blockquote><p><strong>5）显示网络的运行状态</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-n选项，只显示网络运行状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># DEV表示网络接口</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -n DEV 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/05/2019 _x86_64_(4 CPU)</span><br><span class="line"></span><br><span class="line">12:04:55 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">12:04:57 AM      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:57 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:57 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:57 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:57 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:57 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">12:04:57 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">12:04:59 AM      eth0      0.50      0.50      0.03      0.37      0.00      0.00      0.00</span><br><span class="line">12:04:59 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:59 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:59 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:59 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:04:59 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">12:04:59 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">12:05:01 AM      eth0      0.50      0.50      0.03      0.37      0.00      0.00      0.00</span><br><span class="line">12:05:01 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:05:01 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:05:01 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:05:01 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:05:01 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">Average:         eth0      0.33      0.33      0.02      0.25      0.00      0.00      0.00</span><br><span class="line">Average:         eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:    vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:      docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示网络接口错包统计</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># EDEV表示网络接口错误信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -n EDEV 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/05/2019 _x86_64_(4 CPU)</span><br><span class="line"></span><br><span class="line">12:06:49 AM     IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s</span><br><span class="line">12:06:51 AM      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:51 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:51 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:51 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:51 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:51 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">12:06:51 AM     IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s</span><br><span class="line">12:06:53 AM      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:53 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:53 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:53 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:53 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:53 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">12:06:53 AM     IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s</span><br><span class="line">12:06:55 AM      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:55 AM      eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:55 AM      eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:55 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:55 AM vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:06:55 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Average:        IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s</span><br><span class="line">Average:         eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eth1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eth2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:    vethc27967f      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:      docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过SOCK关键字，可以只显示套接字信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -n SOCK 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/05/2019 _x86_64_(4 CPU)</span><br><span class="line"></span><br><span class="line">12:08:42 AM    totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw</span><br><span class="line">12:08:44 AM       979         4         1         0         0         0</span><br><span class="line">12:08:46 AM       979         4         1         0         0         0</span><br><span class="line">12:08:48 AM       979         4         1         0         0         0</span><br><span class="line">Average:          979         4         1         0         0         0</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令输出结果的说明：</strong></p><p>IFACE：网络接口。</p><p>rxpck/s：每秒钟接收的数据包。</p><p>txpck/s：每秒钟发送的数据包。</p><p>rxkB/s：每秒钟接收的字节数。</p><p>txkB/s：每秒钟发送的字节数。</p><p>rxcmp/s：每秒钟接收的压缩数据包。</p><p>txcmp/s：每秒钟发送的压缩数据包。</p><p>rxmcst/s：每秒钟接收的多播数据包。</p></blockquote><p><strong>6）显示磁盘的读写性能</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过-d选项，可以只显示磁盘的读写状态</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># sar -d 2 3</span></span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (C7-Server01) 05/05/2019 _x86_64_(4 CPU)</span><br><span class="line">12:10:13 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util</span><br><span class="line">12:10:15 AM   dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:10:15 AM    dev8-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:10:15 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util</span><br><span class="line">12:10:17 AM   dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:10:17 AM    dev8-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:10:17 AM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util</span><br><span class="line">12:10:19 AM   dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">12:10:19 AM    dev8-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util</span><br><span class="line">Average:      dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:       dev8-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure><blockquote><p><strong>输出结果说明如下：</strong></p><p>DEV：表示磁盘的设备名称。</p><p>tps：表示该设备每秒的传输次数，“一次传输”的意思是“一次I/O请求”，多个逻辑请求可能会被合并为“一次I/O请求”，“一次传输”请求的大小是未知的。</p><p>rd_sec/s：表示每秒从设备读取的扇区数。</p><p>wr_sec/s：表示每秒写入设备的扇区数目。</p><p>avgrq-sz：设备平均每次I/O操作的数据大小（扇区）。</p><p>avgqu-sz：平均I/O队列长度。</p><p>await：设备平均每次I/O操作的等待时间（毫秒）。</p><p>svctm：设备平均每次I/O操作的服务时间（毫秒）。</p><p>％util：每秒钟用于I/O操作的百分比。</p></blockquote><h2 id="ntsysv：管理开机服务"><a href="#ntsysv：管理开机服务" class="headerlink" title="ntsysv：管理开机服务"></a>ntsysv：管理开机服务</h2><p>ntsysv命令提供了一种基于文本界面的菜单操作方式，以设置不同运行级别下的系统服务启动状态。</p><p>此工具在最小化系统安装时没有安装，需要手动安装，安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询ntsysv的yum包，结果显示属于基础包</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum list | grep ntsysv</span></span><br><span class="line">ntsysv.x86_64                           1.7.4-1.el7                    base</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行yum install进行安装</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y ntsysv</span></span><br></pre></td></tr></table></figure><p><strong>语法格式：ntsysv [option]</strong> </p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3f2f7bcc312594.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>配置系统服务</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在命令行直接输入ntsysv，进入交互式菜单界面</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ntsysv</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/27/5ceb3f56f2f2286102.jpg"></p><p><strong>进入后，就可以通过键盘的上下左右键和tab键选择你需要配置的开机启动服务，如果需要确认某个选项，按空格键完成，取消确认按两次空格键即可。</strong></p><h2 id="rpm：RPM包管理器"><a href="#rpm：RPM包管理器" class="headerlink" title="rpm：RPM包管理器"></a>rpm：RPM包管理器</h2><p>rpm命令的全称是Red Hat Package Manager（Red Hat包管理器），几乎所有的Linux发行版本都使用了这种形式的命令管理、安装、更新和卸载软件。概括地说，rpm命令包含了五种基本功能（不包括创建rpm包）：安装、卸载、升级、查询和验证。</p><p><strong>语法格式：rpm [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb3f77ab40292709.jpg"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载一个软件包作为测试</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget https://mirrors.aliyun.com/centos/6/os/x86_64/Packages/lrzsz-0.12.20-27.1.el6.x86_64.rpm</span></span><br><span class="line">--2019-05-05 00:35:39--  https://mirrors.aliyun.com/centos/6/os/x86_64/Packages/lrzsz-0.12.20-27.1.el6.x86_64.rpm</span><br><span class="line">Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 112.19.3.240, 112.19.3.241, 112.19.3.182, ...</span><br><span class="line">Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|112.19.3.240|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 72436 (71K) [application/x-redhat-package-manager]</span><br><span class="line">Saving to: ‘lrzsz-0.12.20-27.1.el6.x86_64.rpm’</span><br><span class="line">100%[=====================================================&gt;] 72,436      --.-K/s   <span class="keyword">in</span> 0.07s   </span><br><span class="line">2019-05-05 00:35:42 (974 KB/s) - ‘lrzsz-0.12.20-27.1.el6.x86_64.rpm’ saved [72436/72436]</span><br></pre></td></tr></table></figure><p><strong>【使用示例】</strong></p><p><strong>1）查看rpm包信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示rpm包概要信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-q选项查询软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-p选项指定某一个rpm包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-i选线关于-qp联用，表示查看某个rpm包的概要信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -qpi lrzsz-0.12.20-27.1.el6.x86_64.rpm </span></span><br><span class="line">warning: lrzsz-0.12.20-27.1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID c105b9de: NOKEY</span><br><span class="line">Name        : lrzsz</span><br><span class="line">Version     : 0.12.20</span><br><span class="line">Release     : 27.1.el6</span><br><span class="line">Architecture: x86_64</span><br><span class="line">Install Date: (not installed)</span><br><span class="line">Group       : Applications/Communications</span><br><span class="line">Size        : 162901</span><br><span class="line">License     : GPLv2+</span><br><span class="line">Signature   : RSA/SHA256, Sun 03 Jul 2011 12:43:30 PM CST, Key ID 0946fca2c105b9de</span><br><span class="line">Source RPM  : lrzsz-0.12.20-27.1.el6.src.rpm</span><br><span class="line">Build Date  : Thu 19 Aug 2010 02:20:40 PM CST</span><br><span class="line">Build Host  : c6b3.bsys.dev.centos.org</span><br><span class="line">Relocations : (not relocatable)</span><br><span class="line">Packager    : CentOS BuildSystem </span><br><span class="line">Vendor      : CentOS</span><br><span class="line">URL         : http://www.ohse.de/uwe/software/lrzsz.html</span><br><span class="line">Summary     : The lrz and lsz modem communications programs</span><br><span class="line">Description :</span><br><span class="line">Lrzsz (consisting of lrz and lsz) is a cosmetically modified</span><br><span class="line">zmodem/ymodem/xmodem package built from the public-domain version of</span><br><span class="line">the rzsz package. Lrzsz was created to provide a working GNU</span><br><span class="line">copylefted Zmodem solution <span class="keyword">for</span> Linux systems.</span><br></pre></td></tr></table></figure><p><strong>2）查询软件包内容</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-q选项表示查询软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-p选项表示查询某一个rpm包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-l选项表示查看某一个rpm包里的软件列表</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -qpl lrzsz-0.12.20-27.1.el6.x86_64.rpm </span></span><br><span class="line">warning: lrzsz-0.12.20-27.1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID c105b9de: NOKEY</span><br><span class="line">/usr/bin/rb</span><br><span class="line">/usr/bin/rx</span><br><span class="line">/usr/bin/rz</span><br><span class="line">/usr/bin/sb</span><br><span class="line">/usr/bin/sx</span><br><span class="line">/usr/bin/sz</span><br><span class="line">/usr/share/locale/de/LC_MESSAGES/lrzsz.mo</span><br><span class="line">/usr/share/man/man1/rz.1.gz</span><br><span class="line">/usr/share/man/man1/sz.1.gz</span><br></pre></td></tr></table></figure><p><strong>3）查询软件包的依赖</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-q选项表示查询软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-p选项表示查询某一个rpm包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-R选项表示查看某一个rpm包依赖关系</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -qpR lrzsz-0.12.20-27.1.el6.x86_64.rpm </span></span><br><span class="line">warning: lrzsz-0.12.20-27.1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID c105b9de: NOKEY</span><br><span class="line">libc.so.6()(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.11)(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.2.5)(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.3)(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.3.4)(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.4)(64bit)</span><br><span class="line">libc.so.6(GLIBC_2.7)(64bit)</span><br><span class="line">libnsl.so.1()(64bit)</span><br><span class="line">rpmlib(CompressedFileNames) &lt;= 3.0.4-1</span><br><span class="line">rpmlib(FileDigests) &lt;= 4.6.0-1</span><br><span class="line">rpmlib(PartialHardlinkSets) &lt;= 4.0.4-1</span><br><span class="line">rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1</span><br><span class="line">rtld(GNU_HASH)</span><br><span class="line">rpmlib(PayloadIsXz) &lt;= 5.2-1</span><br></pre></td></tr></table></figure><p><strong>4）安装软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单独使用-i选项，表示安装某一个rpm包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-v选项，表示安装时显示详细信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-h选项，表示用‘#’符号显示安装进度条</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -ivh lrzsz-0.12.20-27.1.el6.x86_64.rpm </span></span><br><span class="line">warning: lrzsz-0.12.20-27.1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID c105b9de: NOKEY</span><br><span class="line">Preparing...                          <span class="comment">################################# [100%]</span></span><br><span class="line">package lrzsz-0.12.20-36.el7.x86_64 (<span class="built_in">which</span> is newer than lrzsz-0.12.20-27.1.el6.x86_64) is already installed</span><br><span class="line">file /usr/bin/rb from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/bin/rx from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/bin/rz from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/bin/sb from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/bin/sx from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/bin/sz from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br><span class="line">file /usr/share/man/man1/sz.1.gz from install of lrzsz-0.12.20-27.1.el6.x86_64 conflicts with file from package lrzsz-0.12.20-36.el7.x86_64</span><br></pre></td></tr></table></figure><p><strong>注意：我的机器因为已经安装过lrzsz工具，所以有上面的提示。</strong></p><p><strong>5）查询系统是否已经安装某个软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-q选项，表示查询软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-a选项，表示查询系统是否已经安装某个软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果没有输出，表示没有安装，如果有输出表示已经安装</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -qa lrzsz</span></span><br><span class="line">lrzsz-0.12.20-36.el7.x86_64</span><br></pre></td></tr></table></figure><p><strong>6）卸载软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-e选项，可以卸载指定的rpm包</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -e lrzsz</span></span><br></pre></td></tr></table></figure><p><strong>注意：这个参数比较危险，因为通过rpm是强依赖卸载，因为很有可能会误删除一些系统必备的文件，最后导致系统损坏。如果非要卸载，可以通过yum工具完成。</strong></p><p><strong>7）插叙文件属于哪个软件包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-q选项，表示查询软件包</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-f选项，表示查询文件属于哪个软件包</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># rpm -qf $(which ifconfig)</span></span><br><span class="line">net-tools-2.0-0.24.20131004git.el7.x86_64</span><br></pre></td></tr></table></figure><p><strong>有时候会发现系统没有某些文件或者命令，但是又不知道这个文件或命令是属于哪个软件包，这时就可以使用-f参数来查询（在有这个文件的系统上查询）。比如本例查询ifconfig命令属于net-tools软件包。</strong></p><h2 id="yum：自动化RPM包管理工具"><a href="#yum：自动化RPM包管理工具" class="headerlink" title="yum：自动化RPM包管理工具"></a>yum：自动化RPM包管理工具</h2><p>yum（Yellow dog Updater Modified）是多个Linux发行版的软件包管理器，例如Redhat RHEL、CentOS和Fedora。yum主要用于自动安装、升级rpm软件包，它能自自动查找并解决rpm包之间的依赖关系。如下图：</p><p><img src="https://i.loli.net/2019/05/27/5ceb4053ebcb844502.jpg"></p><p>通过执行yum install -y lrzsz命令后，它会自动发现系统老版本的软件包，然后进行更新，更新后会自动删除老版本的软件包。</p><p><strong>语法格式：yum [option] [command] [package]</strong></p><p><strong>重要选线参数</strong></p><p><img src="https://i.loli.net/2019/05/27/5ceb406c42a6f39618.jpg"></p><p><img src="https://i.loli.net/2019/05/27/5ceb408073af029814.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）安装httpd软件包</strong></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-y选项，自动确认，无需交互式手动</span></span><br><span class="line">    </span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum install -y httpd</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line">    </span><br><span class="line">- base: mirrors.aliyun.com</span><br><span class="line">- epel: mirrors.njupt.edu.cn</span><br><span class="line">- extras: mirrors.huaweicloud.com</span><br><span class="line">- updates: mirrors.huaweicloud.com</span><br><span class="line">Package httpd-2.4.6-89.el7.centos.x86_64 already installed and latest version</span><br><span class="line">Nothing to <span class="keyword">do</span></span><br></pre></td></tr></table></figure><p>​    </p><p><strong>2）查看已安装和未安装的包组</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用grouplist命令，可以查看所有包组情况</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># yum grouplist</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">      There is no installed groups file.</span><br><span class="line">      Maybe run: yum groups mark convert (see man yum)</span><br><span class="line">      Loading mirror speeds from cached hostfile</span><br><span class="line">    - base: mirrors.aliyun.com</span><br><span class="line">    - epel: mirrors.njupt.edu.cn</span><br><span class="line">    - extras: mirrors.huaweicloud.com</span><br><span class="line">    - updates: mirrors.huaweicloud.com</span><br><span class="line">      Available Environment Groups:</span><br><span class="line">      Minimal Install</span><br><span class="line">      Compute Node</span><br><span class="line">      Infrastructure Server</span><br><span class="line">      File and Print Server</span><br><span class="line">      Cinnamon Desktop</span><br><span class="line">      MATE Desktop</span><br><span class="line">      Basic Web Server</span><br><span class="line">      Virtualization Host</span><br><span class="line">      Server with GUI</span><br><span class="line">      GNOME Desktop</span><br><span class="line">      KDE Plasma Workspaces</span><br><span class="line">      Development and Creative Workstation</span><br><span class="line">      Available Groups:</span><br><span class="line">      Cinnamon</span><br><span class="line">      Compatibility Libraries</span><br><span class="line">      Console Internet Tools</span><br><span class="line">      Development Tools</span><br><span class="line">      Educational Software</span><br><span class="line">      Electronic Lab</span><br><span class="line">      Fedora Packager</span><br><span class="line">      General Purpose Desktop</span><br><span class="line">      Graphical Administration Tools</span><br><span class="line">      Haskell</span><br><span class="line">      Legacy UNIX Compatibility</span><br><span class="line">      MATE</span><br><span class="line">      Milkymist</span><br><span class="line">      Scientific Support</span><br><span class="line">      Security Tools</span><br><span class="line">      Smart Card Support</span><br><span class="line">      System Administration Tools</span><br><span class="line">      System Management</span><br><span class="line">      TurboGears application framework</span><br><span class="line">      Xfce</span><br><span class="line">      Done</span><br></pre></td></tr></table></figure><pre><code>- base: mirrors.aliyun.com    - epel: mirrors.njupt.edu.cn    - extras: mirrors.huaweicloud.com    - updates: mirrors.huaweicloud.com  Available Environment Groups:  Minimal Install  Compute Node  Infrastructure Server  File and Print Server  Cinnamon Desktop  MATE Desktop  Basic Web Server  Virtualization Host  Server with GUI  GNOME Desktop  KDE Plasma Workspaces  Development and Creative Workstation  Available Groups:  Cinnamon  Compatibility Libraries  Console Internet Tools  Development Tools  Educational Software  Electronic Lab  Fedora Packager  General Purpose Desktop  Graphical Administration Tools  Haskell  Legacy UNIX Compatibility  MATE  Milkymist  Scientific Support  Security Tools  Smart Card Support  System Administration Tools  System Management  TurboGears application framework  Xfce  Done</code></pre><p><strong>注意：此例只是示例，只是表示可以这样使用，并不代表真的存在相关描述的软件包。因为从包组中查找安装软件包非常少用，几乎用不到。如果想安装某个软件包，可以使用yum list | grep “软件包名或通配”来完成。</strong></p><p><strong>至此，Linux常用的系统管理命令已经更新完毕，其实，在Linux系统管理中最常用的还是一些管理工具，会在Linux常用工具分类中系统管理工具有总体介绍。</strong></p><p><strong>随着Linux系统管理命令更新结束，Linux系统核心命令部分全部更新完毕，共分为10篇，约70-80个常用命令，与Linux系统总体命令600余个相比还差很远。但是，这些常用命令以及后续介绍常用工具是一个运维人员必须掌握的，至于其它命令和工具在实际中碰到了再查询使用帮助即可。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;lsof：查看进程打开的文件&quot;&gt;&lt;a href=&quot;#lsof：查看进程打开的文件&quot; class=&quot;headerlink&quot; title=&quot;lsof：查看进程打开的文件&quot;&gt;&lt;/a&gt;lsof：查看进程打开的文件&lt;/h2&gt;&lt;p&gt;lsof全名为list open files，也就是列举系统中已经被打开的文件，通过lsof命令，就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。
    
    </summary>
    
      <category term="Linux核心命令" scheme="https://kkutysllb.cn/categories/Linux%E6%A0%B8%E5%BF%83%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="Linux" scheme="https://kkutysllb.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-25-Linux系统命令-第九篇《网络管理命令》</title>
    <link href="https://kkutysllb.cn/2019/05/25/2019-05-25-Linux%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4-%E7%AC%AC%E4%B9%9D%E7%AF%87%E3%80%8A%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E3%80%8B/"/>
    <id>https://kkutysllb.cn/2019/05/25/2019-05-25-Linux系统命令-第九篇《网络管理命令》/</id>
    <published>2019-05-25T13:51:45.000Z</published>
    <updated>2019-05-25T14:13:21.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ifconfig：配置或显示网络接口信息"><a href="#ifconfig：配置或显示网络接口信息" class="headerlink" title="ifconfig：配置或显示网络接口信息"></a>ifconfig：配置或显示网络接口信息</h2><p>ifconfig命令用于配置网卡IP地址等网络参数或显示当前网络的接口状态，其类似于Windows下的ipconfig命令，这两个命令很容易混淆，读者需要区分一下。此外，ifconfig命令在配置网卡信息时必须以root用户的身份来执行。使用ifconfig命令配置网卡信息仅会临时生效，重启网络或服务器配置就会失效。要想配置永久生效，正确的姿势是“编辑配置网卡配置文件”。<a id="more"></a></p><p>如果系统中没有ifconfig命令，那就需要安装一下，安装命令为yum-y install net-tools。</p><p>interface为网络接口名，Linux下的网络接口名类似于eth0、eth1和lo等，分别表示第1块网卡、第2块网卡和回环接口。这是个可选项，如果不添加此选项，则显示系统中所有的网卡信息；如果添加此选项，则显示指定的网卡信息。</p><p><strong>语法格式：ifconfig [interface] [option]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce948c28413a32697.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示当前系统开启的所有网络接口</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用ifconfig不带任何选项显示所有活动的网络接口</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig</span></span><br><span class="line">docker0: flags=4163  mtu 1500</span><br><span class="line">inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class="line">inet6 fe80::42:56ff:fe71:5647  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 02:42:56:71:56:47  txqueuelen 0  (Ethernet)</span><br><span class="line">RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 8  bytes 648 (648.0 B)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">eth0: flags=4163  mtu 1500</span><br><span class="line">inet 192.168.101.81  netmask 255.255.255.0  broadcast 192.168.101.255</span><br><span class="line">inet6 fe80::20c:29ff:fe17:f09e  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 00:0c:29:17:f0:9e  txqueuelen 1000  (Ethernet)</span><br><span class="line">RX packets 84  bytes 9437 (9.2 KiB)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 112  bytes 11835 (11.5 KiB)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">eth1: flags=4163  mtu 1500</span><br><span class="line">inet 172.0.2.81  netmask 255.255.255.0  broadcast 172.0.2.255</span><br><span class="line">inet6 fe80::20c:29ff:fe17:f0a8  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 00:0c:29:17:f0:a8  txqueuelen 1000  (Ethernet)</span><br><span class="line">RX packets 1  bytes 243 (243.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 14  bytes 1008 (1008.0 B)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">inet 10.0.5.81  netmask 255.255.255.0  broadcast 10.0.5.255</span><br><span class="line">inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">RX packets 1  bytes 243 (243.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 14  bytes 1008 (1008.0 B)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">lo: flags=73  mtu 65536</span><br><span class="line">inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">inet6 ::1  prefixlen 128  scopeid 0x10</span><br><span class="line">loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">veth1f3cf35: flags=4163  mtu 1500</span><br><span class="line">inet6 fe80::483c:5fff:fe03:30fa  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 4a:3c:5f:03:30:fa  txqueuelen 0  (Ethernet)</span><br><span class="line">RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 16  bytes 1296 (1.2 KiB)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>2）显示指定网卡信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示网卡eth2的信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">inet 10.0.5.81  netmask 255.255.255.0  broadcast 10.0.5.255</span><br><span class="line">inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">RX packets 2  bytes 501 (501.0 B)</span><br><span class="line">RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">TX packets 14  bytes 1008 (1008.0 B)</span><br><span class="line">TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>3）启动/关闭指定网卡</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭eth2网卡</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2 down</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-a选项查询关闭状态下的网卡信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网卡flags没有UP项，表示网卡关闭</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig -a eth2</span></span><br><span class="line">eth2: flags=4098  mtu 1500</span><br><span class="line">        inet 10.0.5.81  netmask 255.255.255.0  broadcast 10.0.5.255</span><br><span class="line">        ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 12  bytes 1572 (1.5 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 14  bytes 1008 (1008.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次启动网卡eth2</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2 up</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig -a eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.81  netmask 255.255.255.0  broadcast 10.0.5.255</span><br><span class="line">        inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 12  bytes 1572 (1.5 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 21  bytes 1586 (1.5 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>4）配置网卡ip地址</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询网卡eth2的ip地址信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示eth2网卡的ip为10.0.5.81</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.81  netmask 255.255.255.0  broadcast 10.0.5.255</span><br><span class="line">        inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 13  bytes 1830 (1.7 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 22  bytes 1656 (1.6 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改eth2网卡的ip地址为10.0.5.181</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2 10.0.5.181</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.181  netmask 255.0.0.0  broadcast 10.255.255.255</span><br><span class="line">        inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 13  bytes 1830 (1.7 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 22  bytes 1656 (1.6 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>在实际运维中，除非测试环境，否则不建议这样修改网卡ip地址，因为会引起生产环境网络连接异常。如果要增加对应ip，可以给对应网卡增加子接口的方式实现，见下面示例。</strong></p><p><strong>5）添加网卡子接口，并配置ip地址</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网卡子接口的格式eth2:0、eth2:1.。。。</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2:0 192.168.101.181/24 up</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2:0</span></span><br><span class="line">eth2:0: flags=4163  mtu 1500</span><br><span class="line">inet 192.168.101.181  netmask 255.255.255.0  broadcast 192.168.101.255</span><br><span class="line">ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br></pre></td></tr></table></figure><p><strong>6）修改网卡MAC地址</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查询eth2的MAC地址为ether 00:0c:29:17:f0:b2</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.181  netmask 255.0.0.0  broadcast 10.255.255.255</span><br><span class="line">        inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:0c:29:17:f0:b2  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 22  bytes 4077 (3.9 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 22  bytes 1656 (1.6 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用hw选项和网卡类型关键ether修改MAC地址</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2 hw ether 00:AA:BB:CC:DD:EE</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.181  netmask 255.0.0.0  broadcast 10.255.255.255</span><br><span class="line">        inet6 fe80::20c:29ff:fe17:f0b2  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:aa:bb:cc:dd:ee  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 23  bytes 4320 (4.2 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 22  bytes 1656 (1.6 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>总结：上述修改在服务器重启后就失效了，要想永久生效，只能修改网卡的配置文件。CentOS系统的网卡配置文件在/etc/sysconfig/network-scripts/下，Ubuntu系统在/etc/network/interfaces中。</strong></p><h2 id="ifup：激活网络接口"><a href="#ifup：激活网络接口" class="headerlink" title="ifup：激活网络接口"></a>ifup：激活网络接口</h2><p>ifup命令用于激活指定的网络接口。ifup命令其实是一个Shell脚本，有Shell基础的读者可以使用which命令来找到这个脚本并读一读。ifup命令可读取配置文件/etc/sysconfig/network和/etc/sysconfig/network-scripts/ifcfg-<configuration>对网络接口进行相应的操作。</configuration></p><p><strong>语法格式：ifup [iface]</strong></p><p><strong>【使用示例】</strong></p><p><strong>激活网络接口</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用ifconfig down关闭网络接口eth2，再使用ifup激活</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2 down</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4098  mtu 1500</span><br><span class="line">        inet 10.0.5.181  netmask 255.0.0.0  broadcast 10.255.255.255</span><br><span class="line">        ether 00:aa:bb:cc:dd:ee  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 23  bytes 4320 (4.2 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 22  bytes 1656 (1.6 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifup eth2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ifconfig eth2</span></span><br><span class="line">eth2: flags=4163  mtu 1500</span><br><span class="line">        inet 10.0.5.181  netmask 255.0.0.0  broadcast 10.255.255.255</span><br><span class="line">        inet6 fe80::2aa:bbff:fecc:ddee  prefixlen 64  scopeid 0x20</span><br><span class="line">        ether 00:aa:bb:cc:dd:ee  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 23  bytes 4320 (4.2 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 35  bytes 2634 (2.5 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p><strong>除了激活网卡用ifup外，还有个关闭网卡指令ifdown，用法和ifup类似，请大家自行练习。</strong></p><h2 id="route：显示或管理路由表"><a href="#route：显示或管理路由表" class="headerlink" title="route：显示或管理路由表"></a>route：显示或管理路由表</h2><p>route命令可以显示或管理Linux系统的路由表，route命令设置的路由主要是静态路由。Linux上配置的路由都属于静态路由。静态路由规则是系统管理员使用route命令加入的，也就是通过手动输入的方式来加入的路由规则。动态路由无需手动配置，其路由规则是本机与不同的机器彼此经过路由程序（Routing daemon）相互交换路由规则而来的。</p><p><strong>语法格式：route [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce94a18a931965974.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）查看当前系统的路由表信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接使用route命令就可以查看当前系统的路由表信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">default         gateway         0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-ee选项可以查看更详细的路由表信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -ee</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface    MSS   Window irtt</span><br><span class="line">default         gateway         0.0.0.0         UG    0      0        0 eth0     0     0      0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2     0     0      0</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2     0     0      0</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1002   0        0 eth0     0     0      0</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1003   0        0 eth1     0     0      0</span><br><span class="line">link-local      0.0.0.0         255.255.0.0     U     1004   0        0 eth2     0     0      0</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1     0     0      0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker   0     0      0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0     0     0      0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-n选项可以不进行DNS解析，这样会加快显示</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br></pre></td></tr></table></figure><blockquote><p><strong>命令结果说明如下：</strong></p><p>Destination：表示网络号，也就是network的意思。</p><p>Gateway：连出网关地址，也就是说该网络是通过该IP连接出去的，如果显示0.0.0.0，则表示该路由是直接由本机传送出去的。如果有IP显示，则表示本条路由必须经过该IP的转接才能连接出去。</p><p>Genmask：表示子网掩码地址，也就是netmask。Destination和Genmask将组合成一个完整的网络地址段。</p><p>Flags：路由标记信息，通常会有下面几种不同的标记：</p><p>​    U（route is up）：表示此路由当前为启动状态。</p><p>​    H（target is a host）：目标路由是一个主机（IP）而非网络。</p><p>​    R（reinstate route for dynamic routing）：使用动态路由时，恢复路由信息标识。</p><p>​    G（use gateway）：表示需要通过外部的主机（gateway）来转接传递数据。</p><p>​    M（modified from routing daemon or redirect）：表示路由已经被修改了。</p><p>​    D（dynamically installed by daemon or redirect）：已经由服务设定为动态路由。</p><p>​    ！（reject route）：这个路由将不会被接受（用来抵挡不安全的网络）。</p><p>Metric：需要经过几个网络节点（hops）才能到达路由的目标网络地址。</p><p>Ref：学习到此路由规则的数目。</p><p>Use：有几个转发数据包学习到了此路由规则。</p><p>Iface：路由对应的网络设备接口。</p></blockquote><p><strong>命令输出结果的第一行是系统的默认网关信息，表示去任何地方（0.0.0.0）都发给192.168.101.2，因为是默认网关，所以放在了第一条，如果不符合任何一条规则就交给默认网关来处理。</strong></p><p><strong>2）删除和添加默认网关</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示路由信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一种方式删除默认网关</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route del default</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一种方式添加默认网关</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route add default gw 192.168.101.2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方式删除默认网关</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route del default gw 192.168.101.2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方式添加默认网关</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route add default gw 192.168.101.2 dev eth0</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth2</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br></pre></td></tr></table></figure><p><strong>3）配置网络路由</strong></p><p>一般多网段之间互相通信，会希望建立一条优先路由，而不是通过默认网关，这时就可以配置网络路由。还是拿房子作比喻，你现在不是要出门，而是要去卧室或卫生间，去卧室就要经过卧室的门，去卫生间就要经过卫生间的门，这里的卧室和卫生间的门就可以认为是去往某一网段的路由，而不是默认路由（即房子的大门）。在实际工作中也会有类似的需求，即两个不同的内部网络之间互相访问，而不是出网访问。</p><p>由于我们是VMware虚拟机实验环境，因此，我们主要验证虚拟机主机之间互通。主机的网段是192.168.100.0/24，虚拟机网段是192.168.101.0/24。在虚拟机安装完成后，天生就具备和主机进行互通，这是因为VMware虚拟网卡的网关功能实现。为了验证我们的配置，首先需要删除虚拟机上的默认网关，然后添加到主机的静态路由来验证。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不删除默认网关，虚拟机可以ping主机（我的主机地址是192.168.100.199）</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping -c 5 192.168.100.199</span></span><br><span class="line">PING 192.168.100.199 (192.168.100.199) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=1 ttl=128 time=0.277 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=2 ttl=128 time=0.566 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=3 ttl=128 time=0.497 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=4 ttl=128 time=2.19 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=5 ttl=128 time=0.524 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.100.199 ping statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0% packet loss, time 4004ms</span><br><span class="line">rtt min/avg/max/mdev = 0.277/0.811/2.193/0.698 ms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除虚拟机默认路由后再次尝试ping主机</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route del default gw 192.168.101.2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping -c 5 192.168.100.199</span></span><br><span class="line">connect: Network is unreachable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到主机网段的静态路由</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route add -net 192.168.100.0/24 gw 192.168.101.2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping -c 5 192.168.100.199</span></span><br><span class="line">PING 192.168.100.199 (192.168.100.199) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=1 ttl=128 time=0.736 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=2 ttl=128 time=0.466 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=3 ttl=128 time=0.690 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=4 ttl=128 time=0.416 ms</span><br><span class="line">64 bytes from 192.168.100.199: icmp_seq=5 ttl=128 time=0.467 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.100.199 ping statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0% packet loss, time 4002ms</span><br><span class="line">rtt min/avg/max/mdev = 0.416/0.555/0.736/0.131 ms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询路右边，发现多了一条道192.168.100.0/24网段的静态路由，从eth0网口转发</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.100.0   192.168.101.2   255.255.255.0   UG    0      0        0 eth0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br></pre></td></tr></table></figure><p><strong>上述的路由配置只是临时的，要想永久生效可以有多种方法，但是建议大家采用如下方式实现：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一个路由配置文件route-eth0</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># touch /etc/sysconfig/network-scripts/route-eth0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下内容到配置文件中</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo "192.168.100.0/24 via 192.168.101.2" &gt;&gt; /etc/sysconfig/network-scripts/route-eth0</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># cat /etc/sysconfig/network-scripts/route-eth0 </span></span><br><span class="line">192.168.100.0/24 via 192.168.101.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启网卡或重启系统后永久生效</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl restart network</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1004   0        0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U     0      0        0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.100.0   192.168.101.2   255.255.255.0   UG    0      0        0 eth0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br></pre></td></tr></table></figure><p><strong>4）配置/删除到主机的路由</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加到C7-Server02主机（192.168.101.82）的静态路由，由eth2网口转发</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route add -host 192.168.101.82 dev eth2</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># route -n|tail -1</span></span><br><span class="line">192.168.101.82  0.0.0.0         255.255.255.255 UH    0      0        0 eth2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试trace，查看配置是否生效</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># traceroute -In 192.168.101.82</span></span><br><span class="line">traceroute to 192.168.101.82 (192.168.101.82), 30 hops max, 60 byte packets</span><br><span class="line"> 1  192.168.101.82  0.434 ms  0.484 ms  0.498 ms</span><br></pre></td></tr></table></figure><p><strong>在keepalived或HA高可用服务器对之间使用单独的网卡接心跳线通信时，就会用到以上的主机路由。</strong></p><h2 id="arp：管理系统的arp缓存"><a href="#arp：管理系统的arp缓存" class="headerlink" title="arp：管理系统的arp缓存"></a>arp：管理系统的arp缓存</h2><p>arp命令用于操作本机的arp缓存区，它可以显示arp缓存区中的所有条目、删除指定的条目或者添加静态的IP地址与MAC地址的对应关系。APR主要功能是根据IP地址获取物理地址（MAC地址）。</p><p><strong>语法格式：arp [option]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce94af8b0a4187954.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示arp缓存区的所有条目</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># arp</span></span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">192.168.101.82           ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line">gateway                  ether   00:50:56:f8:93:68   C                     eth0</span><br><span class="line">192.168.101.1            ether   00:50:56:c0:00:08   C                     eth0</span><br><span class="line">10.0.5.82                ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-n选项，以数字ip的形式显示缓存区所有条目</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># arp -n</span></span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">192.168.101.82           ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line">192.168.101.2            ether   00:50:56:f8:93:68   C                     eth0</span><br><span class="line">192.168.101.1            ether   00:50:56:c0:00:08   C                     eth0</span><br><span class="line">10.0.5.82                ether   00:0c:29:d3:54:c1   C                     eth2</span><br></pre></td></tr></table></figure><blockquote><p><strong>输出结果说明：</strong></p><p>Address：主机地址。</p><p>Hwtype：硬件类型。</p><p>Hwaddress：硬件地址。</p><p>Flags Mask：记录标志，“C”表示arp高速缓存中的条目，“M”表示静态的arp条目。</p><p>Iface：网络接口。</p></blockquote><p><strong>2）绑定静态ip地址和MAC地址</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-s选项可以绑定主机ip和固定mac地址的映射关系</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># arp -s 192.168.101.254 00:AA:BB:CC:DD:EE</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># arp -n</span></span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">192.168.101.82           ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line">192.168.101.2            ether   00:50:56:f8:93:68   C                     eth0</span><br><span class="line">192.168.101.254          ether   00:aa:bb:cc:dd:ee   CM                    eth0</span><br><span class="line">192.168.101.1            ether   00:50:56:c0:00:08   C                     eth0</span><br><span class="line">10.0.5.82                ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除绑定关系可以使用选项-d</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># arp -d 192.168.101.254</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># arp -n</span></span><br><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">192.168.101.82           ether   00:0c:29:d3:54:c1   C                     eth2</span><br><span class="line">192.168.101.2            ether   00:50:56:f8:93:68   C                     eth0</span><br><span class="line">192.168.101.1            ether   00:50:56:c0:00:08   C                     eth0</span><br><span class="line">10.0.5.82                ether   00:0c:29:d3:54:c1   C                     eth2</span><br></pre></td></tr></table></figure><p><strong>当局域网有arp病毒时，就可以用上述方法绑定MAC地址，以防止中毒。</strong></p><h2 id="netstat：查看网络状态"><a href="#netstat：查看网络状态" class="headerlink" title="netstat：查看网络状态"></a>netstat：查看网络状态</h2><p>netstat命令用于显示本机网络的连接状态、运行端口和路由表等信息。</p><p><strong>语法格式：netstat [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce94b6a6ac4364705.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）常用选项组合</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -an选项组合以ip地址的形式显示所有socket的监听信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># netstat -an</span></span><br><span class="line">Active Internet connections (servers and established)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State      </span><br><span class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     </span><br><span class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     </span><br><span class="line">tcp        0     52 192.168.101.81:22       192.168.101.1:6481      ESTABLISHED</span><br><span class="line">tcp6       0      0 :::4000                 :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::80                   :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 :::22                   :::*                    LISTEN     </span><br><span class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN     </span><br><span class="line">udp        0      0 127.0.0.1:323           0.0.0.0:*                          </span><br><span class="line">udp6       0      0 ::1:323                 :::*                               </span><br><span class="line">Active UNIX domain sockets (servers and established)</span><br><span class="line">Proto RefCnt Flags       Type       State         I-Node   Path</span><br><span class="line">unix  2      [ ACC ]     STREAM     LISTENING     19221    /var/run/vmware/guestServicePipe</span><br><span class="line">unix  2      [ ACC ]     STREAM     LISTENING     27162    /var/run/docker.sock</span><br><span class="line">unix  3      [ ]         DGRAM                    31       /run/systemd/notify</span><br><span class="line">unix  2      [ ]         DGRAM                    33       /run/systemd/cgroups-agent</span><br><span class="line">unix  2      [ ACC ]     STREAM     LISTENING     22569    /var/run/docker.sock</span><br><span class="line">unix  2      [ ACC ]     STREAM     LISTENING     41       /run/systemd/journal/stdout</span><br><span class="line">unix  2      [ ACC ]     STREAM     LISTENING     22571    /run/dbus/system_bus_socket</span><br><span class="line">unix  6      [ ]         DGRAM                    44       /run/systemd/journal/socket</span><br><span class="line">unix  12     [ ]         DGRAM                    46       /dev/<span class="built_in">log</span></span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-lntup选项组合，查看所有监听连接的端口和进程PID</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># netstat -lntup</span></span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </span><br><span class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1038/sshd           </span><br><span class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1310/master         </span><br><span class="line">tcp6       0      0 :::4000                 :::*                    LISTEN      1648/docker-proxy   </span><br><span class="line">tcp6       0      0 :::80                   :::*                    LISTEN      1042/httpd          </span><br><span class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1038/sshd           </span><br><span class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN      1310/master         </span><br><span class="line">udp        0      0 127.0.0.1:323           0.0.0.0:*                           645/chronyd         </span><br><span class="line">udp6       0      0 ::1:323                 :::*</span><br></pre></td></tr></table></figure><blockquote><p><strong>输出结果说明如下：</strong></p><p>Active Internet connections (servers and established) ：表示活动的TCP/IP网络连接。</p><p>Active UNIX domain sockets (servers and established)：表示活动的unix socket连接。</p><p>Proto：表示socket使用的协议（TCP、UDP、RAW）</p><p>Recv-Q：接收到但还未处理的字节数。</p><p>Send-Q：已经发送，但是还未收到远程主机响应的自己数。</p><p>Local Address：本地主机地址和端口信息。</p><p>Foreign Address：远程主机的地址和端口信息。</p><p>State：socket的状态，通常仅有TCP的状态信息，状态值有ESTABBLISHED、SYN_SENT、SYN_RECV、FIN_WAIT、FIN_WAIT2、TIME_WAIT等。</p></blockquote><p><strong>2）显示当前系统的路由信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-r选项显示系统路由表信息，使用-n选项显示ip地址，不进行DNS解析</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># netstat -rn</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface</span><br><span class="line">0.0.0.0         192.168.101.2   0.0.0.0         UG        0 0          0 eth0</span><br><span class="line">10.0.5.0        0.0.0.0         255.255.255.0   U         0 0          0 eth2</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth2</span><br><span class="line">172.0.2.0       0.0.0.0         255.255.255.0   U         0 0          0 eth1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U         0 0          0 docker0</span><br><span class="line">192.168.100.0   192.168.101.2   255.255.255.0   UG        0 0          0 eth0</span><br><span class="line">192.168.101.0   0.0.0.0         255.255.255.0   U         0 0          0 eth0</span><br><span class="line">192.168.101.82  0.0.0.0         255.255.255.255 UH        0 0          0 eth2</span><br></pre></td></tr></table></figure><p><strong>3）显示网卡状态</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-i选项显示网络接口状态信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># netstat -i</span></span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface             MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">docker0          1500        0      0      0 0             8      0      0      0 BMRU</span><br><span class="line">eth0             1500     8480      0      0 0          4404      0      0      0 BMRU</span><br><span class="line">eth1             1500       24      0      0 0            54      0      0      0 BMRU</span><br><span class="line">eth2             1500       41      0      0 0            60      0      0      0 BMRU</span><br><span class="line">lo              65536       10      0      0 0            10      0      0      0 LRU</span><br><span class="line">vethe5480a8      1500        0      0      0 0            16      0      0      0 BMRU</span><br></pre></td></tr></table></figure><blockquote><p><strong>输出结果说明如下：</strong></p><p>Iface：表示网络设备的接口名称。</p><p>MTU：表示最大传输单元，单位为字节。</p><p>RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。</p><p>RX-ERR/TX-ERR：表示接收/发送数据包时产生了多少错误。</p><p>RX-DRP/TX-DRP：表示接收/发送数据包时丢弃了多少数据包。</p><p>RX-OVR/TX-OVR：表示由于误差而遗失了多少数据包。</p><p>Flg：表示接口标记，其中各标记含义具体如下。</p><p>​    L：表示该接口是个回环设备。</p><p>​    B：表示设置了广播地址。</p><p>​    M：表示接收所有数据包。</p><p>​    R：表示接口正在运行。</p><p>​    U：表示接口处于活动状态。</p><p>​    O：表示在该接口上禁用arp。</p><p>​    P：表示一个点到点的连接。</p></blockquote><p><strong>正常情况下，RX-ERR/TX-ERR、RX-DRP/TX-DRP和RX-OVR/TX-OVR的值都应该为0，如果这几个选项的值不为0，并且很大，那么网络质量肯定有问题，网络传输性能也一定会下降。</strong></p><h2 id="ping：测试主机之间网络的连通性"><a href="#ping：测试主机之间网络的连通性" class="headerlink" title="ping：测试主机之间网络的连通性"></a>ping：测试主机之间网络的连通性</h2><p>ping命令可用于测试主机之间网络的连通性。执行ping命令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而可得知该主机运作正常。但是，如果ping不通，不一定是网络问题，也可能是远端主机设置了禁ping功能，就是收到ICMP包不会回应。</p><p><strong>语法格式：ping [option] [destination]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce94c01ae0ff71667.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）测试目标主机的网络连通性</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试openstack官网的连通性</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping www.openstack.org</span></span><br><span class="line">PING www.openstack.org.cdn.cloudflare.net (104.20.111.33) 56(84) bytes of data.</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=1 ttl=128 time=41.8 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=2 ttl=128 time=40.7 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=3 ttl=128 time=41.0 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=6 ttl=128 time=49.0 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=7 ttl=128 time=40.2 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=8 ttl=128 time=40.9 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=9 ttl=128 time=40.9 ms</span><br><span class="line">64 bytes from 104.20.111.33 (104.20.111.33): icmp_seq=10 ttl=128 time=41.7 ms</span><br><span class="line">。。。。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时不使用ctrl+c就会一直ping下去</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-c选项，设定ping的次数</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping -c 3 www.openstack.org</span></span><br><span class="line">PING www.openstack.org.cdn.cloudflare.net (104.20.110.33) 56(84) bytes of data.</span><br><span class="line">64 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=1 ttl=128 time=63.3 ms</span><br><span class="line">64 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=2 ttl=128 time=54.0 ms</span><br><span class="line">64 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=3 ttl=128 time=54.0 ms</span><br><span class="line"></span><br><span class="line">--- www.openstack.org.cdn.cloudflare.net ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 5517ms</span><br><span class="line">rtt min/avg/max/mdev = 54.017/57.164/63.387/4.404 ms</span><br></pre></td></tr></table></figure><p>ping命令会显示一个时间作为衡量网络延迟的参数，以判断源主机与目标主机之间网络的质量。ping命令的输出信息中含有TTL值。TTL（Time To Life）称为生存期，它是ICMP报文在网络上的存活时间。不同的操作系统发出的ICMP报文的生存期各不相同，常见的生存期为32、64、128和255等。TTL值反映了ICMP报文所能够经过的路由器数目，每经过一个路由器，路由器都会将其数据包的生存期减去1，如果TTL值变为0，则路由器将不再转发此报文。</p><p><strong>2）用1k的大包测试</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-s选项可以这是ICMP包的大小</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ping -c 5 -s 1024 www.openstack.org</span></span><br><span class="line">PING www.openstack.org.cdn.cloudflare.net (104.20.110.33) 1024(1052) bytes of data.</span><br><span class="line">1032 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=1 ttl=128 time=55.2 ms</span><br><span class="line">1032 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=2 ttl=128 time=55.6 ms</span><br><span class="line">1032 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=3 ttl=128 time=55.2 ms</span><br><span class="line">1032 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=4 ttl=128 time=55.0 ms</span><br><span class="line">1032 bytes from 104.20.110.33 (104.20.110.33): icmp_seq=5 ttl=128 time=63.0 ms</span><br><span class="line">--- www.openstack.org.cdn.cloudflare.net ping statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0% packet loss, time 7575ms</span><br><span class="line">rtt min/avg/max/mdev = 55.084/56.875/63.085/3.122 ms</span><br></pre></td></tr></table></figure><h2 id="telnet：远程登录主机"><a href="#telnet：远程登录主机" class="headerlink" title="telnet：远程登录主机"></a>telnet：远程登录主机</h2><p>telnet命令以前是用于登录远程主机，对远程主机进行管理的。但是因为telnet是采用明文传送报文的，其安全性不好，因此现在很多Linux服务器都不开放telnet服务，而是改用更安全的SSH服务了。现在，只有在交换机等网络设备还可能呢会采用telnet登录的方式。<strong>但是，使用telnet命令还可以判断远端服务器的端口是否开放，这是目前telnet命令使用最主要场景。</strong></p><p><strong>语法格式：telnet [option] [host] [port]</strong></p><p><strong>【使用示例】</strong></p><p><strong>测试SSH服务端口是否开放</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试192.168.101.83的ssh服务是否开放</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># telnet 192.168.101.83 22  # 22端口就是ssh服务的端口</span></span><br><span class="line">Trying 192.168.101.83...</span><br><span class="line">Connected to 192.168.101.83.</span><br><span class="line">Escape character is <span class="string">'^]'</span>.</span><br><span class="line">SSH-2.0-OpenSSH_7.4   <span class="comment"># &lt;==看到这种结果，就证明SSH服务的22端口已经开放了。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时命令行已经挂起了，不能再进行其他操作，Ctrl+C也无法退出。根据提示输入“Ctrl+]”，然后进入telnet命令行，输入quit就能退出。</span></span><br><span class="line"></span><br><span class="line">SSH-2.0-OpenSSH_7.4</span><br><span class="line">^]</span><br><span class="line">telnet&gt; quit</span><br><span class="line">Connection closed.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 出现下列情况表示服务未开启或端口被屏蔽无法访问</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># telnet 192.168.101.83 23</span></span><br><span class="line">Trying 192.168.101.83...</span><br><span class="line">telnet: connect to address 192.168.101.83: Connection refused</span><br></pre></td></tr></table></figure><h2 id="wget：命令行下载工具"><a href="#wget：命令行下载工具" class="headerlink" title="wget：命令行下载工具"></a>wget：命令行下载工具</h2><p>wget命令用于从网络上下载某些资料，该命令对于能够连接到互联网的Linux系统，作用非常大，可以直接从网络上下载自己所需要的文件。wget的特点如下：</p><ol><li>支持断点下载功能。</li><li>支持FTP和HTTP下载方式。</li><li>支持代理服务器。</li><li>非常稳定，它在带宽很窄的情况下或不稳定的网络中有很强的适应性。如果是由于网络的原因下载失败，wget会不断地尝试，直到整个文件下载完毕。如果是服务器打断了下载过程，它会再次连接到服务器上从停止的地方继续下载。这对那些从限定了连接时间的服务器上下载大文件非常有用。</li></ol><p><strong>语法格式：wget [option] [url]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce94c90227ad34833.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）使用wget下载单个文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从阿里云镜像服务器上下载epel源</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget http://mirrors.aliyun.com/repo/epel-6.repo</span></span><br><span class="line">--2019-05-04 17:46:56--  http://mirrors.aliyun.com/repo/epel-6.repo</span><br><span class="line">Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 183.201.217.232, 183.201.229.102, 183.201.217.227, ...</span><br><span class="line">Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|183.201.217.232|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 664 [application/octet-stream]</span><br><span class="line">Saving to: ‘epel-6.repo’</span><br><span class="line">100%[======================================================&gt;] 664         --.-K/s   <span class="keyword">in</span> 0s      </span><br><span class="line">2019-05-04 17:46:58 (191 MB/s) - ‘epel-6.repo’ saved [664/664]</span><br></pre></td></tr></table></figure><p><strong>2）指定保存文件名下载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-O选项指定本地保存文件名</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget -O ~/MyCentOS6-epel.repo http://mirrors.aliyun.com/repo/epel-6.repo</span></span><br><span class="line">--2019-05-04 17:48:38--  http://mirrors.aliyun.com/repo/epel-6.repo</span><br><span class="line">Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 183.201.217.230, 183.201.217.233, 111.48.28.118, ...</span><br><span class="line">Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|183.201.217.230|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 664 [application/octet-stream]</span><br><span class="line">Saving to: ‘/root/MyCentOS6-epel.repo’</span><br><span class="line">100%[======================================================&gt;] 664         --.-K/s   <span class="keyword">in</span> 0s      </span><br><span class="line">2019-05-04 17:48:40 (123 MB/s) - ‘/root/MyCentOS6-epel.repo’ saved [664/664]</span><br></pre></td></tr></table></figure><p><strong>wget默认会以最后一个符合“/”的后面的字符来命名，对于动态链接的下载文件名通常会不正确。为了解决这个问题，我们可以使用参数-O来指定一个文件名。</strong></p><p><strong>3）限速加载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用--limit-rate选项限定下载速度为10K</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget -O ~/mydata/myico.ico --limit-rate=10k https://kkutysllb.cn/favicon.ico</span></span><br><span class="line">--2019-05-04 17:52:22--  https://kkutysllb.cn/favicon.ico</span><br><span class="line">Resolving kkutysllb.cn (kkutysllb.cn)... 185.199.110.153</span><br><span class="line">Connecting to kkutysllb.cn (kkutysllb.cn)|185.199.110.153|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 97780 (95K) [image/vnd.microsoft.icon]</span><br><span class="line">Saving to: ‘/root/mydata/myico.ico’</span><br><span class="line">100%[======================================================&gt;] 97,780      10.0KB/s   <span class="keyword">in</span> 9.5s   </span><br><span class="line">2019-05-04 17:52:34 (10.0 KB/s) - ‘/root/mydata/myico.ico’ saved [97780/97780]</span><br><span class="line">[root@C7-Server01 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p><strong>4）断点续传</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从阿里云镜像仓库下载centos6.10的iso镜像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-c选项支持断点续传，当下载到5%时，我们手动通过ctrl+c打断</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget -c https://mirrors.aliyun.com/centos/6/isos/x86_64/CentOS-6.10-x86_64-bin-DVD1.iso</span></span><br><span class="line">--2019-05-04 17:58:23--  https://mirrors.aliyun.com/centos/6/isos/x86_64/CentOS-6.10-x86_64-bin-DVD1.iso</span><br><span class="line">Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 183.203.69.11, 183.201.217.227, 183.203.69.12, ...</span><br><span class="line">Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|183.203.69.11|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 3991928832 (3.7G) [application/octet-stream]</span><br><span class="line">Saving to: ‘CentOS-6.10-x86_64-bin-DVD1.iso’</span><br><span class="line">5% [==&gt;                                                    ] 223,244,572 11.3MB/s  eta 5m 21s ^C</span><br></pre></td></tr></table></figure><p>再次下载，发现继续从5%开始下载，再次在11%打断，再次继续上次地方下载</p><p><img src="https://i.loli.net/2019/05/25/5ce94d0d2045c41932.jpg"></p><p><strong>5）后台下载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-b选项后台下载，同时也可组合-c选项，支持断点续传</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget -bc https://mirrors.aliyun.com/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso</span></span><br><span class="line">Continuing <span class="keyword">in</span> background, pid 3333.</span><br><span class="line">Output will be written to ‘wget-log’.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看下载进度日志文件wget-log</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># tail -f wget-log</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/25/5ce94d3aee85858500.jpg"></p><p><strong>6）伪装下载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用--user-agent选项伪装客户端下载</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" https://kkutysllb.cn/favicon.ico</span></span><br><span class="line">--2019-05-04 18:11:26--  https://kkutysllb.cn/favicon.ico</span><br><span class="line">Resolving kkutysllb.cn (kkutysllb.cn)... 185.199.110.153</span><br><span class="line">Connecting to kkutysllb.cn (kkutysllb.cn)|185.199.110.153|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 97780 (95K) [image/vnd.microsoft.icon]</span><br><span class="line">Saving to: ‘favicon.ico’</span><br><span class="line">100%[======================================================&gt;] 97,780      24.0KB/s   <span class="keyword">in</span> 4.0s   </span><br><span class="line">2019-05-04 18:11:33 (24.0 KB/s) - ‘favicon.ico’ saved [97780/97780]</span><br></pre></td></tr></table></figure><p><strong>有些网站会根据判断代理名称不是浏览器而拒绝你的下载请求，不过你可以通过——user-agent参数进行伪装。</strong></p><p><strong>7）监控网站URL是否正常</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-T选项设置超时时间，单位为秒</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-q关闭尝试连接的输出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用--tries选项设置重试次数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用--spider选项模拟爬虫方式访问网站</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后通过echo $?输出结果判断，如果结果为0就是表示URL正常，否则异常</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># wget -q -T 3 --tries=3 --spider www.sina.com.cn</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo $?</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure><p><strong>上述语句常用自动化运维脚本中。</strong></p><p><strong><em>结论：截止目前Linux系统核心命令中网络管理命令基本介绍这么多，还有一些常用的命令工具，如：抓包（tcpdump），监听（nmap）、追踪（traceroute）、配置（ip、nc）、邮件（mail、mailq）等等会放在Linux常用网络工具一文中介绍。</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ifconfig：配置或显示网络接口信息&quot;&gt;&lt;a href=&quot;#ifconfig：配置或显示网络接口信息&quot; class=&quot;headerlink&quot; title=&quot;ifconfig：配置或显示网络接口信息&quot;&gt;&lt;/a&gt;ifconfig：配置或显示网络接口信息&lt;/h2&gt;&lt;p&gt;ifconfig命令用于配置网卡IP地址等网络参数或显示当前网络的接口状态，其类似于Windows下的ipconfig命令，这两个命令很容易混淆，读者需要区分一下。此外，ifconfig命令在配置网卡信息时必须以root用户的身份来执行。使用ifconfig命令配置网卡信息仅会临时生效，重启网络或服务器配置就会失效。要想配置永久生效，正确的姿势是“编辑配置网卡配置文件”。
    
    </summary>
    
      <category term="Linux核心命令" scheme="https://kkutysllb.cn/categories/Linux%E6%A0%B8%E5%BF%83%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="Linux" scheme="https://kkutysllb.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-25-计算虚拟化之I/O虚拟化</title>
    <link href="https://kkutysllb.cn/2019/05/25/2019-05-25-%E8%AE%A1%E7%AE%97%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B9%8BI-O%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <id>https://kkutysllb.cn/2019/05/25/2019-05-25-计算虚拟化之I-O虚拟化/</id>
    <published>2019-05-25T13:35:24.000Z</published>
    <updated>2019-05-25T13:50:12.793Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IO虚拟化概述"><a href="#IO虚拟化概述" class="headerlink" title="IO虚拟化概述"></a>IO虚拟化概述</h2><p>现实中的外设资源是有限的，为了提高资源的利用率，满足多个虚拟机操作系统对外部设备的访问需求，VMM必须通过I/O虚拟化的方式来实现资源的复用，让有限的资源能被多个虚拟机共享。如何将服务器上的物理设备虚拟化为多个逻辑设备，并将物理设备与逻辑设备解耦，使虚拟机可以在各个虚拟化平台间无缝迁移，正是I/O虚拟化的目标。I/O虚拟化的基本要求主要有以下的三点：<a id="more"></a></p><p><strong>(1) 保真性，</strong>要求在虚拟化平台下进行的I/O访问与非虚拟化条件下的I/O访问除了完成时间差别外，其它效果相同；</p><p><strong>(2) 安全性，</strong>要求各虚拟机操作系统只能访问VMM分配给其的I/O资源，而各I/O设备也只能与属于同一个虚拟机的其它资源进行交互，如存储空间和CPU，而不能越界访问属于其它虚拟机的资源；</p><p><strong>(3) 性能，</strong>要求虚拟化系统下I/O访问的性能与非虚拟化系统下的I/O访问性能接近。</p><p>在这三个基本要求之中最为重要的就是<strong>安全性方面的要求，这是保证虚拟化环境可以正常运行的根本</strong>，只有首先满足这一要求才能保证虚拟化I/O的保真性，对于性能的要求才会有意义。虚拟化环境下之所以会出现安全性的问题是因为虚拟机操作系统可见的地址并不是实际的机器物理地址，而是客户物理地址，设备若无法获知客户物理地址和机器物理地址间的转换关系，直接使用客户物理地址进行内存访问，这会导致非法地址访问、破坏正常数据。</p><p>正是由于I/O虚拟化对于I/O空间安全隔离性方面的要求，所以对于虚拟机操作系统的I/O访问操作一般都需要VMM的介入，而不允许虚拟机操作系统与I/O设备直接进行交互，导致虚拟机操作系统的I/O访问会受到VMM干预，导致性能与非虚拟化环境有较大差距。而VMM介入之所以会导致性能严重损失的根本原因就是发生了上下文切换。</p><p>上下文切换分为两种<strong>，虚拟机与虚拟机之间发生的上下文切换</strong>以及<strong>虚拟机与VMM之间发生的上下文切换</strong>。在I/O虚拟化中影响性能的就是虚拟机和VMM之间的上下文切换。虚拟机操作系统产生的I/O请求会被VMM截获，VMM将I/O请求交由驱动域去处理，驱动域完成I/O请求要返回执行结果，这些过程都会造成上下文切换。虚拟机和VMM之间的上下文切换的开销主要分为以下三个部分：</p><p><strong>（1）直接开销，</strong>这个部分主要由CPU的切换造成，CPU需要停滞虚拟机切换到VMM去执行，之后又要从VMM转回虚拟机执行下一条指令。</p><p><strong>（2）间接开销，两种环境的切换导致需要保存上下文环境。</strong></p><p><strong>（3）同步开销，</strong>这个部分主要是VMM处理VM EXIT造成的。</p><p>因此，一旦发生大量的上下文切换，将严重影响I/O虚拟化的性能，尤其在I/O密集型的任务中，上下文切换导致的开销往往是无法忍受的。为了解决性能的问题，通过DMA重映射、IOMMU等硬件辅助，实现了域间隔离和设备地址转换，保证被分配给虚拟机的设备不会访问不属于该虚拟机的存储器空间。</p><p><strong>I/O虚拟化在具体实现上与CPU和内存虚拟化一样，分为软件与硬件虚拟化；在被虚拟机访问的方式上，又分为共享模式与直接访问模式。</strong></p><h2 id="软件I-O虚拟化技术"><a href="#软件I-O虚拟化技术" class="headerlink" title="软件I/O虚拟化技术"></a>软件I/O虚拟化技术</h2><p>软件I/O虚拟化通过软件模拟设备的方式，使得I/O设备资源能够被多个虚拟机共享，该方式可使I/O设备的利用率得到极大的提高，并且可以做到物理设备与逻辑设备分离，具有良好的通用性，但由于该方式需要VMM的介入而导致多次上下文切换，使得I/O性能受到影响。 其本质是VMM需要截获虚拟机操作系统对外部设备的访问请求，通过软件的方式模拟出真实的物理设备的效果，这样，虚拟机看到的实际只是一个虚拟设备，而不是真正的物理设备，这种模拟的方式就是I/O虚拟化的一种实现，下图所示就是一个典型的虚拟机I/O模型。</p><p><img src="https://i.loli.net/2019/05/25/5ce945341886148676.jpg"></p><p>为了达到虚拟化I/O的目的，VMM截获客户操作系统对设备的访问请求，然后通过软件的方式来模拟真实设备的效果。I/O虚拟化中的设备对软件来说，就是一堆的寄存器（I/O端口）和I/O内存，以及中断和DMA。而设备虚拟化的过程，就是模拟设备的这些寄存器和内存，然后截获Guest OS里面对I/O端口和寄存器的访问，然后通过软件的方式来模拟真实的硬件。软件I/O虚拟化需要解决3个问题：</p><p><strong>1）设备发现:</strong> 需要控制各虚拟机能够访问的设备。</p><p>所谓设备发现就是VMM必须采取某种方式，使得虚拟机能够发现虚拟设备。这样，虚拟机才能够加载相应的驱动程序。</p><p>在没有虚拟化的系统中，由BIOS或者操作系统通过遍历PCI总线上的所有设备完成设备发现过程，而<strong>在虚拟化系统中，则由VMM决定向虚拟机呈现哪些设备</strong>。具体过程要根据设备是否存在于物理总线上来进行。对于一个真实存在于物理总线的设备，如果是不可枚举的类型，例如PS/2键盘，由于这类设备是硬编码固定的，驱动程序会通过其特定的访问方式来检查设备是否存在，因此VMM只要在相应端口上模拟出该设备，虚拟机即可成功检测到它；如果是可枚举的类型，譬如PCI设备或者PCIe设备，这种设备通常定义了完整的设备发现方法，并允许BIOS或者操作系统在设备枚举过程中通过PCI配置空间对其资源进行配置。因此VMM不仅要模拟这些设备本身的逻辑，还要模拟PCI总线的一些属性，包括总线拓扑关系及相应设备的PCI配置空间，以便虚拟机OS在启动时能够发现这些设备。</p><p>VMM不仅可以模拟真实设备，还可以实际并不存在的虚拟设备。由于这类设备并没有现实中的规范和模型与之相对应，因此完全由VMM决定它们的总线类型。这类虚拟设备可以挂载在已有PCI总线上，也可以完全自定义一套新的总线。若使用自定义的新总线，则必须在虚拟机中加载特殊的总线驱动程序，且影响虚拟机在不同虚拟化平台的迁移性。</p><p><strong>2）访问截获:</strong> 通过I/O端口对设备的访问。</p><p>所谓访问截获就是虚拟机操作系统发现虚拟设备之后，虚拟机上的驱动程序就会按照特定接口访问这个虚拟设备。驱动程序对于接口的调用必须能够被VMM截获，并能按照真实设备的行为进行模拟。</p><p>以分配到端口I/O资源的设备为例，由于<strong>CPU对于端口I/O资源的控制与指令流所处的特权级别和相关 I/O位图有关</strong>，而在虚拟化环境中虚拟机OS又被降级到非特权级别，因此OS能否访问设备的I/O端口就完全由I/O位图决定。对于没有直接分配给虚拟机的设备，VMM就可以把它的I/O端口在I/O位图中关闭，当 虚拟机操作系统在访问该端口时，就会抛出一个保护异常，VMM即可获得异常原因，并进而将请求发送给底层设备模拟器进行模拟，并异常访问处理结果返回给虚拟机；如果该设备是直接分配给虚拟机，那么VMM就可以在I/O位图中打开它的I/O端口，这样虚拟机驱动程序就可以直接访问该设备。</p><p>同理，对于分配到MMIO（Memory Mapped I/ O）资源的设备，比如某些PCIe设备，由于MMIO是系统物理地址空间的一部分，物理地址空间由页表管理，因此VMM同样可以通过控制MMIO相应的页表项是否有效来截获虚拟机操作系统对于MMIO资源的访问。</p><p><strong>3）设备模拟：</strong>通过软件的方式模拟真实的物理设备。</p><p>所谓设备模拟就是模拟设备的功能，内容十分多样且复杂。对于像PS/2键盘、鼠标这样的设备，VMM需要根据设备的接口规范模拟设备的所有行为，才能够无需修改驱动就在虚拟机上展现出设备应有的效果。而<strong>对于磁盘存储系统，则不必受限于实际的磁盘控制器以及具体磁盘类型和型号</strong>。比如，对IDE硬盘其I/O端口虚拟化时，底层可以是一块磁盘，可以是一个分区，也可以是不同格式的文件；然后在其上实现一个专门的块设备抽象层；最后在块设备上使用文件系统，并引入一些真实硬件没有的高级特性，例如：加密、备份、增量存储等。</p><p>上述三个环节仅是VMM处理一个虚拟 机所发出I/O请求的流程。在实际中，系统的物理设备需要同时接受来自多个虚拟 机的I/O请求。因此，VMM还要将多个虚拟机的I/O请求合并为单独一个I/O数据流发送给底层设备驱动。当VMM收到来自底层设备驱动完成I/O请求的中断时，VMM还要能够将中断响应结果转发给正确的虚拟机，以通知其I/O操作结束。同时VMM在调度各个虚拟机发送来的I/O请求处理时，必须依据一定的算法确保虚拟机I/O的QoS与设备共享的公平性。</p><p><strong>在实现架构上，软件I/O虚拟化技术主要包括Hypervisor全虚架构和前端/后端的半虚架构来说实现。</strong></p><p><strong>1）全虚拟化—模拟模型**</strong>，即完全使用软件来模拟真实硬件，模拟通常硬件，例如键盘鼠标。**</p><p>该架构使用最为广泛的I/O设备虚拟化模型，采用软件的方式模拟设备行为，为虚拟机模拟出与底层硬件完全一致的虚拟化环境，保证虚拟机操作系统的行为与非虚拟化环境下完全一致。在模拟模型中，虚拟设备必须以某种方式让虚拟机可以发现，导致虚拟机被“<strong>欺骗</strong>”。当虚拟机访问虚拟设备时，访问请求被VMM截获，然后VMM将I/O请求交由domain0来模拟完成，最后将结果返回给虚拟机。如下图所示是一个基于设备模拟的xen的I/O虚拟化模型。</p><p><img src="https://i.loli.net/2019/05/25/5ce945600a26c48392.jpg"></p><p><strong>这种架构最大的优点在于不需要对虚拟机操作系统内核做修改，也不需要为改写其原生驱动程序，因此，这种架构是可移植性与兼容性最佳的一种I/O设备虚拟模型</strong>，这也是它被如此广泛使用的主要原因，除了Xen架构的全虚模型外，VMware的Workstations和ESX都有类似的全虚模型，且是全虚模型的典型代表。</p><p>但是，全虚模型有一个<strong>很大的不足之处，即性能不够高</strong>，主要原因有两方面：第一、模拟方式是用软件行为进行模拟，这种方式本身就无法得到很高的性能；第二、这种模型下I/O请求的完成需要虚拟机与VMM多次的交互，产生大量的上下文切换，造成巨大开销。模拟IO虚拟化方式的<strong>最大开销在于处理器模式的切换：包括从Guest OS到VMM的切换，以及从内核态的VMM到用户态的IO模拟进程之间的切换。</strong></p><p>在全虚拟化，由于VMM实现模式不同，采用的设备虚拟化方式也不同。比如，全虚拟化最有代表性的VMware ESX和VMWare Workstattion。</p><blockquote><p>在VMware ESX中，VMM直接运行在物理硬件之上，直接操作硬件设备，而Guest OS看到的则是一组统一的虚拟IO设备。Guest  OS对这些虚拟设备的每一个IO操作都会陷入VMM 中，由VMM对IO指令进行解析并映射到实际的物理设备，然后直接控制硬件完成。</p><p>而VMWare WorkStation采用了不同的方式。ＶＭＭ实际上运行在一个传统的操作系统之上，这类VMM无法获得对硬件资源的完全控制，因此采用软件模拟的方式来模拟IO设备。Guest OS的IO操作会被VMM捕获，并转发给宿主机（host OS）的一个用户态进程，该进程通过对宿主机操作系统的系统调用来模拟设备的行为。</p></blockquote><p>以下是VMware的ESX架构，<strong>VMkernel负责管理虚拟机对于网络和存储设备的访问。</strong>通过设备模拟术，不同的物理设备对于虚拟机可以呈现为某种特定的虚拟设备，甚至并不存在的虚拟设备。</p><p><img src="https://i.loli.net/2019/05/25/5ce9459328c1395295.jpg"></p><p>对于存储，物理服务器上部署的可能是某种SCSI设备、磁盘阵列甚至是SAN存储网络，但是ESX能够模拟出BusLogic或者LSILogic的SCSI适配器，因此对于虚拟机总是呈现为SCSI设备。而对于网络ESX则模拟为AMD Lance适配器或者一个并不存在的自定义接口vmxnet，来帮助虚拟机对网络的问。上图显示了在ESXi服务器内部经过的I/O路径。其中，虚拟机分别使用vmxnet虚拟网络适配器与LSI Logic虚拟SCSI适配器对网络和存储进行访问，而物理服务器则使用Intel e1000网卡连接到SAN网络的QLogic光纤HBA卡。</p><ul><li>第1步所示，虚拟机中的某个应用程序通过操作系统发起I/O访问，比如发送一个网络数据包或者向磁盘写入一个文件；</li><li>第2步表示操作系统对其进行处理，并调用设备驱动处理相应的I/O请求；</li><li>第3步表示当设驱动试图访问外设时，VMM拦截到该操作并将控制权切换到Vmkernel；</li><li>第4步为VMkernel获得控制权后，I/O请求会被转发到与设备无关的网络或者存储抽象层进行处理；</li><li>第5步表示VMkernel还会同时接收到来自其他虚拟机的多个I/O请求，并对这些I/O请求按照特定算法进行优先级调度处理。</li></ul><p>I/O请求最终会被转发到具有物理设备驱动程序的硬件接口层进行处理。当I/O请求的完成中断到达时，I/O处理过程则与上述路径完全相反。VMkernel中设备驱动会将到达的中断保护起来，并调用VMkernel来处理该中断；接下来VMkernel会通知相应虚拟机的VMM进程，VMM进程会向虚拟机发起中断，以通知I/O请求处理完毕；同时VMkernel还要确保I/O处理完毕的相关信息与其他虚拟机的数据相互隔离。</p><p>由于上述过程需要VMkernel处理I/O请求，因此从虚拟机到VMkernel上下文的切换过程会导致一定的开销。为了降低开销，vmxnet在收发数据包之前，会收集一组数据包再转发给各个虚拟机或者一起发送出去。对于多个虚拟机之间的设备资源管理方面，对于网络ESX采用了<strong>流量整形</strong>的方式限制每个虚拟机的总带外流量；对于存储ESX实现了<strong>比例公平的算法</strong>平衡多个虚拟机之间磁盘访问带宽。</p><p><strong>2）半虚拟化—泛虚拟化模型**</strong>，即属于前后端驱动模型的IO虚拟化，也称为分离驱动模型。**</p><p>泛虚拟化模型是被广泛使用的另一种I/O设备虚拟化模型。相比于全虚模型而言，泛虚拟化模型在性能上有很大的提升。主要有以下两个原因：<strong>一是该模型采用了I/O环机制（一种大块多队列聚合传输技术，支持I/O环适配功能的虚拟机操作系统，只有安装了Tools才能使用到IO环适配功能），减少了虚拟机与VMM之间的切换；二是该模型摒弃了传统的中断机制，而采用事件或回调机制来实现设备与客户机间的通信</strong>。进行中断处理时，传统的中断服务程序需要进行中断确认和上下文切换，而采用事件或回调机制，无需进行上下文切换。如下图所示是一个基于泛虚拟化的Xen的I/O虚拟化模型。</p><p><img src="https://i.loli.net/2019/05/25/5ce945be9222f40793.jpg"></p><p>前端/后端架构也称为“Split I/O”，即将传统的I/O驱动模型分为两个部分，一部分是位于客户机OS内部的设备驱动程序（前端），该驱动程序不会直接访问设备，所有的I/O设备请求会转发给位于一个特权虚机的驱动程序（后端），后端驱动可以直接调用物理I/O设备驱动访问硬件。前端驱动负责接收来自其他模块的I/O操作请求，并通过虚拟机之间的事件通道机制将I/O请求转发给后端驱动。后端在处理完请求后会异步地通知前端。相比于全虚模型中VMM需要截获每个I/O请求并多次上下文切换的式，这种基于请求/事务的方式能够在很大程度上减少上下文切换的频率，并降低开销。 但是这种I/O模型有一个<strong>很大的缺点，要修改操作系统内核以及驱动程序，因此会存在移植性和适用性方面的问题，导致其使用受限。**</strong>下面以Xen架构的模型为例说明：**</p><p><img src="https://i.loli.net/2019/05/25/5ce945e74afc210781.jpg"></p><p>在Xen架构的半虚拟化模型中，通过修改Guest OS的内核，将原生的设备驱动从Guest OS移出，放到一个特殊的设备虚拟机中Dom0了，其余虚拟机中的I/O请求都由设备虚拟机处理。而在Guest OS内部，为每个虚拟设备安装一个特殊的驱动程序，由该驱动程序负责I/O请求的传递，设备虚拟机经过VMM授权，解析收到的请求并映射到实际物理设备，最后交给设备的原生驱动来完成IO。实际上在这种情况下，<strong>Guest OS的驱动是消息代理的作用，把I/O事件转换为消息，发送给设备虚拟机处理。具体前后端驱动配合实现物理设备驱动功能，需要通过以下几步实现：</strong></p><p><strong>Step1：如何实现设备发现？</strong></p><p>a）所有VM的设备信息保存在Domain0的XenStore中。</p><p>b）VM中的XenBus (为Xen开发的半虚拟化驱动)通过与Domain0的XenStore通信，获取设备信息。</p><p>c）加载设备对应的前端驱动程序。</p><p><strong>Step2：如何实现设备数据截获？</strong></p><p>a）前端设备驱动将数据通过VMM提供的接口全部转发到后端驱动。</p><p>b）后端驱动VM的数据进行分时分通道进行处理。</p><p><strong>Step3：如何模拟使用IO设备</strong></p><p>Domain U中虚拟机程序使用IO设备时，通过前端驱动Front-End Driver由XenBus总线访问Domain 0中的Back-End Driver，Back-End Driver通过XenStor中记录的IO设备信息，找到真实的设备驱动Native Driver去访问真实IO设备。</p><p><strong>需要注意一点：这种前后端驱动架构的瓶颈就是Domain 0，因为Domain 0通过XenBus总线采用时分复用的策略与前端多个DomainU联动。</strong></p><h2 id="硬件I-O虚拟化技术"><a href="#硬件I-O虚拟化技术" class="headerlink" title="硬件I/O虚拟化技术"></a>硬件I/O虚拟化技术</h2><p>为了改善I/O性能，旨在简化I/O访问路径的设备直通访问方式又被提了出来。代表技术为Intel公司出 的VT-d与AMD公司的IOMMU技术。尽管这两种技术在一定程度上提高了I/O访问性能，但代价却是限制了系统的可扩展性。目前PCI-SIG提出的SR-IOV与MR-IOV是平衡I/O虚拟化通用性、访问性能与系统可扩展性的很好的解决方案。</p><p><strong>IO透传—设备直接分配模型**</strong>，即直接分配给虚拟机物理设备**</p><p>软件实现I/O虚拟化的技术中，所有的虚拟机都共享物理平台上的硬件设备。如果物理条件好，有足够的硬件，就可以考虑让每个虚拟机独占一个物理设备，这样无疑会提高系统的性能。把某一个设备直接分配给一个虚拟机，让虚拟机可以直接访问该物理设备而不需要通过VMM或被VMM截获，这就是设备直通技术。如下图所示为设备直接分配的I/O模型。</p><p><img src="https://i.loli.net/2019/05/25/5ce9461d9625e48412.jpg"></p><p>在设备直接分配模型中，虚拟机操作系统可直接拥有某一物理设备的访问控制权限，VMM不再干涉其访问操作。因此，该模型可以较大地改善虚拟化设备的性能，降低VMM程序的复杂性，易于实现，并且不需要修改操作系统，保证了高可用性。</p><p>设备直接分配模型虽然在性能上相比软件方式的两种I/O设备虚拟化模型有着很大的提升，但是该模型的使用也是有一定限制的。因为该模型将一件物理设备直接分配给了一个虚拟机，其它虚拟机是无法使用该设备的，所产生的一个问题就是如果其它虚拟机需要访问该设备则无法满足需求，解决办法就是物理资源充分满足需求或者通过硬件虚拟化技术虚拟出多个IO设备（与物理设备性能极为接近）供多个虚拟机使用（硬件必须支持）。</p><h3 id="Intel的设备硬件虚拟化技术—VT-d"><a href="#Intel的设备硬件虚拟化技术—VT-d" class="headerlink" title="Intel的设备硬件虚拟化技术—VT-d"></a>Intel的设备硬件虚拟化技术—VT-d</h3><p><strong>VT-d，即VT for Direct I/O，主要在芯片组中实现，允许虚拟机直接访问I/O设备，以减少VMM和CPU的负担</strong>，如下图画红框部分。</p><p><img src="https://i.loli.net/2019/05/25/5ce94660648d578256.jpg"></p><p>Intel公司提出的VT系列技术中VT-d其目的就是让虚拟机直接访问物理机底层I/O设备，使虚拟机能够使用自己的驱动直接操作I/O设备，而无需VMM的介入和干涉。通过引入DMA重映射，VT-d不仅可以使虚拟机直接访问设备，同时还提供了一种安全隔离机制，防止其他虚拟机或者VMM访问分配给指定虚拟机的物理内存。VT-d中DMA重映射原理如下图所示：（在北桥也就是现在CPU封装中实现）</p><p><img src="https://i.loli.net/2019/05/25/5ce94688b93c449969.jpg"></p><p>具体来说，<strong>VT-d技术在北桥引入了DMA重映射技术，并通过两种数据结构（Root Entry 和 Context Entry）维护了设备的I/O页表。设备上的DMA操作都会被DMA重映射硬件截获，并根据对应的I/O页表对DMA中的地址进行转换，同时也会对要访问的地址空间进行控制。</strong></p><p>在具体实现上，VT-d使用PCI总线中的设备描述符BDF（Bus Device Function）来标示DMA操作发起者的标示符。其次，VT-d使用两种数据结构来描述PCI总线结构，分别是<strong>根条目（Root Entry）</strong>和<strong>上下文条目（Context Entry）</strong>。如下图所示，其中根条目用于描述PCI总线。由于PCI总线个数可以达到256个，因此根条目的范围是0~255，其中每个根条目的一个指针字段都指向该总线的所有PCI设备的上下文条目表指针（Context Table Pointer，CTP）。由于一个PCI总线可以包含256个设备，因此上下文条目表的范围也是0~255 。在每个上下文条目中都包含两个重要字段：<strong>地址空间根（Address Space Root，ASR） 指向该设备的I/O页表；域标示符（Domain ID，DID）可以理解为唯一标示一个虚拟机的标示符。</strong></p><p><img src="https://i.loli.net/2019/05/25/5ce946aaf04ca75158.jpg"></p><p>基于这种方式，当某一个设备发起DMA操作及被DMA重映射硬件截获时，通过该设备的BDF中的Bus字段，可以找到其所在的根条目。根据device和function字段，可以索引到具体设备的上下文条目。这样就可根据上下文条目中的ASR字段找到该设备的I/O页表，再通过DMA重映射硬件将I/O请求的GPA转换为HPA，从而达到设备直接访问虚拟机内存的目的。</p><p>使用VT-d将设备直接分配给虚拟机的I/O访问性能十分接近无虚拟化环境下的I/O访问性能，然而VT-d事实上是一种I/O设备被虚拟机独占的方式，这种方式牺牲了虚拟化平台中的设备共享能力，设备用率大大降低，而且系统的可扩展性受到物理平台插槽个数的限制。比如，假定一个服务器配置4个CPU，每个CPU为8核，按照平均分配方式每个虚拟机一个核，则可以创建32个虚拟机，如果按照备 直接访问的方式分配网卡，则需要32个物理插槽，这是不现实的。</p><p><img src="https://i.loli.net/2019/05/25/5ce946d37b7ec39760.jpg"></p><p>VT-d还为DMA重映射提供了安全隔离的保障。上图是没有VT-d技术与有VT-d技术的虚拟化平台的对比。可以看出，图（a）部分没有VT-d虚拟化技术的平台中，物理设备的DMA操作可以访问整个系统内存。而图（b）有VT-d技术的平台中，对设备DMA操作的地址范围进行了限制，只能访问指定的地址空间。</p><p>除了DMA重映射外，VT-d还提供了中断重映射功能，有兴趣的可以参考Intel官网的VT技术手册。</p><h3 id="VMDq和VMDc技术"><a href="#VMDq和VMDc技术" class="headerlink" title="VMDq和VMDc技术"></a>VMDq和VMDc技术</h3><p>在集群和数据中心这类环境中，每台主机通常同时运行大量的虚拟机。由于主机的网络设备数目有限，多个虚拟机不得不复用同一个网络设备，从而导致性能下降。Intel VT-c 技术可针对虚拟化进一步优化网络性能。VT-c 包括如下两个关键技术：</p><p><strong>1）虚拟机设备队列（Virtual Machine Device Queues，VMDq）</strong>。收到一个数据包时，VMM必须将其分类以确定应该转发给哪个虚拟机，这占用了大量宝贵的处理器资源。如果以太网控制器支持 VMDq 技术，VMM可以为虚拟机使用不同的数据包队列，以太网控制器自动分类数据包并投放到相应的队列中，大大减轻VMM的负担，提高了I/O吞吐量，如下图所示。</p><p><img src="https://i.loli.net/2019/05/25/5ce9470a3591081240.jpg"></p><p>而Intel所使用的VMDq就是通过网卡芯片內建的 Layer 2 classifier / sorter 以加速网络数据传送,它可以先行將不同的虚拟机所需的网络数据包，直接在芯片里规划好，然后再通过 receive queue直送给虚拟机。这样就不用送过虚拟交换机转发数据包减少网络的负载与CPU的开销，有VMDq和没VMDq的对比如下：</p><p><img src="https://i.loli.net/2019/05/25/5ce9472e1ce2730190.jpg"></p><p><strong>2）虚拟机直接连接（Virtual Machine Direct Connect，VMDc）</strong>。这是Intel借鉴了SR-IOV技术的特点。与SR-IOV技术一样，支持该技术的网络设备能够对外展现出多个虚拟功能接口VF（Virtual Function）。每个功能接口相当于一个网络设备，VMM可将其直接分配给某个虚拟机，从而“避免”了网络设备的复用。例如，VMM仅用单个英特尔万兆位服务器网卡，可为10个客户机操作系统分配独立受保护的1Gb/秒的专用链路，VMM无需继续管理这些直接通信链路，进一步提升I/O性能并减少主机CPU的负载 。</p><h3 id="SR-IOV与MR-IOV：PCIe的虚拟化"><a href="#SR-IOV与MR-IOV：PCIe的虚拟化" class="headerlink" title="SR-IOV与MR-IOV：PCIe的虚拟化"></a>SR-IOV与MR-IOV：PCIe的虚拟化</h3><p>如前所述，软件设备模拟尽管实现了物理与逻辑的分离，但是性能受到影响；VT-d或者IOMMU技术则以牺牲系统扩展性为代价获得近似于直接访问设备的I/O性能，而且其中任何一种都不是基于现有的工业标准。因此，业界希望重新设计一种可以原生共享的设备。具有原生共享特性的设备可同时为多个虚拟机提供单独的内存空间、工作队列、中断与命令处理，使得设备的资源能够在多个虚拟机之间共享。同时，这些设备能够从多个源端同时接收命令，并将其合并再一起发送出去。因此，原生共享设备不需要VMM模拟设备，同时也在硬件层次上使得多个虚拟机同时访问设备，很好地兼顾了虚拟化系统的性能与可扩展性。</p><p>PCI-SIG组织提出了一个新的技术规范：SR-IOV（Single Root I/O Virtualization）。该规范定义了一个单根设备（如 一个以太网卡端口）如何呈现为多个虚拟设备。在SR-IOV中，定义了两个功能类型：一是物理功能类型PF，负责管理SR-IOV设备的特殊驱动，其主要功能是提供设备访问功能和全局共享资源配置的功能，虚拟机所有影响设备状态的操作均需通过通信机制向PF发出请求完成。二是虚拟功能类型VF是轻量级的PCIe功能，包含三个方面：向虚拟机操作系统提供的接口；数据的发送、接收功能；与PF进行通信，完成全局相关操作。由于VF的资源仅是设备资源的子集，因此VF驱动能够访问的资源有限，对其它资源的访问必须通过PF完成。</p><p><img src="https://i.loli.net/2019/05/25/5ce9476ca691932811.jpg"></p><p>上图是一个支持SR-IOV的网卡配置。其中左侧三个VM是通过VF可以直接分配到的网卡资源，而该网卡的PF所具有的完整资源仍能用于最右侧两个虚拟机对模拟设备的访问路径。一个具备SR-IOV特性的设备通过VMM配置可以在PCI配置空间中呈现为多个VF，每个VF都配置了基地址寄存器（Base Address Register，BAR）的完整配置空间。VMM通过将一个或多个VF的配置空间映射到虚拟机的PCI配置空间中实现VF的分配。结合VT-d内存映射等技术，虚拟机可以直接访问VF的内存空间，这就 能绕过VMM直接访问I/ O设备。如下图所示：</p><p><img src="https://i.loli.net/2019/05/25/5ce94791d8d3870020.jpg"></p><p>SR-IOV还实现了地址转换服务（Address Translation Service，ATS）来提供更好的性能。通过缓存TLB到本地，I/O设备可以在发起PCI事务之前直接对DMA地址进行转换，这样就避免了在IOMMU中进行地址转换时可能发生的缺页情况。通过这种方式，绑 定到VF的虚拟机可 获得与基于硬件I/O虚拟 化虚拟机接近的性能。但是与基于硬件I/O虚拟化较低的可扩展性相比，一个SR-IOV设备可以具有几百个VF，因此SR-IOV具有更好的可扩展性。</p><p>MR-IOV（Multiple Root I/O Virtualization）扩展了SR-IOV规范。MR-IOV允许PCIe设备在多个有独立PCI根的系统之间共享，这些系统通过基于PCIe转换器的拓扑结构与PCIe设备或者PCIe-PCI桥相接。MR-IOV与SR-IOV相比，每个VH（Virtual Hierarchy，一个VH就是一个虚拟独立的SR-IOV设备）拥有独立的PCI Memory，IO，配置空间。如下图是MR-IOV的作用，本来每个系统只有一个Host，两个PCIe设备，但是有了MRA Switch之后，系统里面有2个Host，4个PCIe设备。</p><p><img src="https://i.loli.net/2019/05/25/5ce947c6b699689726.jpg"></p><p>MR-IOV里有个重要概念：VH，Virtual Hirearchy：每个VH至少包含一个PCIe Switch，这个PCIe Switch是MRA Switch里面的一个虚拟组件。每个VH可以包含各种PCIe设备、MRA PCIe设备、或者PCIe-PCI桥的组合。如下图，在MRA PCIe Switch中，可以有多个根端口Root Port，RP。</p><p><img src="https://i.loli.net/2019/05/25/5ce947e96ec5549655.jpg"></p><p>这样，有了MR-IOV之后，软件系统变成了下面这种，物理机之间也能相互通信，PCIe设备被多台物理机共享。下图中的SI就是虚拟机OS、VI就是虚拟机监视器VMM。</p><p><img src="https://i.loli.net/2019/05/25/5ce9480e95a7c64528.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;IO虚拟化概述&quot;&gt;&lt;a href=&quot;#IO虚拟化概述&quot; class=&quot;headerlink&quot; title=&quot;IO虚拟化概述&quot;&gt;&lt;/a&gt;IO虚拟化概述&lt;/h2&gt;&lt;p&gt;现实中的外设资源是有限的，为了提高资源的利用率，满足多个虚拟机操作系统对外部设备的访问需求，VMM必须通过I/O虚拟化的方式来实现资源的复用，让有限的资源能被多个虚拟机共享。如何将服务器上的物理设备虚拟化为多个逻辑设备，并将物理设备与逻辑设备解耦，使虚拟机可以在各个虚拟化平台间无缝迁移，正是I/O虚拟化的目标。I/O虚拟化的基本要求主要有以下的三点：
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-18-计算虚拟化之内存虚拟化</title>
    <link href="https://kkutysllb.cn/2019/05/18/2019-05-18-%E8%AE%A1%E7%AE%97%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B9%8B%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <id>https://kkutysllb.cn/2019/05/18/2019-05-18-计算虚拟化之内存虚拟化/</id>
    <published>2019-05-18T02:45:07.000Z</published>
    <updated>2019-05-18T02:54:36.837Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内存虚拟化概述"><a href="#内存虚拟化概述" class="headerlink" title="内存虚拟化概述"></a>内存虚拟化概述</h2><p><strong>所谓的内存虚拟化，即如何在多个虚拟机之间共享物理内存以及如何进行动态分配</strong>。在《x86架构基础》一文中已经介绍操作系统对物理服务器内存管理的知识，它的本质就是将物理内存地址映射到一段线性地址空间，也有叫逻辑地址空间，应用程序访问内存物理地址是通过段页查询机制完成。而这个线性地址空间或逻辑地址空间本身就是物理内存的虚拟化呈现。在虚拟化环境中，分配给虚拟机内存非常类似于操作系统中关于线性地址空间的实现。操作系统负责维护虚页号到实页号的映射，并将这一 映射信息保存到页表（Page Table）。在 x86架构的CPU中，内存管理单元MMU与TLB这两个模块就负责实现并优化虚拟内存的性能。详见《DPDK技术在电信云中最佳实践》系列文章。<a id="more"></a></p><p>一个操作系统对其物理内存存在两个主要的基本认识：<strong>物理地址从0开始</strong>和<strong>内存地址连续性</strong>（至少在一些大的粒度上连续）。</p><p><img src="https://i.loli.net/2019/05/18/5cdf720f6123725981.jpg"></p><p>如上图所示，而VMM与客户机操作系统在对物理内存的认识上存在冲突，这使得真正拥有物理内存的VMM必须对客户机操作系统所访问的内存进行一定程度的虚拟化。换句话说，就是VMM 负责将MMU进行虚拟化，为客户机操作系统提供一段连续的“物理”地址空间，而操作系统本身不会意识到这种变化，仍能够将虚拟机虚拟地址（Guest Virtual Address，GVA）映射到虚拟机物理地址（Guest Physical Address，GPA），但是需要VMM将虚拟机物理地址映射到物理机物理地址（Host Physical Address，HPA）。</p><p>所以，<strong>内存虚拟化的本质就是把物理机的真实物理内存统一管理，包装成多份虚拟的内存给若干虚拟机使用</strong>。内存虚拟化的核心，在于引入一层新的地址空间—<strong>客户机物理地址空间</strong>，客户机以为自己运行在真实的物理地址空间中，实际上它是通过VMM访问真实的物理地址的。在VMM中保存客户机地址空间和物理机地址空间之间的映射表。</p><p><strong>如下图所示：虚拟化系统中包括三层内存地址空间：虚拟机虚拟地址GVA、虚拟机物理地址GPA和物理机物理地址HPA。因此，原先由MMU完成的线性地址到物理地址的映射已经不能满足，必须由VMM接入来完成这三层地址的映射维护和转换。</strong></p><p><img src="https://i.loli.net/2019/05/18/5cdf7229c2feb27866.jpg"></p><ul><li><strong>GVA：</strong>指GuestOS提供给其应用程序使用的线性地址空间。</li><li><strong>GPA：</strong>经VMM抽象的，虚拟机看到的伪物理地址空间。</li><li><strong>HPA：</strong>真实的机器地址，即地址总线上出现的地址信号。</li></ul><p>为了实现上述映射和转换关系，主要有两种解决方案：<strong>软件解决方案—影子页表和硬件解决方案—Intel的EPT和AMD的RVI。</strong></p><h2 id="内存虚拟化软件解决方案"><a href="#内存虚拟化软件解决方案" class="headerlink" title="内存虚拟化软件解决方案"></a>内存虚拟化软件解决方案</h2><h3 id="MMU半虚拟化（MMU-Paravirtualization）这种方式主要为Xen所用"><a href="#MMU半虚拟化（MMU-Paravirtualization）这种方式主要为Xen所用" class="headerlink" title="MMU半虚拟化（MMU Paravirtualization）这种方式主要为Xen所用"></a>MMU半虚拟化（MMU Paravirtualization）这种方式主要为Xen所用</h3><p><strong>MMU半虚拟化主要原理是：</strong></p><p>1）当Guest OS创建新页表时，VMM从维护的空闲内存中为其分配页面并进行注册。后续，Guest OS对该页表的写操作都会陷入VMM进行验证和转换；VMM检查页表中的每一项，确保它们只映射到属于该虚拟机的机器页面，而且不包含对页表页面的可写映射。</p><p>2）然后，VMM会根据其维护的映射关系PA-MA，将页表项中的虚拟机逻辑地址VA替换为相应的机器地址MA。</p><p>3）最后把修改过的页表载入MMU，MMU就可以根据修改过的页表直接完成虚拟地址VA到机器地址MA的转换。</p><p><strong>这种方式的本质是将映射关系VA-MA直接写入Guest OS的页表中，以替换原来的映射VA-PA映射关系。</strong></p><h3 id="影子页表"><a href="#影子页表" class="headerlink" title="影子页表"></a>影子页表</h3><p>相比较MMU半虚，大部分虚拟化厂商在VMM中还使用了一种称为<strong>影子页表（Shadow Page Table）</strong>的技术实现上述功能。对于每个虚拟机的主页表（Primary Page Table），VMM都维持一个影子页表来记录和维护GVA与HPA的映射关系。 影子页表包括以下两种映射关系，如下图所示：</p><p><img src="https://i.loli.net/2019/05/18/5cdf728ab26fc27225.jpg"></p><p><strong>1）GVA&gt;&gt;&gt;GPA，</strong>虚拟机操作系统负责维护从虚拟机逻辑地址到虚拟机物理地址的映射关系，VMM可以从虚拟机主页表中获取这种映射关系。</p><p><strong>2）GPA&gt;&gt;&gt;HPA，</strong>VMM负责维护从虚拟机物理地址到物理机物理地址的映射关系。</p><p>通过这种两级映射的方式，VMM为Guest OS的每个页表维护一个影子页表，并将GVA-HPA的映射关系写入影子页表，Guest OS的页表内容保持不变，然后，VMM将影子页表写入MMU。同时，又对虚拟机可访问的内存边界进行了有效控制。并且，使用TLB缓存影子页表的内容可以大大提高虚拟机问内存的速度。</p><p>影子页表的维护将带来<strong>时间</strong>和<strong>空间</strong>上的较大开销。<strong>时间开销</strong>主要体现在Guest OS构造页表时不会主动通知VMM，VMM必须等到Guest OS发生缺页错误时（必须Guest OS要更新主页表），才会分析缺页原因再为其补全影子页表。而<strong>空间开销</strong>主要体现在VMM需要支持多台虚拟机同时运行，每台虚拟机的 Guest OS通常会为其上运行的每个进程创建一套页表系统，因此影子页表的空间开销会随着进程数量的增多而迅速增大。</p><p>为权衡时间开销和空间开销，现在一般采用<strong>影子页表缓存</strong>（Shadow Page Table Cache）技术，即VMM在内存中维护部分最近使用过的影子页表，只有当影子页表在缓存中找不到时，才构建一个新的影子页表。<strong>当前主要的虚拟化技术都采用了影子页表缓存技术</strong>。</p><h3 id="内存虚拟化的硬件解决方案"><a href="#内存虚拟化的硬件解决方案" class="headerlink" title="内存虚拟化的硬件解决方案"></a>内存虚拟化的硬件解决方案</h3><p>为了解决影子页表导致的上述开销问题，除了使用影子页表缓存技术外（这项技术虽然能避免时间上的一部分开销，但是空间开销还是实实在在存在的）， Intel与AMD公司都针对MMU虚拟化给出了自 的解决方案：Intel公司在Nehalem微架构CPU中推出<strong>扩展页表（Extended Page Table，EPT）</strong>技术；AMD公司在四核皓龙CPU中推出<strong>快速虚拟化索引（Rapid Virtualization Index，RVI）</strong>技术。</p><p>RVI与EPT尽管在具体实现细节上有所不同，但是在设计理念上却完全一致：<strong>通过在物理MMU中保存两个不同的页表，使得内存地址的两次映射都在硬件中完成，进而达到提高性能的目的。</strong>具体来说，MMU中管理管理了两个页表，第一个是GVA &gt;&gt;&gt;GPA，由虚拟机决定；第二个是GPA&gt;&gt;&gt;HPA，对虚拟机透明，由VMM决定。根据这两个映射页表，CPU中的page walker就可以生成最近访问过key-value键值对&lt;GVA，HPA&gt; ，并缓存在TLB中（类似影子页表缓存技术思路）。</p><p>另外，原来在影子页表中由VMM维持的GPA&gt;&gt;&gt;HPA映射关系，则由一组新的数据结构扩展页表（Extended Page Table，也称为Nested Page Table）来保存。由于GPA &gt;&gt;&gt;HPA的映射关系非常定，并在虚拟机创建或修改页表时无需更新，因此VMM在虚拟机更新页表的时候无需进行干涉。VMM也无需参与到虚拟机上下文切换，虚拟机可以自己修改GVA &gt;&gt;&gt;GPA的页表。</p><p>我们以Intel EPT技术为例说明。Intel EPT是Intel VT-x 提供的内存虚拟化支持技术，其基本原理下图所示。在原有的CR3页表地址映射的基础上，EPT引入EPT页表来实现另一次映射。比如：假设客户机页表和EPT页表都是4级页表，CPU完成一次地址转换的基本过程如下：</p><p><img src="https://i.loli.net/2019/05/18/5cdf72c9c659e24729.jpg"></p><p>CPU首先查找客户机CR3寄存器指向的L4页表。客户机CR3寄存器给出的是GPA，所以，CPU通过EPT页表将客户机CR3中的GPA转换为HPA：CPU 首先查找EPT TLB，如果没有相应的记录，就进一步查找EPT页表，如果还没有，CPU则抛出EPT Violation异常交给VMM处理。</p><p>CPU获得L4页表地址（指的是HPA）后，CPU根据GVA和L4页表项的内容来获取L3 页表项的GPA。如果L4页表中GVA对应的表项显示为“缺页”，那么CPU 产生Page Fault，直接交由客户机操作系统处理。获得L3 页表项的GPA后，CPU通过查询EPT页表来将L3的GPA转换为HPA。同理，CPU 会依次完成L2、L1页表的查询，获得GVA所对应的GPA，然后进行最后一次查询EPT页表获得HPA。</p><p>正如上图所示，CPU需要5次查询EPT页表，每次查询都需要4次内存访问。这样，在最坏的情况下总共需要20次内存访问。<strong>EPT硬件通过增大EPT TLB 尽量减少内存访问。</strong></p><h2 id="内存虚拟化管理"><a href="#内存虚拟化管理" class="headerlink" title="内存虚拟化管理"></a>内存虚拟化管理</h2><p>在虚拟化环境中，内存是保证虚拟机工作性能的关键因素。如何尽可能提高虚拟机的性能、提高内存利用率、降低虚拟机上下文切换的内存开销，依然非常复杂，这就引入了<strong>内存虚拟化管理的问题</strong>。像介绍CPU虚拟化管理一样，我们还是通过实例来说明内存的虚拟化管理。以VMware的ESX解决方案为例，在没有出现硬件支持的内存虚拟化技术之前，ESX/ESXi采用影子页表来实现虚拟机的虚拟地址到物理机物理地址的快速转换。当Intel和AMD公司分别推出了EPT与RIV技术之后，ESX/ESXi很快转向硬件支持来提高内存虚拟化的性能。</p><p>在虚拟化内存管理 上，ESX/ESXi实现了主机内存超分配的目标：即<strong>多个虚拟机总的内存分配量大于物理机的实际内存容量</strong>。如下图所示，一个物理内存只有4GB的Host，可以同时运行三个内存配置为2GB的虚拟机。</p><p><img src="https://i.loli.net/2019/05/18/5cdf72f7358ee63929.jpg"></p><p>主机内存超分配功能意味着VMM必须能够有效地回收虚拟机中不断释放的内存，并在有限的内存容量中尽能 地提高内存利用率。因为，Host Memory与Guest Memory并不是一一对应的关系，通过Host Memory超配技术可以实现某一个Host上某一个虚拟机内存大于主机内存，这一点与CPU虚拟化不一样。但是，在执行超配技术时，需要考虑主机性能问题，不能过大。一般的超配限额是主机内存的50%。要实现主机内存超配，必须通过<strong>内存复用</strong>技术实现。目前常用的内存复用技术有：<strong>零页共享技术、内存气球回收技术</strong>和<strong>内存置换技术</strong>三种。</p><h3 id="零页（透明页）共享技术"><a href="#零页（透明页）共享技术" class="headerlink" title="零页（透明页）共享技术"></a>零页（透明页）共享技术</h3><p>当运行多个虚拟机时，有些内存页面的内容很可能是完全一样的，比如：什么数据都没有的零页。这就为虚拟机之间甚至在虚拟机内部提供了共享内存的可能。例如：当几个虚拟机都运行相同的操作系统、相同的应用程序或者包含相同的用户数据时，那些包含相同数据的内存页面完可以被共享。基于这个原理，VMM完全可通过回收冗余数据的内存页面，仅维持一个被多个虚拟机共享的内存拷贝来实现这个功能。</p><p><strong>如下图所示，是华为FusionCompute的零页共享技术示意图：</strong></p><p><img src="https://i.loli.net/2019/05/18/5cdf732c5c23754430.jpg"></p><p><strong>其基本原理是</strong>：用户进程定时扫描虚拟机的的内存数据，如果发现其数据内容全为零，则通过修改PA to MA映射的形式，把其指向一个特定的零页，从而做到在物理内存中只保留一份零页拷贝，虚拟机的所有零页均指向该页，从而达到节省内存资源的目的。当零页数据发生变动时，由Xen动态分配一页内存出来给虚拟机，使修改后的数据有内存页进行存放。因此，对GuestOS来说，整个零页共享技术是完全不感知的。</p><p>而在VMware的ESX解决方案中，也有同样的技术。在VMware ESX/ESXi中，检测页面数据是否冗余是通过<strong>散列</strong>的方法来实现的，如下图所示。</p><p><img src="https://i.loli.net/2019/05/18/5cdf734451c6887409.jpg"></p><p>首先VMM会维持一个全局散列表，其中<strong>每个表项都记录了一个物理页面数据的散列值与页号</strong>。当对某一个虚拟机进行页面共享扫描时，VMM会针对该虚拟机物理页面的数据计算散列值，并在全局散列表 中进行遍历及匹配是否有相同的散列值的表项。<strong>当找到了匹配的表项，还要对页面数据内容逐位比较，以避免由于散列冲突而导致的页面内容不一样的可能性。</strong>一旦确定页面数据完全一致，则会修改逻辑地址到物理地址的映射关系，即<strong>将从逻辑地址对应到包含冗余数据的物理地址的映射关系（上图中虚线所示）改为对应到要被共享物理地址的映射关系，并回收冗余的物理页面</strong>。这一过程对于虚拟机操作系统是完全透明的。因此，<strong>共享页面中含有敏感数据的部分不会在虚拟机之间泄露</strong>。</p><p>当虚拟机对共享页面发生写操作时，通过“写时拷贝”（ Copy-on-Write）技术来实现。 如下图所示：</p><p><img src="https://i.loli.net/2019/05/18/5cdf735c64aa688044.jpg"></p><p>具体来说，任何一个对共享页面的写操作都会引发页面错误（Minor Page Fault）。当VMM捕获到这个错误时，会给发起写操作的虚拟机创建一个该页面的私有拷贝，并将被写的逻辑地址映射到这个私有拷贝页面。这样虚拟机就可以安全地进行写操作，并且不会影响到其他共享该页面的虚拟机。相比于对非共享页面的写操作，尽管这种处理方法的确导致了一些额外的开销，但是却在一定程度上提高了内存页面的利用率。</p><h3 id="内存气球回收技术"><a href="#内存气球回收技术" class="headerlink" title="内存气球回收技术"></a>内存气球回收技术</h3><p><strong>内存气球回收技术也称为内存气泡技术，</strong>基于气球回收法的内存管理机制与页面共享完全不同。在虚拟化环境中，VMM会一次性在虚拟机启动后分配给虚拟机内存，由于虚拟机并没有意识到自己运行于 虚拟化平台上，之后它会一直运行在分配好的内存空间，而不主动释放分配的物理内存给其他虚拟机。因此VMM需要一种机制使得虚拟机能够主动释放空闲内存归还给物理机，再由VMM分配给其他有需求的虚拟机。并且，在内存资源需求紧张时还能从物理机中“拿回”自己释放的那部分内存。 </p><p><strong>如下所示，是华为FusionCompute内存气泡技术示意图：</strong></p><p><img src="https://i.loli.net/2019/05/18/5cdf73824ce0891613.jpg"></p><p><strong>原理如下：</strong>Hypervisor通过利用预装在用户虚拟机中的前端驱动程序，“偷取”Guest OS的内存贡献给VMM，以供其他虚拟机使用，反向时由VMM“偷取”气泡中的内存给特定虚拟机使用。内存气泡本质是将较为空闲的虚拟机内存释放给内存使用率较高的虚拟机，从而提升内存利用率。</p><p>在VMware的ESX解决方案中，也有类似的技术。下图给出了内存释放过程的原理图。</p><p><img src="https://i.loli.net/2019/05/18/5cdf7398dc3fa66352.jpg"></p><p>在上图（a）中，VMM有四个页面被映射到虚拟机的内存页面空间中，其中左侧两个页面被应用程序占用，而另两个被打上星号的页面则是在内存空闲列表中。当VMM要从虚拟机中回收内存时，比如要回收两个内存页面，VMM就会将Balloon驱动的目标膨胀大小设置为两个页面。Balloon驱动获得了目标膨胀值之后，就会在虚拟机内部申请两个页面空间的内存，并如上图（b）所示，调用虚拟机操系统的接口标示这两个页面被“ <strong>钉住</strong>”，即不能再被分配出去。</p><p>内存申请完毕后，Balloon驱动会通知VMM这两个页面的页号，这样VMM就可以找到相应的物理页号并进行回收。在上（b）中虚线就标示了这两个页面从虚拟机分配出去的状态。</p><p>由于被释放的页面在释放前已经在虚拟机的空闲列表中，因此没有进程会对该页面进行读写操作。如果虚拟机的进程接下来要重新访问这些页面，那么VMM可以像平常分配内存一样，再分配新的物理内存给这台虚拟机。当VMM决定收缩气球膨胀大小时，通过设置更小的目标膨胀值，balloon驱动会将已经被“<strong>钉住</strong>” 的页面归还给虚拟机。</p><p>通过气球回收法，尽管虚拟机的负载略微增加，但VMM却成功地将系统内存压力转移到各个虚拟机上。当balloon驱动发起申请内存的请求时，由虚拟机操作系统决定了是否要将虚拟机物理内存换出来满足balloon驱动的申请内存请求。如果虚拟机有充足的空闲内存，那么balloon驱动申请内存并不会对虚拟机的性能造成影响；如果虚拟机内存已经吃紧，那么就需要由虚拟机的操作系统决定换出哪些内存页面，满足balloon驱动的请求。因此，<strong>气球回收法巧妙地利用了各个虚拟机操作系统的内存换页机制来确定哪些页面要被释放给物理机，而不是由VMM来决定</strong>。 </p><p><strong>气球回收法要求虚拟机操作系统必须安装balloon驱动</strong>，在VMware的ESX/ESXi产品中，就是VMware Tool。另外，气球回收法回收内存需要一段时间，不能马上满足系统的需求。</p><h3 id="内存置换技术"><a href="#内存置换技术" class="headerlink" title="内存置换技术"></a>内存置换技术</h3><p>页面共享机制与气球回收法都从不同的角度尽可能地提高虚拟机的内存利用率，从虚拟机中收回可以复用或者空闲的内存。然而这两种方法都不能在短时间内满足系统内存回收的要求：<strong>页面共享依赖于页面的扫描速度，以及是否有页面可共享；气球回收法则取决于虚拟机操作系统对于balloon驱动申请内存的响应时间</strong>。如果这两种温和的方法都不能满足需求，<strong>VMM则会采取内存换出机制，即强制性地从虚拟机中夺回内存，这就是内存置换技术。</strong></p><p><strong>如下所示，是华为FusionCompute和VMware ESX/ESXI的内存置换技术示意图。</strong></p><p><img src="https://i.loli.net/2019/05/18/5cdf73c2b12e968100.jpg"></p><p><strong>原理如下：</strong>通过VMM实现请页功能，这时Guest OS类似进程一样在VMM缺少内存时，能被换出到宿主机磁盘上，也就是将虚拟机长时间未访问的内存内容被置换到存储中，并建立映射，当虚拟机再次访问该内存内容时再置换回来。该方法也对虚拟机透明，即虚拟机不感知。</p><p>具体来说，VMM会在每个虚拟机启动时创建一个单独的换页文件（Swap File）。在必要的时候，VMM会主动将虚拟机的物理内存页面换到这个换页文件上，释放给其他虚拟机使用。内存换出机制是VMM需要在短时间内缓解内存压力的一种有效方法，然而这种方法却很可能严重导致VMM的性能下降。由于VMM对于虚拟机的内存使用状态并不解，且该方法对虚拟机透明，强制内存换出可能触发虚拟机操作系统内部的一些换页机制。举例来说，虚拟机操作系统永远都不会将内核的内存页面换出，而VMM并不知道哪些页正在被内核使用，一旦这些页面被换出，会使得虚拟机性能严重受损。</p><h3 id="内存的回收"><a href="#内存的回收" class="headerlink" title="内存的回收"></a>内存的回收</h3><p>接下来以VMware ESX为例，结合上述三种内存复用技术，介绍内存回收机制。一般来说，ESX会对物理机的空闲内存状态按照空闲内存的百分比设置四种状态，分别是：<strong>高（6%）、平缓（4%）、繁重（2%）和低（1%）</strong>。ESX会按照这四种状态来选择前述三种内存回收机制。</p><p>缺省状态下，ESX会启用页面共享机制，因为页面共享机制能以较小的开销提高内存利用率。何时启用气球回收和换页则取决于当前系统的内存状态。当内存状态处于“高”，很显然此时总的虚拟机内存使用量要小于物理机的内存容量，因此不管虚拟机的内存是否已经被过载分配，VMM都不会使用气球 或者换页的方法回收内存。</p><p>然而，当物理机空闲内存状态下降到了“平缓” 状态，VMM则开始使用气球回收法。事实上，气球回收法是在空闲内存的百分比高于“平缓” 的阈值4%之前启动的，这是因为该方法总是需要一段时间才能在虚拟机内申请到一些内存。通常气球回收法都能够及时将空闲内存比的阈值控制在“平缓”状态之上。</p><p>一旦气球回收法不能够及时回收内存，并且空闲内存下降到“繁重”状态，即空闲内存比低于2%，那么VMM就会再启动内存换出机制强制从虚拟机回收内存。使用这种办法，VMM能够很快回收内存，并将空闲内存比控制回“平缓”状态。</p><p>在最坏的情况下，万一空闲内存状态低于“低”状态，即空闲内存比低于1%，那么VMM会继续使用内存换出法，同时将那些消耗内存值超过内存配置值的虚拟机挂起。</p><p>在某些情况下，VMM可能不会考虑物理机空闲内存状态，而仍然启动物理机内存回收机制。比如，即使整个系统的物理机空闲内存状态为“高”，如果某个虚拟机的内存使用量超过了其指定的内存上限，那么VMM会启动气球回收法，如有必要，也会启动内存换出机制从虚拟机回收内存，直到该虚拟机的内存低于指定的内存上限。</p><h3 id="内存QoS保障"><a href="#内存QoS保障" class="headerlink" title="内存QoS保障"></a>内存QoS保障</h3><p>在虚拟化系统中，内存虚拟化的QoS保障包括两个基本特征：<strong>预留</strong>和<strong>份额</strong>。</p><p><strong>内存预留：</strong>虚拟机预留的最低内存。预留的内存会被VM独占。即，一旦内存被某个虚拟机预留，即使虚拟机实际内存使用量不超过预留量，其它VM也无法抢占该VM的内存空闲资源。即，上述的三种内存复用技术对该虚拟机不生效。</p><p><strong>内存份额：</strong>适用上述三种资源复用场景，按比例分配内存资源。以6G内存规格的主机为例，假设其上运行有3台4G内存规格的虚拟机VMA，VMB，VMC。内存份额分别为20480，20480，40960，那么其内存分配比例为1：1：2。当三台VM内部逐步加压，策略会根据三个虚拟机的份额按比例分配调整内存资源，最终三台虚拟机获得的内存量稳定为1.5G/1.5G/3G。</p><p><strong>同样需要注意一点：内存份额只在各虚拟机发生资源竞争时生效。如没有竞争，则有需求的虚拟机可独占物理内存。</strong></p><p><strong>但是，内存QoS不像CPU QoS一样设置上限？，这是因为分配给虚拟机的内存大小就是其内存上限。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;内存虚拟化概述&quot;&gt;&lt;a href=&quot;#内存虚拟化概述&quot; class=&quot;headerlink&quot; title=&quot;内存虚拟化概述&quot;&gt;&lt;/a&gt;内存虚拟化概述&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;所谓的内存虚拟化，即如何在多个虚拟机之间共享物理内存以及如何进行动态分配&lt;/strong&gt;。在《x86架构基础》一文中已经介绍操作系统对物理服务器内存管理的知识，它的本质就是将物理内存地址映射到一段线性地址空间，也有叫逻辑地址空间，应用程序访问内存物理地址是通过段页查询机制完成。而这个线性地址空间或逻辑地址空间本身就是物理内存的虚拟化呈现。在虚拟化环境中，分配给虚拟机内存非常类似于操作系统中关于线性地址空间的实现。操作系统负责维护虚页号到实页号的映射，并将这一 映射信息保存到页表（Page Table）。在 x86架构的CPU中，内存管理单元MMU与TLB这两个模块就负责实现并优化虚拟内存的性能。详见《DPDK技术在电信云中最佳实践》系列文章。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-15-Linux系统命令-第八篇《进程管理命令》</title>
    <link href="https://kkutysllb.cn/2019/05/15/2019-05-15-Linux%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4-%E7%AC%AC%E5%85%AB%E7%AF%87%E3%80%8A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E3%80%8B/"/>
    <id>https://kkutysllb.cn/2019/05/15/2019-05-15-Linux系统命令-第八篇《进程管理命令》/</id>
    <published>2019-05-15T15:30:32.000Z</published>
    <updated>2019-05-15T15:52:48.726Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ps：查看进程"><a href="#ps：查看进程" class="headerlink" title="ps：查看进程"></a>ps：查看进程</h2><p>ps命令用于列出执行ps命令的那个时刻的进程快照，就像用手机给进程照了一张照片。如果想要动态地显示进程的信息，就需要使用top命令，该命令类似于把手机切换成录像模式。因为ps命令能够支持多种系统（Linux\UNIX等），所以选项较多。但是学习时只需要掌握常用的参数即可。而且由于ps命令的功能实在是太多了，26个字母已经满足不了，因此，在ps命令的参数中有类似于-a与a这2种写法，这2种写法的功能是不一样的。<a id="more"></a></p><p><strong>语法格式：ps [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc30fef395980814.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）PS命令不接任何参数</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># ps</span></span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line"> 11097 pts/1    00:00:00 bash</span><br><span class="line"> 40755 pts/1    00:00:00 ps</span><br></pre></td></tr></table></figure><p><strong>默认情况下，ps命令不接任何参数，显示的使用者当前所在终端的进程。</strong></p><p><strong>2）常用命令组合</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-e选项显示unix格式所有进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -e</span></span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line">     1 ?        00:00:01 systemd</span><br><span class="line">     2 ?        00:00:00 kthreadd</span><br><span class="line">     3 ?        00:00:00 ksoftirqd/0</span><br><span class="line">     5 ?        00:00:00 kworker/0:0H</span><br><span class="line">     7 ?        00:00:00 migration/0</span><br><span class="line">     8 ?        00:00:00 rcu_bh</span><br><span class="line">     9 ?        00:00:02 rcu_sched</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时加上-f选项，额外显示UID、PPID、C和TIME栏</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># C栏表示进程占用CPU的百分比</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TTY栏显示？表示该进程与终端无关，否则显示相应的终端</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -ef   # 常用组合</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">root          1      0  0 17:12 ?        00:00:01 /usr/lib/systemd/systemd --system --deseriali</span><br><span class="line">root          2      0  0 17:12 ?        00:00:00 [kthreadd]</span><br><span class="line">root          3      2  0 17:12 ?        00:00:00 [ksoftirqd/0]</span><br><span class="line">root          5      2  0 17:12 ?        00:00:00 [kworker/0:0H]</span><br><span class="line">root          7      2  0 17:12 ?        00:00:00 [migration/0]</span><br><span class="line">root          8      2  0 17:12 ?        00:00:00 [rcu_bh]</span><br><span class="line">root          9      2  0 17:12 ?        00:00:02 [rcu_sched]</span><br><span class="line">root         10      2  0 17:12 ?        00:00:00 [lru-add-drain]</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找特定进程信息，常用ps -ef与grep结合使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示系统SSH进程的相关信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -ef|grep ssh</span></span><br><span class="line">root       1146      1  0 17:13 ?        00:00:00 /usr/sbin/sshd -D</span><br><span class="line">root      11093   1146  0 17:23 ?        00:00:02 sshd: root@pts/1</span><br><span class="line">root      40759  11097  0 22:42 pts/1    00:00:00 grep --color=auto ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用BSD格式显示每个进程信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所谓BSD格式就是选项前面不带“-”符号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># VSZ栏表示该进程使用掉的虚拟内存量（单位KB）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RSS栏表示该进程占用的固定内存量（单位KB）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># STAT栏表示该进程目前的状态，具体状态解释详见最后</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps aux</span></span><br><span class="line">USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root          1  0.0  0.0  46104  6396 ?        Ss   17:12   0:01 /usr/lib/systemd/systemd --sy</span><br><span class="line">root          2  0.0  0.0      0     0 ?        S    17:12   0:00 [kthreadd]</span><br><span class="line">root          3  0.0  0.0      0     0 ?        S    17:12   0:00 [ksoftirqd/0]</span><br><span class="line">root          5  0.0  0.0      0     0 ?        S&lt;   17:12   0:00 [kworker/0:0H]</span><br><span class="line">root          7  0.0  0.0      0     0 ?        S    17:12   0:00 [migration/0]</span><br><span class="line">root          8  0.0  0.0      0     0 ?        S    17:12   0:00 [rcu_bh]</span><br><span class="line">root          9  0.0  0.0      0     0 ?        S    17:12   0:02 [rcu_sched]</span><br><span class="line">root         10  0.0  0.0      0     0 ?        S&lt;   17:12   0:00 [lru-add-drain]</span><br><span class="line">root         11  0.0  0.0      0     0 ?        S    17:12   0:00 [watchdog/0]</span><br><span class="line">root         12  0.0  0.0      0     0 ?        S    17:12   0:00 [watchdog/1]</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><p><strong><em>STAT栏进程状态解释：</em></strong></p><ul><li>R：正在运行，或者是可以运行。</li><li>S：正在中断睡眠中，可以由某些信号量唤醒。</li><li>D：不可中断睡眠</li><li>T：正在侦测或停止了。</li><li>Z：已经终止，但是其父进程无法终止它，从而编程僵尸进程状态。</li><li>+：前台进程。</li><li>l：多线程进程</li><li>N：低优先级进程</li><li>&lt;：高优先级进程</li><li>s：进程领导者</li><li>L：已将页面锁定到内存中</li></ul><p><strong>3）显示指定用户相关的进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-u选项显示root'用户相关进程，注意-u和u的区别</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -u root</span></span><br><span class="line">PID TTY          TIME CMD</span><br><span class="line">1 ?        00:00:01 systemd</span><br><span class="line">2 ?        00:00:00 kthreadd</span><br><span class="line">3 ?        00:00:00 ksoftirqd/0</span><br><span class="line">5 ?        00:00:00 kworker/0:0H</span><br><span class="line">7 ?        00:00:00 migration/0</span><br><span class="line">8 ?        00:00:00 rcu_bh</span><br><span class="line">9 ?        00:00:02 rcu_sched</span><br><span class="line">10 ?        00:00:00 lru-add-drain</span><br></pre></td></tr></table></figure><p><strong>4）显示进程的详细信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># F：代表这个进程的标志（flag），4代表使用者为super user</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># S：代表这个进程的状态（STAT)，见前例说明</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PPID：父进程号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PID：本进程号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># NI：nice值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ADDR：表示进程在内存中的地址范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># WCHAN：表示这个进程是否在运行，若在运行，取值为“-”</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -l</span></span><br><span class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0  11097  11093  0  80   0 - 28859 do_wai pts/1    00:00:00 bash</span><br><span class="line">0 R     0  40780  11097  0  80   0 - 38300 -      pts/1    00:00:00 ps</span><br></pre></td></tr></table></figure><p><strong>5）显示进程树</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-H选项显示进程树，配合-e选项显示所有进程的进程树</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -eH</span></span><br><span class="line">PID TTY          TIME CMD</span><br><span class="line">2 ?        00:00:00 kthreadd</span><br><span class="line">3 ?        00:00:00   ksoftirqd/0</span><br><span class="line">5 ?        00:00:00   kworker/0:0H</span><br><span class="line">7 ?        00:00:00   migration/0</span><br><span class="line">8 ?        00:00:00   rcu_bh</span><br><span class="line">9 ?        00:00:02   rcu_sched</span><br><span class="line">10 ?        00:00:00   lru-add-drain</span><br><span class="line">11 ?        00:00:00   watchdog/0</span><br><span class="line">12 ?        00:00:00   watchdog/1</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 或者使用BSD格式axf组合选项也可达到同样效果</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps axf</span></span><br><span class="line">PID TTY      STAT   TIME COMMAND</span><br><span class="line">2 ?        S      0:00 [kthreadd]</span><br><span class="line">3 ?        S      0:00  \_ [ksoftirqd/0]</span><br><span class="line">5 ?        S&lt;     0:00  \_ [kworker/0:0H]</span><br><span class="line">7 ?        S      0:00  \_ [migration/0]</span><br><span class="line">8 ?        S      0:00  \_ [rcu_bh]</span><br><span class="line">9 ?        S      0:02  \_ [rcu_sched]</span><br><span class="line">10 ?        S&lt;     0:00  \_ [lru-add-drain]</span><br><span class="line">11 ?        S      0:00  \_ [watchdog/0]</span><br><span class="line">12 ?        S      0:00  \_ [watchdog/1]</span><br><span class="line">13 ?        S      0:00  \_ [migration/1]</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><p><strong>6）查看系统进程，找出CPU占用率最高的进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-o选项自定义显示pcpu字段值，使用--sort选项进行排序，默认从小到大，前面加-号从大到小排序</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -eo pid,ppid,pcpu,args,comm --sort -pcpu</span></span><br><span class="line">PID   PPID %CPU COMMAND                     COMMAND</span><br><span class="line">30785      1  1.7 /usr/bin/dockerd --insecure dockerd</span><br><span class="line">11489      1  1.2 /usr/bin/containerd         containerd</span><br><span class="line">1      0  0.0 /usr/lib/systemd/systemd -- systemd</span><br><span class="line">2      0  0.0 [kthreadd]                  kthreadd</span><br><span class="line">3      2  0.0 [ksoftirqd/0]               ksoftirqd/0</span><br><span class="line">5      2  0.0 [kworker/0:0H]              kworker/0:0H</span><br><span class="line">7      2  0.0 [migration/0]               migration/0</span><br><span class="line">8      2  0.0 [rcu_bh]                    rcu_bh</span><br><span class="line">9      2  0.0 [rcu_sched]                 rcu_sched</span><br><span class="line">10      2  0.0 [lru-add-drain]             lru-add-drain</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure><h2 id="pstree：显示进程状态树"><a href="#pstree：显示进程状态树" class="headerlink" title="pstree：显示进程状态树"></a>pstree：显示进程状态树</h2><p>pstree命令以树形结构显示进程和进程之间的关系。如果不指定进程的PID号，或者不指定用户名称，则会以init进程（CentOS 7为systemd进程）为根进程，显示系统的所有进程信息；若指定用户或PID，则将以用户或PID为根进程，显示用户或PID对应的所有进程。</p><p><strong>注意：CentOS 7中默认没有pstree命令，因此执行命令后会提示command not found，此时需要通过yum命令安装，执行以下命令即可</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y psmisc</span><br></pre></td></tr></table></figure><p><strong>语法格式：pstree [option] [<pid>/<user>]</user></pid></strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc32159287525588.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示进程树</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若不指定PID号或者不指定用户，则会以init（CentOS7系统是systemd）进程为根进程，显示系统所有进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pstree</span></span><br><span class="line">systemd─┬─VGAuthService</span><br><span class="line">├─agetty</span><br><span class="line">├─auditd───&#123;auditd&#125;</span><br><span class="line">├─chronyd</span><br><span class="line">├─containerd─┬─containerd-shim─┬─registry───7*[&#123;registry&#125;]</span><br><span class="line">│            │                 └─9*[&#123;containerd-shim&#125;]</span><br><span class="line">│            └─16*[&#123;containerd&#125;]</span><br><span class="line">├─crond</span><br><span class="line">├─dbus-daemon───&#123;dbus-daemon&#125;</span><br><span class="line">├─dockerd─┬─docker-proxy───7*[&#123;docker-proxy&#125;]</span><br><span class="line">│         └─15*[&#123;dockerd&#125;]</span><br><span class="line">├─irqbalance</span><br><span class="line">├─master─┬─pickup</span><br><span class="line">│        └─qmgr</span><br><span class="line">├─polkitd───5*[&#123;polkitd&#125;]</span><br><span class="line">├─rsyslogd───2*[&#123;rsyslogd&#125;]</span><br><span class="line">├─sshd───sshd───bash───pstree</span><br><span class="line">├─systemd-journal</span><br><span class="line">├─systemd-logind</span><br><span class="line">├─systemd-udevd</span><br><span class="line">├─tuned───4*[&#123;tuned&#125;]</span><br><span class="line">└─vmtoolsd───&#123;vmtoolsd&#125;</span><br></pre></td></tr></table></figure><p><strong>2）显示指定用户的进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示apache用户的所有进程，共有5个进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pstree apache</span></span><br><span class="line">httpd</span><br><span class="line">httpd</span><br><span class="line">httpd</span><br><span class="line">httpd</span><br><span class="line">httpd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-c选项显示所有进程，包含父进程和子进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-p选项显示进程的pid</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pstree -c -p apache</span></span><br><span class="line">httpd(40920)</span><br><span class="line">httpd(40921)</span><br><span class="line">httpd(40922)</span><br><span class="line">httpd(40923)</span><br><span class="line">httpd(40924)</span><br></pre></td></tr></table></figure><p><strong>3）显示进程归属的用户</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-u选项显示进程归属的用户</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进程后[&#123;...&#125;]中的内容就是进程归属的用户信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pstree -u</span></span><br><span class="line">systemd─┬─VGAuthService</span><br><span class="line">├─agetty</span><br><span class="line">├─auditd───&#123;auditd&#125;</span><br><span class="line">├─chronyd(chrony)</span><br><span class="line">├─containerd─┬─containerd-shim─┬─registry───7*[&#123;registry&#125;]</span><br><span class="line">│            │                 └─9*[&#123;containerd-shim&#125;]</span><br><span class="line">│            └─16*[&#123;containerd&#125;]</span><br><span class="line">├─crond</span><br><span class="line">├─dbus-daemon(dbus)───&#123;dbus-daemon&#125;</span><br><span class="line">├─dockerd─┬─docker-proxy───7*[&#123;docker-proxy&#125;]</span><br><span class="line">│         └─15*[&#123;dockerd&#125;]</span><br><span class="line">├─httpd───5*[httpd(apache)]</span><br><span class="line">├─irqbalance</span><br><span class="line">├─master─┬─pickup(postfix)</span><br><span class="line">│        └─qmgr(postfix)</span><br><span class="line">├─polkitd(polkitd)───5*[&#123;polkitd&#125;]</span><br><span class="line">├─rsyslogd───2*[&#123;rsyslogd&#125;]</span><br><span class="line">├─sshd───sshd───bash───pstree</span><br><span class="line">├─systemd-journal</span><br><span class="line">├─systemd-logind</span><br><span class="line">├─systemd-udevd</span><br><span class="line">├─tuned───4*[&#123;tuned&#125;]</span><br><span class="line">└─vmtoolsd───&#123;vmtoolsd&#125;</span><br></pre></td></tr></table></figure><h2 id="pgrep：查找匹配条件的进程"><a href="#pgrep：查找匹配条件的进程" class="headerlink" title="pgrep：查找匹配条件的进程"></a>pgrep：查找匹配条件的进程</h2><p>pgrep命令可以查找匹配条件的进程号。</p><p><strong>语法格式：pgrep [option] [pattern]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc32916906552788.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示指定进程的pid</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示httpd进程进程号</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pgrep httpd</span></span><br><span class="line">40919</span><br><span class="line">40920</span><br><span class="line">40921</span><br><span class="line">40922</span><br><span class="line">40923</span><br><span class="line">40924</span><br></pre></td></tr></table></figure><p><strong>2）显示指定用户的进程号</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-u选项显示指定用户postfix的进程号</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pgrep -u postfix</span></span><br><span class="line">1737</span><br><span class="line">40931</span><br></pre></td></tr></table></figure><h2 id="kill：终止进程"><a href="#kill：终止进程" class="headerlink" title="kill：终止进程"></a>kill：终止进程</h2><p>kill命令能够终止你希望停止的进程。</p><p><strong>语法格式：kill [option] [pid]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc32dd9719b18900.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）列出所有信号的名称</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用-l选项，显示所有信号</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># kill -l</span></span><br><span class="line">1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP</span><br><span class="line">6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL10) SIGUSR1</span><br><span class="line">11) SIGSEGV12) SIGUSR213) SIGPIPE14) SIGALRM15) SIGTERM</span><br><span class="line">16) SIGSTKFLT17) SIGCHLD18) SIGCONT19) SIGSTOP20) SIGTSTP</span><br><span class="line">21) SIGTTIN22) SIGTTOU23) SIGURG24) SIGXCPU25) SIGXFSZ</span><br><span class="line">26) SIGVTALRM27) SIGPROF28) SIGWINCH29) SIGIO30) SIGPWR</span><br><span class="line">31) SIGSYS34) SIGRTMIN35) SIGRTMIN+136) SIGRTMIN+237) SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+439) SIGRTMIN+540) SIGRTMIN+641) SIGRTMIN+742) SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+944) SIGRTMIN+1045) SIGRTMIN+1146) SIGRTMIN+1247) SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+1449) SIGRTMIN+1550) SIGRTMAX-1451) SIGRTMAX-1352) SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-1154) SIGRTMAX-1055) SIGRTMAX-956) SIGRTMAX-857) SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-659) SIGRTMAX-560) SIGRTMAX-461) SIGRTMAX-362) SIGRTMAX-2</span><br><span class="line">63) SIGRTMAX-164) SIGRTMAX</span><br></pre></td></tr></table></figure><p><strong>常用信号说明：</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc33114511356436.jpg"></p><p><strong>2）终止进程说明</strong></p><p>kill指令默认使用的信号为15，用于结束进程。如果进程忽略此信号，则可以使用信号9强制终止进程。一般是先通过ps等命令获取到要终止进程的进程号，然后直接使用“kill进程号”就可以了。比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> 2203 <span class="comment">#&lt;==kill命令默认使用的信号为15，这种格式也是最常用的。</span></span><br><span class="line"><span class="built_in">kill</span> -s 15 2203 <span class="comment">#&lt;==这种格式使用-s参数明确指定发送值为15的信号，效果和kill 2203一样。</span></span><br><span class="line"><span class="built_in">kill</span> -15 2203 <span class="comment">#&lt;==上面的-s 15可以简写为-15。</span></span><br></pre></td></tr></table></figure><p>如果用上面的方法还是无法终止进程，那么我们就可以用KILL（9）信号强制终止进程。</p><p>kill -9 2203 #&lt;==<strong>信号9会强行终止进程，这会带来一些副作用，如数据丢失，或者终端无法恢复到正常状态等，因此应尽量避免使用，除非进程使用其他信号无法终止。</strong></p><p><strong>3）特殊信号0的作用</strong></p><p>在kill的所有信号中，有一个十分特殊的信号值0，使用格式为<strong>kill -0 $pid</strong>。其中的-0表示不发送任何信号给$pid对应的进程，但是仍然会对$pid是否存在对应的进程进行检査，如果$pid对应的进程已存在，则返回0，若不存在则返回1。因此，这个特殊信号通常用于系统管理shell脚本中判断某个进程是否运行的条件表达式。</p><h2 id="killall：通过进程名终止进程"><a href="#killall：通过进程名终止进程" class="headerlink" title="killall：通过进程名终止进程"></a>killall：通过进程名终止进程</h2><p>使用kill命令终止进程还需要先获取进程的pid进程号，这个过程有点繁琐，而使用killall命令就可以直接用“killall进程名”这种形式终止进程。</p><p><strong>语法格式：killall [option] [name]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc33bc0e31d24710.jpg"></p><p><img src="https://i.loli.net/2019/05/15/5cdc33cd04b8435545.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）终止定时任务服务进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># killall crond</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看crond进程状态，确认</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果什么输出也没有，则表示crond进程被终止</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -ef | grep crond | grep -v grep</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同样，也可使用BSD格式aux选项查看进程状态确认</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果进程的状态是S，则表示被终止</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps aux | grep cornd</span></span><br><span class="line">root      40964  0.0  0.0 112704   972 pts/1    S+   00:14   0:00 grep --color=auto cornd</span><br></pre></td></tr></table></figure><p><strong>2）终止指定用户的所有进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 终止apache用户的所有httpd进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># killall -u apache httpd</span></span><br></pre></td></tr></table></figure><h2 id="pkill：通过进程名终止进程"><a href="#pkill：通过进程名终止进程" class="headerlink" title="pkill：通过进程名终止进程"></a>pkill：通过进程名终止进程</h2><p>pkill命令可通过进程名终止指定的进程。使用killall终止进程需要连续执行几次，而pkill可以杀死指定进程及其所有子进程。</p><p><strong>语法格式：pkill [option] [name]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc342e2eb4733234.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）通过进程名终止进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看定时任务crond当前状态</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl status crond</span></span><br><span class="line">● crond.service - Command Scheduler</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: inactive (dead) since Sat 2019-05-04 00:11:34 CST; 11min ago</span><br><span class="line">  Process: 10272 ExecStart=/usr/sbin/crond -n <span class="variable">$CRONDARGS</span> (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 10272 (code=exited, status=0/SUCCESS)</span><br><span class="line"></span><br><span class="line">May 03 17:19:56 C7-Server01 systemd[1]: Started Command Scheduler.</span><br><span class="line">May 03 17:19:56 C7-Server01 systemd[1]: Starting Command Scheduler...</span><br><span class="line">May 03 17:19:56 C7-Server01 crond[10272]: (CRON) INFO (RANDOM_DELAY will be scaled with f...d.)</span><br><span class="line">May 03 17:19:56 C7-Server01 crond[10272]: (CRON) INFO (running with inotify support)</span><br><span class="line">May 03 17:19:56 C7-Server01 crond[10272]: (CRON) INFO (@reboot <span class="built_in">jobs</span> will be run at comput...p.)</span><br><span class="line">May 04 00:11:34 C7-Server01 crond[10272]: (CRON) INFO (Shutting down)</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show <span class="keyword">in</span> full.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动定时任务crond</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl start crond</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过进程名终止进程crond</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pkill crond</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># systemctl status crond</span></span><br><span class="line">● crond.service - Command Scheduler</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: inactive (dead) since Sat 2019-05-04 00:24:03 CST; 9s ago</span><br><span class="line">  Process: 40980 ExecStart=/usr/sbin/crond -n <span class="variable">$CRONDARGS</span> (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 40980 (code=exited, status=0/SUCCESS)</span><br><span class="line"></span><br><span class="line">May 04 00:23:29 C7-Server01 systemd[1]: Started Command Scheduler.</span><br><span class="line">May 04 00:23:29 C7-Server01 systemd[1]: Starting Command Scheduler...</span><br><span class="line">May 04 00:23:29 C7-Server01 crond[40980]: (CRON) INFO (RANDOM_DELAY will be scaled with f...d.)</span><br><span class="line">May 04 00:23:29 C7-Server01 crond[40980]: ((null)) No security context but SELinux <span class="keyword">in</span> per...ab)</span><br><span class="line">May 04 00:23:29 C7-Server01 crond[40980]: ((null)) No security context but SELinux <span class="keyword">in</span> per...ly)</span><br><span class="line">May 04 00:23:29 C7-Server01 crond[40980]: (CRON) INFO (running with inotify support)</span><br><span class="line">May 04 00:23:29 C7-Server01 crond[40980]: (CRON) INFO (@reboot <span class="built_in">jobs</span> will be run at comput...p.)</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show <span class="keyword">in</span> full.</span><br></pre></td></tr></table></figure><p><strong>2）通过终端名终止进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前用户运行的终端信息，通过w指令实现</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TTY列就是当前用户终端类型</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># w</span></span><br><span class="line"> 00:29:17 up  7:16,  2 users,  load average: 0.00, 0.01, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">kkutysll tty1                      00:27   13.00s  0.03s  0.01s vim /etc/ssh/ssh_config</span><br><span class="line">root     pts/1    192.168.101.1    17:23    5.00s  0.30s  0.01s w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述结果说明：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kkutysllb用户正在服务器本地登录，且正在编辑ssh服务配置文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># root用户正在远程登录，且正在使用w命令查询服务器当前登录用户状态信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过终端名终止kkutysllb的进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pkill -t tty1</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># w</span></span><br><span class="line"> 00:31:48 up  7:18,  2 users,  load average: 0.00, 0.01, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">kkutysll tty1                      00:27    2:44   0.03s  0.03s -bash</span><br><span class="line">root     pts/1    192.168.101.1    17:23    4.00s  0.29s  0.00s w</span><br></pre></td></tr></table></figure><p>本地登录用户kkutysllb编辑ssh配置文件的操作被终止了</p><p><img src="https://i.loli.net/2019/05/15/5cdc348a1ceed80249.jpg"></p><p><strong>3）通过用户名终止进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># w</span></span><br><span class="line"> 00:34:34 up  7:21,  2 users,  load average: 0.00, 0.01, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">kkutysll tty1                      00:27   10.00s  0.26s  0.02s vim /etc/sysconfig/network-scr</span><br><span class="line">root     pts/1    192.168.101.1    17:23    2.00s  0.29s  0.00s w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-u选项，终止kkutysllb用户编辑网卡配置文件操作</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># pkill -u kkutysllb</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># w</span></span><br><span class="line"> 00:35:23 up  7:22,  2 users,  load average: 0.00, 0.01, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">kkutysll tty1                      00:27   59.00s  0.24s  0.24s -bash</span><br><span class="line">root     pts/1    192.168.101.1    17:23    3.00s  0.29s  0.00s w</span><br></pre></td></tr></table></figure><p>用户kkutysllb编辑网卡配置文件的操作被root用户远程终止。</p><p><img src="https://i.loli.net/2019/05/15/5cdc34c0179d588853.jpg"></p><p><strong>如果kkutysllb不是通过本地登录服务器，而是远程登录，通过-u选项可以将kkutysllb踢下线，效果请大家自行练习。</strong></p><h2 id="nice：调整程序运行时的优先级"><a href="#nice：调整程序运行时的优先级" class="headerlink" title="nice：调整程序运行时的优先级"></a>nice：调整程序运行时的优先级</h2><p>nice命令是一个当程序启动时，修改程序运行优先级的命令。Linux的优先级范围是从-20（最大优先级）到19（最小优先级）。优先级越高的程序占用CPU的次数越多，反之亦然。</p><p><strong>语法格式：nice [option] [command]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc34e785e9542473.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）单独使用nice命令</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不接任何选项和程序时，显示出当前系统默认的nice程序运行优先级为0</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># nice</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure><p><strong>2）默认增加优先级10</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不加-n选项，直接跟程序名</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># nice nice</span></span><br><span class="line">10</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># nice nice nice</span></span><br><span class="line">19</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># nice nice nice nice</span></span><br><span class="line">19</span><br></pre></td></tr></table></figure><p>第1个nice命令以默认值10来调整第2个nice命令运行的优先级，即在系统默认的程序运行优先级0的基础之上增加10，得到新的程序运行优先级10，然后以优先级10来运行第2个nice命令，最后第2个nice命令显示当前程序运行的优先级为10。所以，再加一个nice就是19（因为最小优先级为19），再往后加nice一直都是19。</p><p><strong>3）查看进程优先级</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -l</span></span><br><span class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0  11097  11093  0  80   0 - 28859 do_wai pts/1    00:00:00 bash</span><br><span class="line">0 R     0  41043  11097  0  80   0 - 38300 -      pts/1    00:00:00 ps</span><br></pre></td></tr></table></figure><p>在上面的输出结果中，需要重点关注以下两列。</p><ul><li>PRI：代表这个进程的优先级，通俗点说就是进程被CPU执行的先后顺序，此值越小进程的优先级别就越高，就能越早执行。</li><li>NI：代表这个进程的nice值，表示进程可被执行的优先级的修正数值，在加入nice值后，将会使得PRI变为：PRI（new）=80（PRI初始默认值）+nice。这样一来，如果nice值为负值，那么该进程的优先级值将变小，即其优先级会变高，也表示其越快被执行。</li></ul><p><strong>总结：NI是优先值，是用户层面的概念，PR是进程的实际优先级，是给内核（kernel）用的。进程的nice值不是进程的优先级，它们不是一个概念，但是进程的nice值会影响到进程的优先级变化。</strong></p><h2 id="renice：调整运行中的进程的优先级"><a href="#renice：调整运行中的进程的优先级" class="headerlink" title="renice：调整运行中的进程的优先级"></a>renice：调整运行中的进程的优先级</h2><p>nice命令常用于修改未运行的程序运行时的优先级，但是对于正在运行的进程，若想要修改其优先级，就需要用到renice命令。</p><p>在系统运行中，有时会发现某个不是很重要的进程占用了太多的CPU资源，因此会希望限制这个进程或者是希望某个进程优先运行。这些都是renice命令的使用场景。</p><p><strong>语法格式：renice [option]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc3559d1cef39479.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）修改指定进程号的优先级</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在当前进程后台创建一个vim命令进程</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># vim /etc/host &amp;</span></span><br><span class="line">[1] 1839</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前系统进程信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -l</span></span><br><span class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0   1770   1767  0  80   0 - 28858 do_wai pts/0    00:00:00 bash</span><br><span class="line">0 T     0   1839   1770  0  80   0 - 37284 do_sig pts/0    00:00:00 vim</span><br><span class="line">0 R     0   1840   1770  0  80   0 - 38300 -      pts/0    00:00:00 ps</span><br><span class="line"></span><br><span class="line">[1]+  Stopped                 vim /etc/host</span><br><span class="line"></span><br><span class="line"><span class="comment"># vim当前进程的优先级为80，NI为0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用renice的-p选项指定进程1839，将其NI值调整为-5</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># renice -n -5 -p 1839</span></span><br><span class="line">1839 (process ID) old priority 0, new priority -5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次查看当前系统进程信息，发现vim的PRI变为75</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -l</span></span><br><span class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0   1770   1767  0  80   0 - 28859 do_wai pts/0    00:00:00 bash</span><br><span class="line">0 T     0   1839   1770  0  75  -5 - 37284 do_sig pts/0    00:00:00 vim</span><br><span class="line">0 R     0   1846   1770  0  80   0 - 38300 -      pts/0    00:00:00 ps</span><br><span class="line"></span><br><span class="line"><span class="comment"># 仍然通过renice指令调整</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># renice -n -5 -p 1839</span></span><br><span class="line">1839 (process ID) old priority -5, new priority -5</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ps -l</span></span><br><span class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0   1770   1767  0  80   0 - 28859 do_wai pts/0    00:00:00 bash</span><br><span class="line">0 T     0   1839   1770  0  75  -5 - 37284 do_sig pts/0    00:00:00 vim</span><br><span class="line">0 R     0   1848   1770  0  80   0 - 38300 -      pts/0    00:00:00 ps</span><br></pre></td></tr></table></figure><p><strong>结论：PRI值并不是在上一次的基础上进行变化，而是一直在初始默认值80这个值之上变动。</strong></p><h2 id="runlevel：输出当前运行级别"><a href="#runlevel：输出当前运行级别" class="headerlink" title="runlevel：输出当前运行级别"></a>runlevel：输出当前运行级别</h2><p>runlevel命令用于输出当前Linux系统的运行级别。</p><p><strong>语法格式：runlevel [option]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/15/5cdc359024f2a37179.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>查看当前系统的运行级别</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># runlevel </span></span><br><span class="line">N 3</span><br></pre></td></tr></table></figure><p><strong>上面的结果说明当前的运行级别为3。对于系统级别，不同的数字代表的意思不一样，具体如下。</strong></p><ul><li>0：停机</li><li>1：单用户模式</li><li>2：无网络的多用户模式</li><li>3：多用户模式</li><li>4：未使用</li><li>5：图形界面多用户模式</li><li>6：重启</li></ul><h2 id="init：初始化Linux进程"><a href="#init：初始化Linux进程" class="headerlink" title="init：初始化Linux进程"></a>init：初始化Linux进程</h2><p>init命令是Linux下的进程初始化工具，init进程是所有Linux进程的父进程，它的进程号为1。init命令的主要任务是依据配置文件“/etc/inittab”创建Linux进程。</p><p><strong>语法格式：init [option]</strong></p><p><strong>【使用示例】</strong></p><p><strong>切换系统运行级别</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关机</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># init 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># init 6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单用户</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># init 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多用户</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># init 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 图形模式</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># init 5</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ps：查看进程&quot;&gt;&lt;a href=&quot;#ps：查看进程&quot; class=&quot;headerlink&quot; title=&quot;ps：查看进程&quot;&gt;&lt;/a&gt;ps：查看进程&lt;/h2&gt;&lt;p&gt;ps命令用于列出执行ps命令的那个时刻的进程快照，就像用手机给进程照了一张照片。如果想要动态地显示进程的信息，就需要使用top命令，该命令类似于把手机切换成录像模式。因为ps命令能够支持多种系统（Linux\UNIX等），所以选项较多。但是学习时只需要掌握常用的参数即可。而且由于ps命令的功能实在是太多了，26个字母已经满足不了，因此，在ps命令的参数中有类似于-a与a这2种写法，这2种写法的功能是不一样的。
    
    </summary>
    
      <category term="Linux核心命令" scheme="https://kkutysllb.cn/categories/Linux%E6%A0%B8%E5%BF%83%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="Linux" scheme="https://kkutysllb.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-13-计算虚拟化之CPU虚拟化</title>
    <link href="https://kkutysllb.cn/2019/05/13/2019-05-13-%E8%AE%A1%E7%AE%97%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B9%8BCPU%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <id>https://kkutysllb.cn/2019/05/13/2019-05-13-计算虚拟化之CPU虚拟化/</id>
    <published>2019-05-13T09:17:34.000Z</published>
    <updated>2019-05-13T09:29:57.886Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CPU虚拟化概述"><a href="#CPU虚拟化概述" class="headerlink" title="CPU虚拟化概述"></a>CPU虚拟化概述</h2><p><strong>CPU虚拟化的一个很大挑战就是要确保虚拟机发出CPU指令的隔离性。</strong>即为了能让多个虚拟机同时在一个主机上安全运行，VMM必须将各个虚拟机隔离，以确保不会相互干扰，同时也不会影响VMM内核的正常运行。尤其要注意的是：<strong>由于特权指令会影响到整个物理机，必须要使得虚拟机发出的特权指令仅作用于自身，而不会对整个系统造成影响。</strong>例如：当虚拟机发出重启命令时，并不是要重启整个物理机，而仅仅是重启所在的虚拟机。因此，VMM必须能够对来自于虚拟机操作硬件的特权指令 进行<strong>翻译</strong>并<strong>模拟</strong>，然后在对应的虚拟设备上执行，而不在整个物理机硬件设备上运行。<a id="more"></a></p><h3 id="软件方式实现的CPU虚拟化—二进制翻译技术"><a href="#软件方式实现的CPU虚拟化—二进制翻译技术" class="headerlink" title="软件方式实现的CPU虚拟化—二进制翻译技术"></a>软件方式实现的CPU虚拟化—二进制翻译技术</h3><p>二进制翻译（Binary Translation，BT）是一 种软件虚拟化技术，由VMware在Workstations和ESX产品中最早实现。在最初没有硬件虚拟化时代，是全虚拟化的唯一途径。由于BT最开始是用来虚拟化32位平台的，因此，也称为BT32。</p><p>二进制翻译，简单来说就是将那些不能直接执行的特权指令进行翻译后才能执行。具体来说，当虚拟机第一次要执行一段指令代码时，VMM会将要执行执行的代码段发给一个称为“Just-In-Time”的BT翻译器，它类似Java中的JVM虚拟机和Python的解释器，实时将代码翻译成机器指令。 翻译器将虚拟机的非特权指令翻译成可在该虚拟机上安全执行的指令子集， 而对于特权指令，则翻译为一组在虚拟机上可执行的特权指令，却不能运行在物理机上。这种机制实现了对虚拟机的<strong>隔离</strong>与<strong>封装</strong>，同时又使得x86指令的语义在虚拟机层次上得到保证。</p><p>在执行效率上，为了降低翻译指令的开销，VMM会将执行过的二进制指令翻译结果进行缓存。如果虚拟机再次执行同样的指令序列，那么之前被缓存的翻译结果可以被复用。这样就可以均衡整个VM执行指令集的翻译开销。为了进一步降低由翻译指令导致的内存开销，VMM还会将虚拟机的内核态代码 翻译结果和用户态代码直接绑定在一起。由于用户态代码不会执行特权指令，因此这种方法可以保证 安全性。<strong>采用BT机制的VMM必须要在虚拟机的地址空间和VMM的地址空间进行严格的边界控制。</strong>VMware VMM利用x86CPU中的段检查功能（Segmentation）来确保这一点。但是由于现代操作系统 Windows、Linux以及Solaris等都很少使用段检查功能，因此VMM可以使用段保护机制来限制虚拟机和VMM之间的地址空间边界控制。在极少数情况下，当虚拟机的确使用了段保护机制并且引发了 VMM冲突，VMM可以转而使用软件的段检查机制来解决这一问题。</p><h3 id="硬件方式实现的CPU虚拟化—VT-x和AMD-v"><a href="#硬件方式实现的CPU虚拟化—VT-x和AMD-v" class="headerlink" title="硬件方式实现的CPU虚拟化—VT-x和AMD-v"></a>硬件方式实现的CPU虚拟化—VT-x和AMD-v</h3><p>2003年，当AMD公司将x86从32位扩展到64位时，也将段检查功能从64位芯片上去除。同样的情况也 出现在Intel公司推出的64位芯片上。这一变化意味着基于BT的VMM无法在64位机上使用段保护机制保护VMM。尽管后来AMD公司为了支持虚拟化又恢复了64位芯片的段检查功能，并一直延续到目前所有的AMD 64位芯片，但是Intel公司却并没有简单恢复 ，而是研发了新的硬件虚拟化技术VT-x，AMD公司紧随后也推出了AMD-V技术来提供CPU指令集虚拟化的硬件支持。VT-x与AMD-V尽管在具体实现上有所不同，但其目的<strong>都是希望通过硬件的途径来限定某些特权指令操作的权限</strong>，而不是原先只能通过二进制动态翻译来解决这个问题。</p><p>如前所述，VT-x提供了2个运行环境：<strong>根（Root）环境</strong>和<strong>非根（Non-root）环境</strong>。根环境专门为VMM准备，就像没有使用VT-x技术的x86服务器，只是多了对VT-x支持的几条指令。非根环境作为一个受限环境用来运行多个虚拟机。</p><p><img src="https://i.loli.net/2019/05/13/5cd936cddfae743184.jpg"></p><p>根操作模式与非根操作模式都有相应的特权级0至特权级3。VMM运行在根模式的特权级0，Guest OS的内核运行在非根模式的特权级0，Guest OS的应用程序运行在非根模式的特权级3。运行环境之间相互转化，从根环境到非根环境叫VM Entry；从非根环境到根环境叫VM Exit。VT-x定义了VM Entry操作，使CPU由根模式切换到非根模式，运行客户机操作系统指令。若在非根模式执行了敏感指令或发生了中断等，会执行VM Exit操作，切换回根模式运行VMM。此外，VT-x还引入了一组新的命令：<strong>VMLanch/ VMResume用于调度Guest OS，发起VM Entry；</strong>VMRead/ VMWrite则用于配置VMCS。</p><p><strong>根模式与非根模式之问的相互转换是通过VMX操作实现的。</strong>VMM可以通过VMX ON 和VMX OFF打开或关闭VT-x。如下图所示：</p><p><img src="https://i.loli.net/2019/05/13/5cd936ea46c3c16573.jpg"></p><p><strong>VMX操作模式流程：</strong></p><ol><li>VMM执行VMX ON指令进入VMX操作模式。</li><li>VMM可执行VMLAUNCH指令或VMRESUME指令产生VM Entry操作，进入到Guest OS，此时CPU处于非根模式。</li><li>Guest OS执行特权指令等情况导致VM Exit的发生，此时将陷入VMM，CPU切换为根模式。VMM根据VM Exit的原因作出相应处理，处理完成后将转到第2步，继续运行GuestOS。</li><li>VMM可决定是否退出VMX操作模式，通过执行VMXOFF指令来完成。</li></ol><p>这样，就无需二进制翻译和半虚拟化来处理这些指令。同时，VT-x与AMD-V都提供了存放虚拟机状态的模块，这样做的的目的就是将虚拟机上 下文切换状态进行缓存，降低频模式繁切换引入的大量开销。 还是以VT-x解决方案为例，VMX新定义了虚拟机控制结构VMCS(Virtual Machine ControlStructure)。VMCS是保存在内存中的数据结构，其包括虚拟CPU的相关寄存器的内容及相关的控制信息。CPU在发生VM Entry或VM Exit时，都会查询和更新VMCS。VMM也可通过指令来配置VMCS，达到对虚拟处理器的管理。VMCS架构图如下图所示：</p><p><img src="https://i.loli.net/2019/05/13/5cd93705adbec22425.jpg"></p><p><strong>每个vCPU都需将VMCS与内存中的一块区域关联起来，此区域称为VMCS区域。</strong>对VMCS区域的操纵是通过VMCS指针来实现的，这个指针是一个指向VMCS的64位的地址值。VMCS区域是一个<strong>最大不超过4KB的内存块，且需4KB对齐</strong>。</p><p>VMCS区域分为三个部分：<strong>偏移地址0起始存放VMCS版本标识，通过不同的版本号，CPU可维护不同的VMCS数据格式</strong>；<strong>偏移地址4起始存放VMX终止指示器，在VMX终止发生时，CPU会在此处存入终止的原因；偏移地址8起始存放VMCS数据区，这一部分控制VMX非根操作及VMX切换。</strong></p><p>VMCS 的数据区包含了VMX配置信息：<strong>VMM在启动虚拟机前配置其哪些操作会触发VM Exit</strong>。VMExit 产生后，处理器把执行权交给VMM 以完成控制，然后VMM 通过指令触发VM Entry 返回原来的虚拟机或调度到另一个虚拟机。<strong>。</strong></p><p>VMCS 的数据结构中，每个虚拟机一个，加上虚拟机的各种状态信息，共由3个部分组成：</p><ul><li><p><strong>Gueststate：</strong>该区域保存了虚拟机运行时的状态，在VM Entry 时由处理器装载；在VM Exit时由处理器保存。它又由两部分组成：</p></li><li><ul><li><strong>Guest OS寄存器状态</strong>：包括控制寄存器、调试寄存器、段寄存器等各类寄存器的值。</li><li><strong>Guest OS非寄存器状态</strong>：记录当前处理器所处状态，是活跃、停机（HLT）、关机（Shutdown）还是等待启动处理器间中断（Startup-IPI）。</li></ul></li><li><p><strong>Hoststate：</strong>该区域保存了VMM 运行时的状态，主要是一些寄存器值，在VM Exit时由处理器装载。</p></li><li><p><strong>Control data：</strong>该区域包含虚拟机执行控制域、VM Exit控制域、VM Entry控制域、VM Exit信息域和VM Entry信息域。</p></li></ul><p>有了VMCS结构后，对虚拟机的控制就是读写VMCS结构。比如：对vCPU设置中断，检查状态实际上都是在读写VMCS数据结构。</p><h2 id="CPU虚拟化管理"><a href="#CPU虚拟化管理" class="headerlink" title="CPU虚拟化管理"></a>CPU虚拟化管理</h2><p>为了保证电信云/NFV中关键业务虚机运行的性能，就要求同一台物理机上的多个业务虚机实例所获取的资源既能满足其运行的需要，同时不互相产生干扰，这就需要对CPU资源进行精细化的调优和管理，也就是CPU QoS保障技术。在介绍CPU QoS保障技术之前，我们首先来看下CPU虚拟化的本质和超配技术。</p><h3 id="CPU虚拟化的本质和超配"><a href="#CPU虚拟化的本质和超配" class="headerlink" title="CPU虚拟化的本质和超配"></a>CPU虚拟化的本质和超配</h3><p><img src="https://i.loli.net/2019/05/13/5cd937364346e91496.jpg"></p><p>vCPU数量和物理CPU对应关系如上图所示，以华为RH2288H V3服务器使用2.6GHz主频CPU为例，单台服务器有2个物理CPU，每颗CPU有8核，又因为超线程技术，每个物理内核可以提供两个处理线程，因此每颗CPU有16线程，总vCPU数量为2<em>8</em>2=32个vCPU。总资源为32*2.6GHz=83.2GHz。</p><p><strong>虚拟机vCPU数量不能超过单台物理服务器节点可用vCPU数量</strong>。但是，由于多个虚拟机间可以复用同一个物理CPU，因此单物理服务器节点上运行的虚拟机vCPU数量总和可以超过实际vCPU数量，这就叫做<strong>CPU超配技术</strong>。</p><p>例如，以华为的FusionCompute为例，查询显示的服务器可用CPU的物理个数为2个，每个主频2.4GHz。</p><p><img src="https://i.loli.net/2019/05/13/5cd9375b03d0624108.jpg"></p><p>这是特权虚机中占用CPU资源，占用了4个vCPU</p><p><img src="https://i.loli.net/2019/05/13/5cd9378993cc569946.jpg"></p><p>在资源池性能页，可以查看每个物理CPU有6个核，并且开启了超线程，也就是每个物理CPU有12个核的资源，一台服务器总共vCPU数量为：12<em>2=24个。由于在华为的FUSinCompute中CPU的资源统计单位不是逻辑核数，而是频率HZ。因此，可用资源（12</em>2-4）*2.4=48GHz（为什么减4个？因为系统DM0占用了4个vCPU，因此单个客户机最多只能使用20个vCPU）。如下所示，当前已经使用了19.15GHZ，占用率为39.39%。</p><p><img src="https://i.loli.net/2019/05/13/5cd937a72be2962794.jpg"></p><h3 id="CPU的QoS保障"><a href="#CPU的QoS保障" class="headerlink" title="CPU的QoS保障"></a>CPU的QoS保障</h3><p>了解了CPU虚拟化的本质和超配，前文提到的CPU的QoS保障技术主要指的是<strong>CPU上下限配额</strong>及<strong>优先级调度</strong>技术。</p><p><strong>CPU的上下限配额主要指的是vCPU资源管理层面的解决方案。</strong>在CPU虚拟化后，根据虚拟化的资源—频率HZ，来对虚拟机进行分配时，为了保证虚拟机的正常运行，特地定义了三种vCPU资源的划分方式，这就是CPU资源的QoS管理。可以按照限额、份额和预留三种方式进行vCPU资源划分，三者之间是有一定依赖和互斥关系的，其定义具体如下：</p><ul><li><strong>CPU资源限额：</strong>控制虚拟机占用物理资源的上限。</li><li><strong>CPU资源份额：</strong>CPU份额定义多个虚拟机在竞争物理CPU资源的时候按比例分配计算资源。</li><li><strong>CPU资源预留：</strong>CPU预留定义了多个虚拟机竞争物理CPU资源的时候分配的最低计算资源。</li></ul><p>为了描述上述三种vCPU资源划分方式的关系，我们还是举例来说明。比如：单核CPU主频为3GHz，该资源供两个虚拟机VM1和VM2使用。</p><p><strong>场景一：当</strong>VM1资源限额为2GHz，VM1可用的CPU资源最多为2GHz，也就意味着如果VM2没有设定CPU QoS，那么VM2最多只有1GHZ的vCPU可以使用。</p><p><strong>场景二：当</strong>VM1和VM2的资源份额分别是1000和2000，在资源紧张场景下发生竞争时，VM1最多可获得1GHz的vCPU，VM2最多可获得2GHz的vCPU。</p><p><strong>场景三：当给虚拟机</strong>VM1资源预留2GHz的vCPU资源，VM2资源预留为0，在资源紧张发生竞争时，VM1最少可获得2GHz的vCPU，最多可获得3GHZ的vCPU（在没有超配时），而VM2最多可获得1GHz（3-2=1）的vCPU资源，最少为0。</p><p>上例只是简单描述了各种vCPU划分方式单独生效时的场景，也是在实际中较常用的场景。同时，在实际中还有一些场景是多种vCPU划分方式共同作用的，虽然不常用，但是却是实实在在有意义的。比如：以一个主频为2.8GHz的单核物理机为例，如果运行有三台单CPU的虚拟机A、B、C，份额分别为1000、2000、4000，预留值分别为700MHz、0MHz、0MHz。当三个虚拟机满CPU负载运行时，每台虚拟机应分配到资源计算如下：</p><p>虚拟机A按照份额分配本应得400MHz，由于其预留值大于400MHz，最终计算能力按照预留值700MHz算，剩余的2100MHz资源按照2000:4000也就是1:2的比例在B和C之间进行划分，因此虚拟机B得到700MHz计算资源，虚拟机C得到1400MHz计算资源。</p><p><strong>这里有一点需要注意：CPU的份额和预留只在多个虚拟机竞争物理CPU资源时发生，如果没有竞争发生，有需求的虚拟机可以独占物理CPU的资源。</strong></p><p><strong>而CPU的优先级调度技术主要指的的服务器虚拟化后资源的重分配机制。</strong>从上述虚拟化的结构可以看出，虚拟机和VMM共同构成虚拟机系统vCPU资源的两极调度框架。如下图所示，是一个多核环境下的虚拟机vCPU资源的两级调度框架。</p><p><img src="https://i.loli.net/2019/05/13/5cd937d8e362836269.jpg"></p><p><strong>虚拟机操作系统负责第2级调</strong>度，即<strong>线程或进程在vCPU上的调度</strong>（将核心线程映射到相应的vCPU 上）。VMM负责第1级调度，即<strong>vCPU在物理处理单元上的调度</strong>。<strong>两级调度的策略和机制不存在依赖关系。</strong> vCPU调度器负责物理处理器资源在各个虚拟机之间的分配与调度，本质上把各个虚拟机中的vCPU按照一定的策略和机制调度在物理处理单元上，可以采用任意的策略（如上面资源管理方案）来分配物理资源，满足虚拟机的不同需求。vCPU可以调度在一个或多个物理处理单元执行（分时复用或空间复用物理处理单元），也可以与物理处理单元建立一对一绑定关系（限制访问指定的物理理单元）。</p><h2 id="NUMA架构感知的调度技术"><a href="#NUMA架构感知的调度技术" class="headerlink" title="NUMA架构感知的调度技术"></a>NUMA架构感知的调度技术</h2><p>除了基础的两级调度技术外，还有基于NUMA架构的精细化调度技术。在<a href>《DPDK技术栈在电信云中的最佳实践（一）》</a>一文中，我们介绍过服务器的NUMA架构，其产生的主要原因就是解决服务器SMP架构扩展性能的问题。同样，在计算虚拟化中的CPU资源调度方面，也有基于服务器NUMA架构的调度技术，这就是<strong>Host NUMA</strong>和<strong>Guest NUMA</strong>技术，<strong>它们都是虚拟化软件技术。</strong></p><p>Host NUMA主要提供CPU负载均衡机制，解决CPU资源分配不平衡引起的VM性能瓶颈问题，当启动VM时，Host NUMA根据当时主机内存和CPU负载，选择一个负载较轻的node放置该VM，使VM的CPU和内存资源分配在同一个node上。</p><p><img src="https://i.loli.net/2019/05/13/5cd93848b9b3e66204.jpg"></p><p>如上图左边所示，Host NUMA把VM的物理内存放置在一个node上，对VM的vCPU调度范围限制在同一个node的物理CPU上，并将VM的vCPU亲和性绑定在该node的物理CPU上。考虑到VM的CPU负载是动态变化，在初始放置的node上，node的CPU资源负载也会随之变化，这会导致某个node的CPU资源不足，而另一个node的CPU资源充足，在此情况下，Host NUMA会从CPU资源不足的node上选择VM，把VM的CPU资源分配在CPU资源充足的node上，从而动态实现node间的CPU负载均衡。 Host NUMA保证VM访问本地物理内存，减少了内存访问延迟，可以提升VM性能，性能提升的幅度与VM虚拟机访问内存大小和频率相关。对于VM的vCPU个数超过node中CPU的核数时，如上图右边所示，Host NUMA把该VM的vCPU和内存均匀地放置在每个node 上，vCPU的调度范围为所有node的CPU。</p><p>如果用户绑定了VM的vCPU亲和性，Host NUMA特性根据用户的vCPU亲和性设置决定VM的放置，若绑定在一个node的CPU上，Host NUMA把VM的内存和CPU放置在一个node上，若绑定在多个node的CPU上，Host NUMA把VM的内存均匀分布在多个node 上，VM的vCPU在多个node的CPU上均衡调度。</p><p><strong>Host NUMA技术的本质保证了VM访问本地物理内存，减少了内存访问延迟，可以提升VM性能，性能提升的幅度与VM访问内存大小和频率相关。Host NUMA主要应用于针对大规格、高性能虚拟机场景，适用Oracle、 SQL Server等关键应用。</strong></p><p><img src="https://i.loli.net/2019/05/13/5cd9386a8ed5914424.jpg"></p><p>Guest NUMA如上图所示，能够使得虚拟机内部程序运行时针对NUMA结构进行优化，CPU会优先使用同一个Node上的内存，从而减小内存访问延时、提高访问效率，以此达到提升应用性能的目的。目前OS和应用都会有针对NUMA的优化，<strong>VMM通过向虚拟机呈现NUMA结构，使Guest OS及其内部应用识别Numa结构， CPU会优先使用同一个Node上的内存，减小内存访问延时、提高访问效率。</strong></p><p><strong>Guest NUMA的本质就是VMM保证NUMNA结构的透传，使虚拟机中的关键应用在NUMA方面的优化生效，减少了内存访问延迟，可以提升VM性能。Guest NUMA主要应用于虚拟机中应用程序减小内存访问延时、提高访问效率，以此达到提升应用性能的目的。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;CPU虚拟化概述&quot;&gt;&lt;a href=&quot;#CPU虚拟化概述&quot; class=&quot;headerlink&quot; title=&quot;CPU虚拟化概述&quot;&gt;&lt;/a&gt;CPU虚拟化概述&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;CPU虚拟化的一个很大挑战就是要确保虚拟机发出CPU指令的隔离性。&lt;/strong&gt;即为了能让多个虚拟机同时在一个主机上安全运行，VMM必须将各个虚拟机隔离，以确保不会相互干扰，同时也不会影响VMM内核的正常运行。尤其要注意的是：&lt;strong&gt;由于特权指令会影响到整个物理机，必须要使得虚拟机发出的特权指令仅作用于自身，而不会对整个系统造成影响。&lt;/strong&gt;例如：当虚拟机发出重启命令时，并不是要重启整个物理机，而仅仅是重启所在的虚拟机。因此，VMM必须能够对来自于虚拟机操作硬件的特权指令 进行&lt;strong&gt;翻译&lt;/strong&gt;并&lt;strong&gt;模拟&lt;/strong&gt;，然后在对应的虚拟设备上执行，而不在整个物理机硬件设备上运行。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-11-计算虚拟化概述</title>
    <link href="https://kkutysllb.cn/2019/05/11/2019-05-11-%E8%AE%A1%E7%AE%97%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A6%82%E8%BF%B0/"/>
    <id>https://kkutysllb.cn/2019/05/11/2019-05-11-计算虚拟化概述/</id>
    <published>2019-05-11T02:36:29.000Z</published>
    <updated>2019-05-11T10:59:17.750Z</updated>
    
    <content type="html"><![CDATA[<p>所谓计算虚拟化，从狭义角度可理解为对单个物理服务器的虚拟化，主要包括对服务器上的CPU、内存、I/O设备进行虚拟化，目的就是实现多个虚拟机能各自独立、相互隔离地运行于一个服务器之上。从广义角度还可延伸到云资源池下，各类资源池组网场景下的CPU、内存、I/O设备等资源进行<strong>整合、抽象</strong>和<strong>虚拟化。</strong><a id="more"></a></p><h2 id="服务器虚拟化平台概念回顾"><a href="#服务器虚拟化平台概念回顾" class="headerlink" title="服务器虚拟化平台概念回顾"></a>服务器虚拟化平台概念回顾</h2><p>在上一篇文章<a href="https://kkutysllb.cn/2019/05/03/2019-05-03-%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">《虚拟化基础》</a>中，我们介绍虚拟化基础的一些基本概念，这里我们按照服务器平台虚拟化后的一个分层结构来简单回顾下。如下：</p><p><img src="https://i.loli.net/2019/05/11/5cd635e4d8024.jpg"></p><p> 一个完整的服务器虚拟化平台从下到上包括以下几个部分：</p><ul><li><strong>底层物理资源：</strong>包括网卡、CPU、内存、存储设备等硬件资源，一般将包含物理资源的物理机称为 宿主机（Host）。</li><li><strong>虚拟机监控器（Virtual Machine Monitor，VMM）：</strong>VMM是位于虚拟机与底层硬件设备之间的虚拟层，直接运行于硬件设备之上，负责对硬件资源进行抽象，为上层虚拟机提供运行环境所需资源，并使每个虚拟机都能够互不干扰、相互独立地运行于同一个系统中。</li><li><strong>抽象化的虚拟机硬件：</strong>即虚拟层呈现的虚拟化的硬件设备。虚拟机能够发现哪种硬件设施，完全由VMM决定。虚拟设备可以是模拟的真实设备，也可以是现实中并不存在的虚拟设备，如VMware的vmxnet网卡。</li><li><strong>虚拟机：</strong>相对于底层提物理机，也称为客户机（Guest）。运行在其上的操作系统则称为客户机操作系统（Guest OS）。每个虚拟机操作系统都拥有自己的虚拟硬件，并在一个独立的虚拟环境中执行。通过VMM的隔离机制，每个虚拟机都认为自己作为一个独立的系统在运行。</li></ul><p>同时，在上一篇文章<a href>《虚拟化基础》</a>中，我们提到过<strong>Hypervisor就是VMM。其实，这个说法并不准确，至少在VMware的虚拟化解决方案中不准确</strong>，在VMware的ESX产品架构中，VMM和Hypervisor还是有一定区别的，如下图所示。</p><p><img src="https://i.loli.net/2019/05/11/5cd636306da7a.jpg"></p><p>Hypervisor是位于虚拟机和底层物理硬件之间的虚拟 层，包括boot loader、x86 平台硬件的抽象层，以及内存与CPU调度器，<strong>负责对运行在其上的多个虚拟机进行资源调度。</strong>而VMM则是与上层的虚机 一一对应 的进程，<strong>负责对指令集、内存、中断与基本的I/O设备进行虚拟化。</strong>当运行一个虚拟机时，Hypervisor中的vmkernel会装载VMM，虚拟机直接运行于VMM之上，并通过VMM的接口与Hypervisor进行通信。而<strong>在KVM和Xen架构中，虚拟层都称为Hypervisor，也就是**</strong>VMM=Hypervisor**。</p><p><strong>判断一个VMM能否有效确保服务器系统实现虚拟化功能，必须具备以下三个基本特征：</strong></p><ul><li><strong><em>等价性（Equivalence Property）：</em></strong>一个 运行于VMM控制 之下的程序（虚拟机），除了时序和资源可用性可能不一致外， 其行为应该与相同条件下运行在物理服务器上的行为一致。 </li><li><strong><em>资源可控 性（Resource Control Property）：</em></strong>VMM必须能够完全控制虚拟化的资源。 </li><li><strong><em>效率性（Efficiency Property）：</em></strong>除了特权指令，绝大部分机器指令都可以直接由硬件执行，而无需VMM干涉控制。</li></ul><p><strong>上述三个基本特征也是服务器虚拟化实现方案的指导思想。</strong></p><h2 id="x86平台虚拟化面临的问题与挑战"><a href="#x86平台虚拟化面临的问题与挑战" class="headerlink" title="x86平台虚拟化面临的问题与挑战"></a>x86平台虚拟化面临的问题与挑战</h2><p>基于x86的操作系统在一开始就被设计为能够直接运行在裸机硬件环境之上，所以自然拥有整个机器硬件的控制权限。为确保操作系统能够安全地操作底层硬件，x86平台使用了特权模式和用户模式的概念对内核程序与用户应用程序进行隔离。 在这个模型下，CPU提供了4个特权级别，分别是Ring0、1、2和3。如下图所示：</p><p><img src="https://i.loli.net/2019/05/11/5cd6367646f12.jpg"></p><p>Ring 0是最高特权级别，拥有对内存和硬件的直接访问控制权。Ring 1、2和3权限依次降低， 无法执行操作讷河系统级别的指令集合。相应的，运行于Ring 0的指令称为“特权指令”；运行于其他级别的称为“非特权指令”。常见的操作系统如Linux与Windows都运行于Ring 0，而用户级应用程序运行于Ring 3。如果低特权级别的程序执行了特权指令，会引起<strong>“ 陷入”（Trap）</strong>内核态，并抛出一个异常。</p><p>当这种分层隔离机制应用于虚拟化平台 ，为了满足 VMM的“资源可控” 特征，VMM必须处于Ring 0级别控制所有的硬件资源，并且执行最高特权系统调用。而虚拟机操作系统Guest OS则要被降级运行在Ring 1级别，故Guest OS在执行特权指令时都会引起”<strong>陷入</strong>“。如果VMM能够正常捕获异常，模拟Guest OS发出的指令并执行，就达到了目的。这就是IBM的Power系列所采用的<strong>特权解除</strong>和<strong>陷入模拟</strong>的机制，支持这种特性的指令集合通常被认为是“ <strong>可虚拟化的</strong>”。</p><p>但是。。。但是。。。但是。。。<strong>x86平台的指令集是不虚拟化的</strong>。为什么这么说？首先我们来看下x86平台指令集分类，x86平台的指令集大致分为以下4类：</p><ol><li>访问或修改机器状态的指令。 </li><li>访问或修改敏感寄存器或存储单元的指令， 比如访问时钟寄存器和中断寄存器。</li><li>访问存储保护系统或内存、地址分配系统的指令（段页之类）。</li><li>所有I/O指令。</li></ol><p>其中，1~4在x86平台都属于敏感指令，第1、4类指令属于敏感指令中的特权指令，由操作系统内核执行，Guest OS在执行两类指令时，因为不处于Ring 0级别，所以会陷入，并抛出异常，这个异常会被VMM捕获，然后模拟Gust OS去执行，并将执行结果返回给Guest OS。到此为止，一切都OK。但是，第2、3类指令属于非特权指令，可以由应用程序调用，也就是可以在Ring 3级别执行，并调用Guest OS内核进程来完成。当应用程序调用这些指令时，由于要修改内存和内部寄存器，这些状态修改需要由Guest OS完成，而Guse OS此时运行在Ring 1级别，虽然也会发生陷入，但是不会抛出异常，这样VMM就捕获不到，也就无法模拟完成。因此，当Guest OS执行这些指令就会导致虚拟机状态异常，甚至影响服务器的状态。在x86平台下，这类指令共有19个，我自己称之为x86平台敏感指令中的边界指令。</p><p>就是因为x86平台指令集有上述缺陷，所以为了计算虚拟化技术在x86平台应用，各大虚拟化厂商推出了五花八门的虚拟化技术，其目的都是围绕“<strong>如何捕获模拟这19条边界指令</strong>”这一命题来设计。在很长一段时间，都是通过软件的方式来解决这个问题，其中包括无需修改内核的<strong>全虚拟化</strong>与需要修改内核的半虚拟化。尽管半虚拟化要求修改Guest OS内核的方式在一定程度上并不满足“ 等价性”要求，但是在性能上却明显优于全虚拟化。直到2005年Intel与AMD公司分别推出了VT-d与AMD-V，能够在芯片级别支持全虚拟化时，虚拟化技术才得到彻底完善，这就是现在称之为的<strong>硬件辅助虚拟化技术</strong>。</p><h2 id="x86平台计算虚拟化解决方案"><a href="#x86平台计算虚拟化解决方案" class="headerlink" title="x86平台计算虚拟化解决方案"></a>x86平台计算虚拟化解决方案</h2><h3 id="全虚拟化"><a href="#全虚拟化" class="headerlink" title="全虚拟化"></a>全虚拟化</h3><p><strong>全虚拟化（Full Virtualization）与半虚拟化（Para- Virtualization）的划分，是相对于是否修改Guest OS而言的。</strong>如下图所示，全虚拟化通过一层能够完整模拟物理硬件环境的虚拟软件，使得Guest OS与底层物理硬件彻底解耦。因此，Guest OS无需任何修改，虚拟化的环境对其完全透明，也就是说在全虚方案中，虚拟机感知不到自己处于虚拟化环境中，认为自己一直运行在物理硬件上。如下图所示： </p><p><img src="https://i.loli.net/2019/05/11/5cd6aa1bb4122.jpg"></p><p>在实现上，通常是结合特权指令的二进制翻译机制与一般指令的直接执行的方式。具体来说， 对于Guest OS发出的特权指令和边界指令，VMM会进行实时翻译，并缓存结果（目的是提高虚拟化性能），而对于一般级别的指令，则无需VMM干涉，可以直接在硬件上执行。异常-捕获-模拟的过程如下图所示：</p><p><img src="https://i.loli.net/2019/05/11/5cd6aa3574064.jpg"></p><p>由于虚拟化环境对Guest OS是完全透明的，全虚拟化模式对于虚拟机的迁移以及可移植性是最佳解决方案，虚拟机可以无缝地从虚拟环境迁移到物理环境中。但是，软件模拟实现的全虚拟化无疑会增加VMM的上下文切换，因为这种方案实现的虚拟机性能不如半虚拟化方案。 VMware的ESX系列产品 和Workstations系列产品是全虚拟化技术的典型产品。</p><h3 id="半虚拟化"><a href="#半虚拟化" class="headerlink" title="半虚拟化"></a>半虚拟化</h3><p>如前所述，x86平台上一直存在一些Ring 3级别可以执行的边界指令，尽管全虚拟化模式通过实时译 这些特殊指令解决了这一问题，但是实现开销较大，性能并不如在实际物理机上运行。为了改善能，半虚拟化技术应运而生， “Para-Virtualization” 可理解为通过某种辅助的方式实现虚拟化。半虚拟化的解决方案如下图所示。</p><p><img src="https://i.loli.net/2019/05/11/5cd6aa688f432.jpg"></p><p>半虚拟化在Guest OS和虚拟层之间增加了一个特殊指令的过渡模块，通过<strong>修改Guest OS内核</strong>，<strong>将执行特权指令和边界指令替换为对虚拟层进行hypercall的调用方式来达到目的</strong>。同时，虚拟层也对内存管理、中断处理、时间同步提供了hypercall的调用接口。Hypercall调用过程如下图所示：</p><p><img src="https://i.loli.net/2019/05/11/5cd6aa85ecc26.jpg"></p><p>通过这种方式，虚拟机运行的性能得以显著提升。但是，对于某些无法修改内核的操作系统，比如：Windows，则不能使其运行于半虚拟化环境中。而且，由于需要修改Guest OS内核，无法保证虚拟机在物理环境与虚拟环境之间的透明切换。开源项目Xen和华为6.3版本之前的虚拟化解决方案Fusion Compute就是通过修改Linux内核以及提供I/O虚拟化操作的Domain 0的特殊虚拟机，使得运行于虚拟化环境上的虚拟机性能可以接近运行于物理环境的性能，属于半虚拟化技术方案的典型产品。但是，随着业务规模的增大，特殊虚机Domain 0是这种解决方案扩展性和性能方面的瓶颈。</p><h3 id="硬件辅助虚拟化"><a href="#硬件辅助虚拟化" class="headerlink" title="硬件辅助虚拟化"></a>硬件辅助虚拟化</h3><p>所谓“解铃还须系铃人”，针对敏感指令引发的一系列虚拟化问题，处理器硬件厂商最终给出了自己的解决方案。2005年Intel与AMD公司都效法IBM大型机虚拟化技术分别推出VT-x和AMD-V技术。如下图所示：</p><p><img src="https://i.loli.net/2019/05/11/5cd6aaa75cc20.jpg"></p><p>第一代VT-x与AMD-V都试图通过定义新的运行模式，使Guest OS恢复到Ring 0，而让VMM运行在比 Ring 0低的级别（可以理解为Ring -1）。比如： Intel公司的VT-x解决方案中，运行于非根模式下的Guest OS可以像在非虚拟化平台下一样运行于Ring 0级别，无论是Ring 0发出的特权指令还是Ring 3发出的敏感指令都会被陷入到根模式的虚拟层。VT-x解决方案具体如下图所示：</p><p><img src="https://i.loli.net/2019/05/11/5cd6aacadcc7a.jpg"></p><p>VT-x与AMD-V推出之后，完美解决解决x86平台虚拟化的缺陷，且提升了性能，所以各个虚拟化厂商均快速开发出对应的产品版本，用于支持这种技术。比如：KVM-x86、Xen 3.0与VMware ESX 3.0之后的虚拟化产品。随后Intel和AMD在第二代硬件辅助虚拟化技术中均推出了针对I/O的硬件辅助虚拟化技术VT-d和IOMMU。</p><p><strong>总结：x86平台下的三种虚拟化技术，都是围绕x86在虚拟化上的一些缺陷产生的。</strong>下图对三种虚拟 化技术进行了比较。</p><p><img src="https://i.loli.net/2019/05/11/5cd6aae286ad4.jpg"></p><p><strong>从图中可以看出，全虚拟化与半虚拟化的Guest OS的特权级别都被压缩在Ring 1中，而硬件虚拟化则将Guest OS恢复到了Ring 0级别。 在半虚拟化中，Guest OS的内核经过修改，所有敏感指令和特权指令都以Hypercall的方式进行调用，而在全虚拟化与硬件虚拟化中，则无需对Guest OS 进行修改。全虚拟化中对于特权指令和敏感指令采用了动态二进制翻译的方式，而硬件虚拟化由于在芯片中增加了根模式的支持，并修改 了敏感指令的语义，所有特权指令与敏感指令都能够自动陷入到根模式的VMM中。</strong></p><table><thead><tr><th></th><th><strong>利用二进制翻译的全虚拟化</strong></th><th><strong>硬件辅助虚拟化</strong></th><th><strong>操作系统协助/半虚拟化</strong></th></tr></thead><tbody><tr><td><strong>实现技术</strong></td><td>BT和直接执行</td><td>遇到特权指令转到root模式执行</td><td>Hypercall</td></tr><tr><td><strong>客户操作系统修改/兼容性</strong></td><td>无需修改客户操作系统，最佳兼容性</td><td>无需修改客户操作系统，最佳兼容性</td><td>客户操作系统需要修改来支持hypercall，因此它不能运行在物理硬件本身或其他的hypervisor上，兼容性差，不支持Windows</td></tr><tr><td><strong>性能</strong></td><td>差</td><td>全虚拟化下，CPU需要在两种模式之间切换，带来性能开销；但是，其性能在逐渐逼近半虚拟化。</td><td>好。半虚拟化下CPU性能开销几乎为0，虚机的性能接近于物理机。</td></tr><tr><td><strong>应用厂商</strong></td><td>VMware Workstation/QEMU/Virtual PC</td><td>VMware ESXi/Microsoft Hyper-V/Xen 3.0/KVM</td><td>Xen</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;所谓计算虚拟化，从狭义角度可理解为对单个物理服务器的虚拟化，主要包括对服务器上的CPU、内存、I/O设备进行虚拟化，目的就是实现多个虚拟机能各自独立、相互隔离地运行于一个服务器之上。从广义角度还可延伸到云资源池下，各类资源池组网场景下的CPU、内存、I/O设备等资源进行&lt;strong&gt;整合、抽象&lt;/strong&gt;和&lt;strong&gt;虚拟化。&lt;/strong&gt;
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-03-虚拟化技术基础</title>
    <link href="https://kkutysllb.cn/2019/05/03/2019-05-03-%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"/>
    <id>https://kkutysllb.cn/2019/05/03/2019-05-03-虚拟化技术基础/</id>
    <published>2019-05-03T06:02:14.000Z</published>
    <updated>2019-05-07T13:19:12.926Z</updated>
    
    <content type="html"><![CDATA[<p>DPDK技术奠定了NFV领域数据包转发性能提升的基础，那么软硬件解耦后，在通用服务器上实现各功能网元，资源层面的隔离和共生问题就需要虚拟化技术来解决。虚拟化使用软件的方法重新定义划分IT资源，可以实现IT资源的动态分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需求。<a id="more"></a></p><p><img src="https://i.loli.net/2019/05/03/5ccbd9e108847.jpg"></p><h2 id="什么是虚拟化"><a href="#什么是虚拟化" class="headerlink" title="什么是虚拟化"></a>什么是虚拟化</h2><p><strong>坦白地说，虚拟化就是欺骗。</strong>随着个人计算机的普及，“虚拟化”这个广泛使用的术语已经脱离了其技术本身，成为一种共同语言、流行文化和理念。自20世纪90年代互联网热潮的早期，任何与Web相关的活动均被称为“虚拟”。通过菲利浦•狄克的科幻小说、让•鲍德里亚的后现代主义研究，以及电影（如《黑客帝国》和《盗梦空间》）的影响，<strong>模拟现实</strong>的概念已经深入人心。</p><p>在技术领域，虚拟化是指利用“欺骗”技术将一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。</p><p><img src="https://i.loli.net/2019/05/03/5ccbda2bdfa98.jpg"></p><p>传统构架是在每台物理机器上仅能拥有一个操作系统，而且多数情况下仅有一个负载。很难在服务器上运行多个主应用程序，否则可能会产生冲突和性能问题（上世纪90年代前，服务器一直面临的问题）。要解决上述冲突，最佳做法是每个服务器仅运行一个应用程序以避免这些问题。但是，这么做的结果是大部分时间资源利用率很低，且成本很高。因此，必须在加大投资和降低风险间寻找平衡。但是，随着业务的增长，随之而来的成本压力也变化，相关管理效率也会变低，需消耗的资源也会变大。</p><p>企业实施虚拟化战略的核心目的就是提高IT部门作为业务支撑部门的工作效率，达到节约成本与提高效率并重的目的。<strong>虚拟化的重要使命之一就是提高管理效率</strong>，从而<strong>降低成本</strong>、提高硬件使用率，把管理变得更加轻松。虚拟化的主攻方向集中在减少实体服务器的部署数量，并将实体机器上的操作系统及应用程序，无缝转移至虚拟机器上，以便集中管理这些不同平台的虚拟环境。</p><p>传统构架下，APP:OS:Phy = 1:1:1。这样子就造成资源利用率低，为不造成资源浪费，会增加APP部署。进而产生的影响就是不同应用之间的资源抢占，隔离性差。而OS主要提供应用运行的环境，在资源调度方面相对薄弱，不能完全有效解决以上问题。</p><p>为在不造成冲突的前提下提高资源利用率，最好是在一个OS上部署一个APP，于是就出现了虚拟化的技术的雏形。在一台主机上部署多个虚拟客户机并安装OS，每个OS安装一个APP，这样就解决了问题，达到的效果是APP:OS:Phy = n:n:1。</p><p>虚拟化之后实现了上层操作系统与下层硬件的解耦，就是说操作系统不再依赖物理的硬件，而是在VMM层上建立OS，由VMM层来实现OS对硬件的需求。</p><p><strong>虚拟化的几个重要概念</strong></p><p><img src="https://i.loli.net/2019/05/03/5ccbdf9299a83.jpg"></p><ol><li><strong>宿主机（Host Machine）：</strong>指物理机资源，被Hypervisor用来执行一个或多个虚拟机器的电脑称为主机。</li><li><strong>客户机（Guest Machine）：</strong>指虚拟机资源，在Hypervisor之上运行多个虚拟机器则称为客户机。</li><li><strong>Guest OS和Host OS：</strong>如果将一个物理机虚拟成多个虚拟机，则称物理机为Host Machine，运行在其上的OS为Host OS；多个虚拟机称为Guest Machine，运行在其上的OS为Guest OS。</li><li><strong>Hypervisor：</strong>通过虚拟化层的模拟，虚拟机在上层软件看来就是一个真实的机器，这个虚拟化层一般称为虚拟机监控机（Virtual Machine Monitor，VMM）。<strong>需要注意一点：在VMware的ESX虚拟化架构中VMM只是Hypervisor中一个进程，因此在这种场景下VMM不等于Hypervisor。</strong></li></ol><h2 id="什么是Hypervisor（VMM）"><a href="#什么是Hypervisor（VMM）" class="headerlink" title="什么是Hypervisor（VMM）"></a>什么是Hypervisor（VMM）</h2><blockquote><p>维基百科的定义如下：Hypervisor，又称虚拟机器监视器（英语：virtual machine monitor，缩写为 VMM），是用来建立与执行虚拟机器的软件、固件或硬件。</p></blockquote><p>通俗的讲：hypervisor是一种运行在物理服务器和操作系统之间的中间层软件，可以允许多个操作系统和应用共享一套基础物理硬件。可以将hypervisor看做是虚拟环境中的“元”操作系统，可以协调访问服务器上的所有物理设备和虚拟机，所以又称为虚拟机监视器（virtual machine monitor）。</p><p>hypervisor是所有虚拟化技术的核心，非中断的支持多工作负载迁移是hypervisor的基本功能。当服务器启动并执行hypervisor时，会给每一台虚拟机分配适量的内存，cpu，网络和磁盘资源，并且加载所有虚拟机的客户操作系统。当前主流的Hypervisor有微软的Hyper-V，VMware、Xen和KVM，但在电信云NFV领域主要用到的就是KVM，在后续虚拟化技术分类中，会专门讲解KVM的相关部署和优化，同时为加深大家对KVM的理解，也会讲 一点Xen的知识，毕竟在KVM广泛应用之前，云架构底层的虚拟化技术都是Xen。</p><p><strong>虚拟化和hypervisor到底什么关系？</strong></p><p>虚拟化就是通过某种方式隐藏底层物理硬件的过程，从而让多个操作系统可以透明地使用和共享它。这种架构的另一个更常见的名称是平台虚拟化。在典型的分层架构中，提供平台虚拟化的层称为 hypervisor （有时称为虚拟机管理程序 或 VMM）。来宾操作系统称为虚拟机（VM），因为对这些 VM 而言，硬件是专门针对它们虚拟化的。如下图示：</p><p><img src="https://i.loli.net/2019/05/03/5ccbdf268869a.jpg"></p><p>在上图中可以看到，hypervisor 是提供底层机器虚拟化的软件层（在某些情况下需要处理器支持）。并不是所有虚拟化解决方案都是一样的（详见Hypervisor分类部分）。客户机操作系统（GuestOS）对机器的底层资源的访问通过VMM来实现。hypervisor 面对的对象不是客户机中的进程，而是整个客户操作系统（GuestOS）。</p><p><strong>hypervisor主要可以划分为两大类：类型1和类型2，以及在此基础上衍生出来的混合类型和操作系统类型。</strong></p><p><strong>类型1这种hypervisor是可以直接运行在物理硬件之上的</strong>。如下图所示，也就是说它不需要宿主机操作系统（HostOS）的支持，本身就可以管理底层硬件的资源，其本质是在Hypervisor中嵌入了一个精简的Linux操作系统内核。Xen 和 VMWare 的 ESXi 都属于这个类型，这种虚拟化类型的模型如下图所示，其特点就是需要硬件的支持，转发性能强（因为少了HostOS这一层转发），VMM就是HostOS。</p><p><img src="https://i.loli.net/2019/05/03/5ccbdf4674cf0.jpg"></p><p><strong>类型2这种hypervisor运行在另一个操作系统（运行在物理硬件之上）中</strong>。如下图所示，也就是说这种类型的Hypervisor是部署在HostOS之上的，从HostOS角度来看，其上层的所有VM都对应Hypervisor这一个进程。从VM的角度来看，其访问底层硬件资源需要Hypervisor和HostOS共同配合完成。KVM、VirtualBox 和 VMWare Workstation 都属于这个类型。这种虚拟化类型的模型如下图所示，其特点就是比较灵活，比如支持虚拟机嵌套（嵌套意味着可以在虚拟机中再运行hypervisor），但是转发性能明显不如类型1。</p><p><img src="https://i.loli.net/2019/05/03/5ccbdf70cc6c3.jpg"></p><p>目前，随着转发性能提升需求和应用的微服务化架构需求，在类型2的基础上又演进出混合类型虚拟化和基于HostOS的操作系统虚拟化。</p><p><strong>混合虚拟化：通过在主机的操作系统中增加虚拟硬件管理模块，通过虚拟硬件管理模块来生成各个虚拟机。</strong>属于类型2虚拟化的一种增强模型。特点是相对于类型2虚拟化，没有冗余，性能高，可支持多种操作系统。但是，需要底层硬件支持虚拟化扩展功能。现阶段的KVM和Hyper-V都属于这种增强型类型2虚拟化技术。</p><p><img src="https://i.loli.net/2019/05/03/5ccbdfbf1fc4b.jpg"></p><p><strong>操作系统虚拟化：没有独立的hypervisor层。相反，主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。</strong>最重要的前提是：<strong>如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统(不过每个实例有各自的应用程序和用户账户)，其本质就是操作系统上面应用程序的一个进程，主要在应用的微服务化架构场景中使用。</strong>特点是：简单、易于实现，管理成本非常低。但是，隔离性差，多个虚拟化实例共享同一个操作系统。最典型就是目前炙手可热的容器技术Docker和Virtuozzo。</p><p><img src="https://i.loli.net/2019/05/03/5ccbdfdab15e6.jpg"></p><h2 id="虚拟化的特征和优势"><a href="#虚拟化的特征和优势" class="headerlink" title="虚拟化的特征和优势"></a>虚拟化的特征和优势</h2><p>从前面描述可知，虚拟化技术就是一个“大块的资源”逻辑分割成“具有独立功能的小块资源”，这个功能通过Hypervisor来实现。对于服务器领域而言，通过Hypervisor将一个物理服务器虚拟化成若干个小的逻辑服务器，每个逻辑服务器具有与物理服务器相同的功能，所有逻辑服务器的资源总和等于物理服务器的全部资源。</p><p>因此，运行在Hypervisor上的<strong>逻辑服务器</strong>，其本质就是由物理服务器上一个个文件组成。相对物理服务器，天生具备<strong>分区、隔离、封装</strong>和<strong>相对硬件独立</strong>四大特征。</p><p><img src="https://i.loli.net/2019/05/03/5ccbe0005eb06.jpg"></p><p><strong>1）分区：在单一物理服务器同时运行多个虚拟机。</strong>分区意味着虚拟化层为多个虚拟机划分服务器资源的能力；每个虚拟机可以同时运行一个单独的操作系统（相同或不同的操作系统），使您能够在一台服务器上运行多个应用程序。每个操作系统只能看到虚拟化层为其提供的“虚拟硬件”（虚拟网卡、CPU、内存等），以使它认为运行在自己的专用服务器上。</p><p><strong>2）隔离：在同一服务器虚拟机之间相互隔离。</strong>虚拟机是互相隔离的。例如：一个虚拟机的崩溃或故障（例如，操作系统故障、应用程序崩溃、驱动程序故障，等等）不会影响同一服务器上的其它虚拟机；一个虚拟机中的病毒、蠕虫等与其它虚拟机相隔离，就像每个虚拟机都位于单独的物理机器上一样。可以通过资源控制以提供性能隔离，比如：可以为每个虚拟机指定最小和最大资源使用量，以确保某个虚拟机不会占用所有的资源而使得同一系统中的其它虚拟机无资源可用；可以在单一机器上同时运行多个负载/应用程序/操作系统，而不会出现因为传统 x86 服务器体系结构的局限性发生DLL冲突等问题。</p><p><strong>3）封装：整个虚拟机都保存在文件中，可以通过移动文件的方式来迁移虚拟机。</strong>封装意味着将整个虚拟机（硬件配置、BIOS 配置、内存状态、磁盘状态、CPU 状态）储存在独立于物理硬件的一小组文件中。这样，只需复制几个文件就可以随时随地根据需要复制、保存和移动虚拟机。</p><p><strong>4）相对硬件独立：无需修改即可在任意服务器上运行（主要基于全虚技术的虚拟机，半虚技术的虚拟机只支持开源操作系统，如Linux）。</strong>因为虚拟机运行于虚拟化层之上，所以只能看到虚拟化层提供的虚拟硬件，无需关注物理服务器的情况。这样，虚拟机就可以在任何 x86 服务器（IBM、Dell、HP等）上运行而无需进行任何修改。这打破了操作系统和硬件以及应用程序和操作系统/硬件之间的约束。</p><p>物理资源在经过Hypervisor虚拟化后，在<strong>资源利用率、独立性、运行效率</strong>和<strong>安全性</strong>等方面与传统物理服务器相比均有不同的优势。</p><p><img src="https://i.loli.net/2019/05/03/5ccbe01b6cf2a.jpg"></p><p><strong>1）资源利用率：</strong>虚拟化前每台主机一个操作系统，系统的资源利用率低。虚拟化后，主机与操作系统不一一对应，按需分配使用，系统的资源利用率高。</p><p><strong>2）独立性：</strong>虚拟化前软硬件紧密结合，硬件成本高昂且不够灵活。虚拟化后，操作系统和硬件不相互依赖，虚拟机独立于硬件，能在任何硬件上运行。</p><p><strong>3）程序运行效率：</strong>虚拟化前同一台主机上同时运行多个程序容易产生冲突，运行效率较低。虚拟化后，操作系统和应用程序被封装成单一个体，不同个体间不冲突。同一台机器上运行多个程序，效率高。</p><p><strong>4）安全性：</strong>虚拟化前，故障影响范围大，安全性较差。虚拟化后，通过资源的池化，有强大的安全和故障隔离机制。</p><h2 id="虚拟化技术的发展"><a href="#虚拟化技术的发展" class="headerlink" title="虚拟化技术的发展"></a>虚拟化技术的发展</h2><p>最近几年，随着云计算技术广泛应用，虚拟化技术也被大家所关注。其实，虚拟化技术的出现要早于云计算技术约半个世纪。在上世纪60年代，虚拟化技术就已经在大型机上有所应用，在1999年小型机上出现逻辑分区的概念，这就是存储虚拟化的雏形。而到了2000年，在x86平台上VMware首先提出了平台虚拟化技术的概念，以及后续随着CPU速度越来越快，Intel和AMD分别在CPU指令架构中引入虚拟化指令，在服务器领域和数据中心范围内虚拟化技术得到的极大发展，从而催生了云计算技术的出现。可以说，<strong>虚拟化技术是云计算技术得以实现并推广落地的重要基石</strong>，同时，随着云计算技术的演进，虚拟化技术也同样在不断演进，从最早的计算虚拟化发展到目前的应用虚拟化，两者是一种相辅相成，螺旋式推进的关系。</p><p>云计算技术从诞生到当前，共经历了3个阶段，分别称为云计算1.0、云计算2.0和云计算3.0，在不同的阶段，虚拟化技术的表现形式和关注点也不相同，两者关系如下图所示：</p><p><img src="https://i.loli.net/2019/05/03/5ccbe03388332.jpg"></p><p><strong>在云计算1.0时代，主要是将传统IT硬件基础设施转换为虚拟化基础设施，来提升资源利用率。</strong>该阶段的关键特征体现为：<strong>通过计算虚拟化技术的引入</strong>，将企业IT应用与底层的基础设施彻底分离解耦，将多个企业IT应用实例及运行环境(客户机操作系统，GuestOS)复用在相同的物理服务器上，并通过虚拟化集群调度软件，将更多的IT应用复用在更少的服务器节点上，从而实现资源利用效率的提升。</p><p><strong>在云计算2.0时代，主要是向云租户提供池化资源服务和精细化自动管理，推动企业业务的云化演进。</strong>该阶段的关键特征体现为：<strong>不仅通过计算虚拟化完成CPU、内存、裸金属服务器等池化资源的集中管理和自动调度，同时引入存储虚拟化和网络虚拟化技术，实现数据中心内部存储资源和网络资源的池化集中管理和统一调度。</strong>面向内部和外部的租户，将原本需要通过数据中心管理员人工干预的基础设施资源复杂低效的申请、释放与配置过程，转变为一键式全自动化资源发放服务过程。这个阶段大幅提升了企业基础设施资源的快速敏捷发放能力，缩短了基础设施资源准备周期，实现资源的按需弹性供给。为企业核心业务走向敏捷，更好地应对瞬息万变的竞争与发展奠定了基础。云计算2.0阶段面向云租户的基础设施资源服务供给，可以是虚拟机形式，可以是容器(轻量化虚拟机)，也可以是物理机形式。该阶段的企业云化演进，暂时还不涉及基础设施层之上的IT应用与中间件、数据库软件架构的变化。</p><p><strong>在云计算3.0时代，面向应用开发者及管理维护者提供分布式微服务化应用架构和大数据智能化服务。</strong></p><p>该阶段的关键特征体现为：<strong>企业IT应用架构逐步开始去IOE化，依托开源增强、跨不同业务应用领域高度共享的数据库、中间件平台服务层以及功能更加轻量化解耦、数据与应用逻辑彻底分离的分布式无状态化架构</strong>，从而实现支撑企业业务敏捷化、智能化以及资源利用效率提升。</p><h2 id="数据中心内部虚拟化技术分类"><a href="#数据中心内部虚拟化技术分类" class="headerlink" title="数据中心内部虚拟化技术分类"></a>数据中心内部虚拟化技术分类</h2><p>目前，在数据中心内虚拟服务器、虚拟网络、虚拟存储、虚拟设备和其他“虚拟技术”等已对传统基础设施产生了逆袭。<strong>在上述云计算的三个阶段，使得虚拟化技术和云计算技术得到极大发展的关键就是2.0时代，主要的特征就是从计算虚拟化走向存储虚拟化和网络虚拟化。</strong></p><p><img src="https://i.loli.net/2019/05/03/5ccbe05131c70.jpg"></p><p>从支撑云计算按需、弹性分配资源，与硬件解耦的虚拟化技术的角度来看，云计算早期阶段主要聚焦在计算虚拟化领域。事实上，计算虚拟化技术早在IBM 370时代就已经在其大型机操作系统上诞生。技术原理是通过在OS与裸机硬件之间插入虚拟化层，来在裸机硬件指令系统之上仿真模拟出多个370大型机的“运行环境”，使得上层“误认为”自己运行在一个独占系统之上，实际上是由计算虚拟化引擎在多个虚拟机之间进行CPU分时调度，同时对内存、I/O、网络等访问也进行访问屏蔽。</p><p>后来，当x86平台演进成为在IT领域硬件平台的主流之后，VMware ESX、XEN、KVM等依托于单机OS的计算虚拟化技术才将IBM 370的虚拟化机制在x86服务器的硬件体系架构下实现，并且在单机/单服务器虚拟化的基础上引入了具备虚拟机动态迁移和HA调度能力的中小集群管理软件，比如：VMware的vCenter/vSphere、Citrix的XEN Center和华为的FusionSphere等，从而形成当前的计算虚拟化主体。</p><p><img src="https://i.loli.net/2019/05/03/5ccbe06505e42.jpg"></p><p>与此同时，作为数据信息持久化载体的存储已经逐步从服务器计算中剥离出来，与必不可少的CPU计算能力一样，在数据中心发挥着至关重要的作用。现在数据中心内部不再封闭，内部服务器互访和对外部互联网访问需求，使得存储和网络也同计算一样，成为数据中心IT基础设施不可或缺的“<strong>三大要素</strong>”。就数据中心端到端基础设施解决方案而言，不仅需要计算资源的按需分配、弹性伸缩、与硬件解耦的需求，对存储资源和网络资源需求同样如此，因此，存储虚拟化和网络虚拟化技术应运而生。</p><p>对于普通x86服务器来说，CPU和内存资源虚拟化后再将其以vCPU/vMemory的方式，按需供给用户/租户使用。计算虚拟化中仅存在资源池的“大分小”的问题。然而对于存储来说，由于硬盘的容量有限，客户/租户对数据容量的需求越来越大，因此必须对数据中心内多个分布式服务器存储资源，比如：服务器内的存储资源、外置SAN/NAS等进行“小聚大”的整合，组成<strong>存储资源池</strong>。</p><p>这个存储资源池，可能是单一厂家提供的同构资源池，也可以是被<strong>存储虚拟化层</strong>整合成为跨多厂家异构的统一资源池。各种存储资源池均能以统一的<strong>块存储、对象存储</strong>或者<strong>文件存储格式</strong>进行访问。数据存储虚拟化示意图如下所示：</p><p><img src="https://i.loli.net/2019/05/03/5ccbe07957b2d.jpg"></p><p>对于数据中心网络来说，网络对于业务应用，作为连接服务器节点的计算和存储资源是一种实实在在的资源需求。传统数据中心内部，网络交换功能都是在物理交换机和路由器设备上完成的，网络功能对上层业务应用而言仅仅体现为一个一个被通信链路连接起来的孤立的“盒子”，无法动态感知来自上层业务的网络功能需求，完全需要人工配置的方式来实现对业务层网络组网与安全隔离策略的需要。</p><p>在云时代多租户虚拟化的环境下，不同租户对于边缘的路由及网关设备的配置管理需求也存在极大的差异化，即使物理路由器和防火墙自身的多实例能力也无法满足云环境下租户数量的要求，如果采用与租户数量等量的路由器与防火墙设备，成本上无法接受。于是，伯克利大学的Nick Mckeown教授提出将网络自身的功能从专用封闭平台迁移到服务器通用x86平台上来，SDN概念从此诞生。</p><p>网络资源虚拟化后，服务器节点的应用VM连接差异化，就可由云操作系统来自动化地创建和销毁，并通过一次性建立起来的物理网络连接矩阵，进行任意两个网络端节点之间的虚拟通讯链路建立，以及必要的安全隔离保障，从而实现业务驱动的网络自动化管理配置，大幅度降低数据中心网络管理的复杂度。从资源利用率来看，任意两个虚拟网络节点之间的流量带宽，都需要通过物理网络来交换和承载，只要不超过物理网络的资源配额上限（一般建议物理网络按照无阻塞的CLOS模式来设计实施)，一旦虚拟节点被释放，其所对应的网络带宽占用也将被同步释放，因此也就相当于实现对物理网络资源的<strong>最大限度的“网络资源动态共享”</strong>。通俗点讲，网络虚拟化让多个盒子式的网络实体第一次以一个统一整合的“<strong>网络资源池</strong>”的形态，出现在业务应用层面前，同时与计算和存储资源之间，也有了统一协同机制。网络虚拟化示意图如下图所示：</p><p><img src="https://i.loli.net/2019/05/03/5ccbe090e8fd7.jpg"></p><p><strong>上面基础设施虚拟化技术的“三要素”是电信云领域需要重点关注的三个分类，属于云计算中IaaS服务部分的内容。</strong></p><p><strong><em>除此之外，还有基于PaaS和SaaS的桌面虚拟化技术，这部分内容因电信云领域目前不涉及，因此在本站的云计算分类中会有相关介绍，这里不再赘述。后续，会在NFV关键技术分类中按照计算虚拟化、存储虚拟化和网络虚拟化三大部分逐一介绍，并会重点KVM的部署和性能调优。</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DPDK技术奠定了NFV领域数据包转发性能提升的基础，那么软硬件解耦后，在通用服务器上实现各功能网元，资源层面的隔离和共生问题就需要虚拟化技术来解决。虚拟化使用软件的方法重新定义划分IT资源，可以实现IT资源的动态分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需求。
    
    </summary>
    
      <category term="NFV关键技术" scheme="https://kkutysllb.cn/categories/NFV%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="电信云" scheme="https://kkutysllb.cn/tags/%E7%94%B5%E4%BF%A1%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>2019-05-02-Linux系统命令-第七篇《磁盘和文件系统管理命令》</title>
    <link href="https://kkutysllb.cn/2019/05/02/2019-05-02-Linux%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4-%E7%AC%AC%E4%B8%83%E7%AF%87%E3%80%8A%E7%A3%81%E7%9B%98%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E3%80%8B/"/>
    <id>https://kkutysllb.cn/2019/05/02/2019-05-02-Linux系统命令-第七篇《磁盘和文件系统管理命令》/</id>
    <published>2019-05-02T12:27:07.000Z</published>
    <updated>2019-05-02T12:56:05.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="fdisk：磁盘分区工具"><a href="#fdisk：磁盘分区工具" class="headerlink" title="fdisk：磁盘分区工具"></a>fdisk：磁盘分区工具</h2><p>fdisk是Linux下常用的磁盘分区工具。受mbr分区表的限制，fdisk工具只能给小于2TB的磁盘划分分区。如果使用fdisk对大于2TB的磁盘进行分区，虽然可以分区，但其仅识别2TB的空间，所以磁盘容量若超过2TB，就要使用parted分区工具（后面会讲）进行分区。<a id="more"></a></p><p><strong>语法格式：fdisk [option] [device]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae26095c66.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示系统磁盘分区列表</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk -l</span></span><br><span class="line">Disk /dev/sda: 53.7 GB, 53687091200 bytes, 104857600 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0x000d2190</span><br><span class="line">Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048      821247      409600   83  Linux</span><br><span class="line">/dev/sda2          821248    17598463     8388608   82  Linux swap / Solaris</span><br><span class="line">/dev/sda3        17598464   104857599    43629568   83  Linux</span><br></pre></td></tr></table></figure><p>上述信息每列功能说明具体如下：</p><ul><li>Device：分区，这里有三个分区；</li><li>Boot：启动分区，用*表示的是启动分区；</li><li>Start：表示开始的柱面；</li><li>End：表示结束的柱面；</li><li>Blocks：block块数量；</li><li>Id：分区类型Id；</li><li>System：分区类型</li></ul><p><strong>2）模拟添加第二块磁盘</strong></p><p>#给C7 Server01再挂载一块20G的磁盘</p><p><img src="https://i.loli.net/2019/05/02/5ccae29766516.jpg"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启系统检查磁盘分区状态</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk -l</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新添加的磁盘为/devsdb，表示sata接口的第二块磁盘</span></span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 53.7 GB, 53687091200 bytes, 104857600 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0x000d2190</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048      821247      409600   83  Linux</span><br><span class="line">/dev/sda2          821248    17598463     8388608   82  Linux swap / Solaris</span><br><span class="line">/dev/sda3        17598464   104857599    43629568   83  Linux</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不想显示其他分区，还可以指定分区查看</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br></pre></td></tr></table></figure><p><strong>3）交互式分区实战</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前系统的分区设备信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ls -l /dev/sd*</span></span><br><span class="line">brw-rw---- 1 root disk 8,  0 May  2 09:41 /dev/sda</span><br><span class="line">brw-rw---- 1 root disk 8,  1 May  2 09:41 /dev/sda1</span><br><span class="line">brw-rw---- 1 root disk 8,  2 May  2 09:41 /dev/sda2</span><br><span class="line">brw-rw---- 1 root disk 8,  3 May  2 09:41 /dev/sda3</span><br><span class="line">brw-rw---- 1 root disk 8, 16 May  2 09:41 /dev/sdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对/dev/sdb进行交互式分区</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk /dev/sdb</span></span><br><span class="line">Welcome to fdisk (util-linux 2.23.2).</span><br><span class="line"></span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write <span class="built_in">command</span>.</span><br><span class="line"></span><br><span class="line">Device does not contain a recognized partition table</span><br><span class="line">Building a new DOS disklabel with disk identifier 0xc0a89c6e.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): m     <span class="comment"># 输入m，打印帮助信息</span></span><br><span class="line">Command action</span><br><span class="line">   a   toggle a bootable flag    <span class="comment"># 设置引导扇区</span></span><br><span class="line">   b   edit bsd disklabel     <span class="comment"># 编辑bsd卷标</span></span><br><span class="line">   c   toggle the dos compatibility flag   <span class="comment"># 设置dos兼容分区</span></span><br><span class="line">   d   delete a partition    <span class="comment"># 删除一个分区</span></span><br><span class="line">   g   create a new empty GPT partition table    <span class="comment"># 创建一个新的且为空的GPT分区表</span></span><br><span class="line">   G   create an IRIX (SGI) partition table   <span class="comment"># 创建一些IRIX分区表</span></span><br><span class="line">   l   list known partition types    <span class="comment"># 查看分区类型对应的编号列表</span></span><br><span class="line">   m   <span class="built_in">print</span> this menu   <span class="comment"># 打印帮助菜单</span></span><br><span class="line">   n   add a new partition   <span class="comment"># 新建一个分区</span></span><br><span class="line">   o   create a new empty DOS partition table    <span class="comment"># 创建一个新的空的DOS分区表</span></span><br><span class="line">   p   <span class="built_in">print</span> the partition table   <span class="comment"># 打印分区表</span></span><br><span class="line">   q   quit without saving changes    <span class="comment"># 退出且不保存更改</span></span><br><span class="line">   s   create a new empty Sun disklabel  <span class="comment"># 创建一个新的空的sun卷标</span></span><br><span class="line">   t   change a partition<span class="string">'s system id  # 更改分区系统的id</span></span><br><span class="line"><span class="string">   u   change display/entry units  # 改变/显示条目的单位</span></span><br><span class="line"><span class="string">   v   verify the partition table   # 验证分区表</span></span><br><span class="line"><span class="string">   w   write table to disk and exit  # 将操作写入分区表并退出程序</span></span><br><span class="line"><span class="string">   x   extra functionality (experts only)   # 额外的功能</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Command (m for help): n   # 输入n，创建一个分区</span></span><br><span class="line"><span class="string">Partition type:</span></span><br><span class="line"><span class="string">   p   primary (0 primary, 0 extended, 4 free)  # 创建主分区，编号1-4</span></span><br><span class="line"><span class="string">   e   extended   # 创建扩展分区</span></span><br><span class="line"><span class="string">Select (default p): p   # 输入p，创建主分区</span></span><br><span class="line"><span class="string">Partition number (1-4, default 1): 1  # 输入1，设置第一个主分区编号为1</span></span><br><span class="line"><span class="string">First sector (2048-41943039, default 2048):   # 直接回车，默认采用2048作为起始柱面</span></span><br><span class="line"><span class="string">Using default value 2048</span></span><br><span class="line"><span class="string">Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): +5G     # 设置结束柱面，一般情况下如果整个磁盘采用一个分区，这里就直接回车就行，否则，采用+size的方式进行分区大小设置，我们这里给第一个分区设置5G的空间    </span></span><br><span class="line"><span class="string">Partition 1 of type Linux and of size 5 GiB is set</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Command (m for help): p   # 输入p，打印刚创建的分区信息</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span></span><br><span class="line"><span class="string">Units = sectors of 1 * 512 = 512 bytes</span></span><br><span class="line"><span class="string">Sector size (logical/physical): 512 bytes / 512 bytes</span></span><br><span class="line"><span class="string">I/O size (minimum/optimal): 512 bytes / 512 bytes</span></span><br><span class="line"><span class="string">Disk label type: dos</span></span><br><span class="line"><span class="string">Disk identifier: 0xc0a89c6e</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Device Boot      Start         End      Blocks   Id  System</span></span><br><span class="line"><span class="string">/dev/sdb1            2048    10487807     5242880   83  Linux</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Command (m for help):  # 重复上述步骤再次创建三个主分区，大家自己练习，注意全部完成后要按w保存，否则分区信息丢失</span></span><br><span class="line"><span class="string">。。。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 打印最终的分区信息</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@C7-Server01 ~]# fdisk -l /dev/sdb</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span></span><br><span class="line"><span class="string">Units = sectors of 1 * 512 = 512 bytes</span></span><br><span class="line"><span class="string">Sector size (logical/physical): 512 bytes / 512 bytes</span></span><br><span class="line"><span class="string">I/O size (minimum/optimal): 512 bytes / 512 bytes</span></span><br><span class="line"><span class="string">Disk label type: dos</span></span><br><span class="line"><span class="string">Disk identifier: 0xc0a89c6e</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Device Boot      Start         End      Blocks   Id  System</span></span><br><span class="line"><span class="string">/dev/sdb1            2048    10487807     5242880   83  Linux</span></span><br><span class="line"><span class="string">/dev/sdb2        10487808    20973567     5242880   83  Linux</span></span><br><span class="line"><span class="string">/dev/sdb3        20973568    31459327     5242880   83  Linux</span></span><br><span class="line"><span class="string">/dev/sdb4        31459328    41943039     5241856   83  Linux</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 不重启情况下通知内核新的分区表已生效</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@C7-Server01 ~]# partprobe /dev/sdb</span></span><br></pre></td></tr></table></figure><p><strong>需要注意一点：用交互指令d删除分区时要小心，要注意分区的序号，如果删除了扩展分区，那么扩展分区之下的逻辑分区都会删除，所以操作时一定要小心。如果不小心操作错了，直接使用交互指令q不保存退出，这样先前的操作就会无效。如果输入w（保存指令）则会保存所有修改。</strong></p><p><strong>4）非交互式分区</strong></p><p>上面的示例是交互式分区，有时需要在脚本中自动执行分区，这时需要非交互式分区。如果使用fdisk分区工具来完成，可以使用如下两种办法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先备份/dev/sdb分区表信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/sdb of=sdb-partb.info bs=1 count=512</span></span><br><span class="line">512+0 records <span class="keyword">in</span></span><br><span class="line">512+0 records out</span><br><span class="line">512 bytes (512 B) copied, 0.00159899 s, 320 kB/s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后清除分区数据</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/zero of=/dev/sdb bs=1 count=512</span></span><br><span class="line">512+0 records <span class="keyword">in</span></span><br><span class="line">512+0 records out</span><br><span class="line">512 bytes (512 B) copied, 0.0017926 s, 286 kB/s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看/dev/sdb分区信息，确认是否被清除</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法一：使用echo指令模拟交互式分区输入过程，自动执行分区</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此方法需要注意最后一次分区时不要输入+size大小，直接回车即可（虚拟机虚拟磁盘原因，在物理机上无此限制）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 脚本中p就是指主分区，如果要分扩展分区，将p改为m</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo -e "n\np\n1\n\n+5G\nw\n" | fdisk /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo -e "n\np\n2\n\n+5G\nw\n" | fdisk /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo -e "n\np\n3\n\n+5G\nw\n" | fdisk /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># echo -e "n\np\n4\n\n\nw\n" | fdisk /dev/sdb</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分区信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0xd0b6c715</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048    10487807     5242880   83  Linux</span><br><span class="line">/dev/sdb2        10487808    20973567     5242880   83  Linux</span><br><span class="line">/dev/sdb3        20973568    31459327     5242880   83  Linux</span><br><span class="line">/dev/sdb4        31459328    41943039     5241856   83  Linux</span><br></pre></td></tr></table></figure><p><strong>方法二：也是模拟交互式分区的过程，将输入的交互式指令写入一个文本文件，然后通过标准输入的方式传递给fdisk /dev/sdb指令，其中交互式指令中回车在文本中用换行替代。与上面的实现方式类似，请大家自行练习。</strong></p><h2 id="partprobe：更新内核的硬盘分区表信息"><a href="#partprobe：更新内核的硬盘分区表信息" class="headerlink" title="partprobe：更新内核的硬盘分区表信息"></a>partprobe：更新内核的硬盘分区表信息</h2><p>partprobe命令用于在硬盘分区发生改变时，更新Linux内核中的硬盘分区表数据。有时在使用fdisk、part命令对硬盘进行分区后，会发现找不到新分区，此时需要重启系统才能使修改生效，但使用partprobe可以不重启系统就让修改的分区表生效。</p><p><strong>语法格式：partprobe [option]</strong> </p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae336aa7df.jpg"></p><p><strong>【使用示例】</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新分区表信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最好加上具体的磁盘，否则可能会报错，那就只能重启系统</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># partprobe /dev/sdb</span></span><br></pre></td></tr></table></figure><h2 id="parted：磁盘分区工具"><a href="#parted：磁盘分区工具" class="headerlink" title="parted：磁盘分区工具"></a>parted：磁盘分区工具</h2><p>对于小于2TB的磁盘可以用fdisk和parted命令进行分区，这种情况一般采用fdisk命令，但对于大于2TB的磁盘则只能用parted分区，且需要将磁盘转换为GPT格式。</p><p><strong>语法格式：parted [option] [device]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae373158e0.jpg"></p><p><strong>【分区命令】</strong></p><p><strong>通过parted -h或直接parted进入交互模式后，输入h查看帮助信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># parted -h</span></span><br><span class="line">Usage: parted [OPTION]... [DEVICE [COMMAND [PARAMETERS]...]...]</span><br><span class="line">Apply COMMANDs with PARAMETERS to DEVICE.  If no COMMAND(s) are given, run <span class="keyword">in</span></span><br><span class="line">interactive mode.</span><br><span class="line">OPTIONs:</span><br><span class="line">-h, --<span class="built_in">help</span>                      displays this <span class="built_in">help</span> message</span><br><span class="line">-l, --list                      lists partition layout on all block devices</span><br><span class="line">-m, --machine                   displays machine parseable output</span><br><span class="line">-s, --script                    never prompts <span class="keyword">for</span> user intervention</span><br><span class="line">-v, --version                   displays the version</span><br><span class="line">-a, --align=[none|cyl|min|opt]  alignment <span class="keyword">for</span> new partitions</span><br><span class="line">COMMANDs:</span><br><span class="line">align-check TYPE N                        check partition N <span class="keyword">for</span> TYPE(min|opt)</span><br><span class="line">alignment</span><br><span class="line"><span class="built_in">help</span> [COMMAND]                           <span class="built_in">print</span> general <span class="built_in">help</span>, or <span class="built_in">help</span> on</span><br><span class="line">COMMAND</span><br><span class="line">mklabel,mktable LABEL-TYPE               create a new disklabel (partition</span><br><span class="line">table)</span><br><span class="line">mkpart PART-TYPE [FS-TYPE] START END     make a partition</span><br><span class="line">name NUMBER NAME                         name partition NUMBER as NAME</span><br><span class="line"><span class="built_in">print</span> [devices|free|list,all|NUMBER]     display the partition table,</span><br><span class="line">available devices, free space, all found partitions, or a particular</span><br><span class="line">partition</span><br><span class="line">quit                                     <span class="built_in">exit</span> program</span><br><span class="line">rescue START END                         rescue a lost partition near START</span><br><span class="line">and END</span><br><span class="line">resizepart NUMBER END                    resize partition NUMBER</span><br><span class="line">rm NUMBER                                delete partition NUMBER</span><br><span class="line">select DEVICE                            choose the device to edit</span><br><span class="line">disk_set FLAG STATE                      change the FLAG on selected device</span><br><span class="line">disk_toggle [FLAG]                       toggle the state of FLAG on selected</span><br><span class="line">device</span><br><span class="line"><span class="built_in">set</span> NUMBER FLAG STATE                    change the FLAG on partition NUMBER</span><br><span class="line">toggle [NUMBER [FLAG]]                   toggle the state of FLAG on partition</span><br><span class="line">NUMBER</span><br><span class="line">unit UNIT                                <span class="built_in">set</span> the default unit to UNIT</span><br><span class="line">version                                  display the version number and</span><br><span class="line">copyright information of GNU Parted</span><br><span class="line">Report bugs to bug-parted@gnu.org</span><br></pre></td></tr></table></figure><p><strong>【使用示例】</strong></p><p><strong>1）显示分区的情况</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># parted -l</span></span><br><span class="line">Model: ATA VMware Virtual S (scsi)</span><br><span class="line">Disk /dev/sda: 53.7GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line">Disk Flags: </span><br><span class="line">Number  Start   End     Size    Type     File system     Flags</span><br><span class="line">1      1049kB  420MB   419MB   primary  xfs             boot</span><br><span class="line">2      420MB   9010MB  8590MB  primary  linux-swap(v1)</span><br><span class="line">3      9010MB  53.7GB  44.7GB  primary  xfs</span><br><span class="line">Model: ATA VMware Virtual S (scsi)</span><br><span class="line">Disk /dev/sdb: 21.5GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line">Disk Flags: </span><br><span class="line">Number  Start   End     Size    Type     File system  Flags</span><br><span class="line">1      1049kB  5370MB  5369MB  primary</span><br><span class="line">2      5370MB  10.7GB  5369MB  primary</span><br><span class="line">3      10.7GB  16.1GB  5369MB  primary</span><br><span class="line">4      16.1GB  21.5GB  5368MB  primary</span><br></pre></td></tr></table></figure><p>上述信息显示系统两块磁盘的分区信息，包括大小，起始，终止柱面，类型，文件系统类型等。磁盘/dev/sda为系统盘，有3个主分区，其中2个位xfs文件系统，1个位swap分区。磁盘/dev/sdb为刚添加的数据盘，有4个主分区，每个大小5G，因为还没有格式化，所以没有文件系统格式。</p><p><strong>2）通过给虚拟机再挂载一块100G的磁盘/dev/sdc，来模拟2TB磁盘用parted分区工具进行分区</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae3c2d6d94.jpg"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过交互式方式完成分区</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># parted /dev/sdc</span></span><br><span class="line">GNU Parted 3.1</span><br><span class="line">Using /dev/sdc</span><br><span class="line">Welcome to GNU Parted! Type <span class="string">'help'</span> to view a list of commands.</span><br><span class="line">(parted) mklabel gpt           <span class="comment"># 为/dev/sdc磁盘创建GPT分区，大于2T的磁盘必须进行这一步</span></span><br><span class="line">(parted) mkpart primary 0 40G  <span class="comment"># 创建主分区，大小为40G</span></span><br><span class="line">Warning: The resulting partition is not properly aligned <span class="keyword">for</span> best performance.</span><br><span class="line">Ignore/Cancel? Ignore            <span class="comment"># 输入Ignore，忽略告警信息</span></span><br><span class="line">(parted) p                 <span class="comment"># 输入p，显示分区表信息                                               </span></span><br><span class="line">Model: ATA VMware Virtual S (scsi)</span><br><span class="line">Disk /dev/sdc: 107GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start   End     Size    File system  Name     Flags</span><br><span class="line"> 1      17.4kB  40.0GB  40.0GB               primary                  <span class="comment"># 第一个主分区已经创建完毕</span></span><br><span class="line">(parted) mkpart logical 40G 50G    <span class="comment"># 创建第一个逻辑分区，大小为10G</span></span><br><span class="line">(parted) p                          <span class="comment">#  打印分区表信息                                      </span></span><br><span class="line">Model: ATA VMware Virtual S (scsi)</span><br><span class="line">Disk /dev/sdc: 107GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start   End     Size    File system  Name     Flags</span><br><span class="line"> 1      17.4kB  40.0GB  40.0GB               primary</span><br><span class="line"> 2      40.0GB  50.0GB  10.0GB               logical                        <span class="comment"># 第一个逻辑分区创建完毕</span></span><br><span class="line">(parted) mkpart logical 50G 70G    <span class="comment"># 创建第二个逻辑分区，大小为20G</span></span><br><span class="line">(parted) mkpart logical 70G 100G   <span class="comment"># 创建第三个逻辑分区，大小为30G                                       </span></span><br><span class="line">(parted) p                       <span class="comment"># 打印分区表信息                                         </span></span><br><span class="line">Model: ATA VMware Virtual S (scsi)</span><br><span class="line">Disk /dev/sdc: 107GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line">Disk Flags: </span><br><span class="line"></span><br><span class="line">Number  Start   End     Size    File system  Name     Flags</span><br><span class="line"> 1      17.4kB  40.0GB  40.0GB               primary</span><br><span class="line"> 2      40.0GB  50.0GB  10.0GB               logical</span><br><span class="line"> 3      50.0GB  70.0GB  20.0GB               logical</span><br><span class="line"> 4      70.0GB  100GB   30.0GB               logical</span><br><span class="line">(parted) quit                                          <span class="comment"># 退出                   </span></span><br><span class="line">Information: You may need to update /etc/fstab.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统设备信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h /dev/sd*</span></span><br><span class="line">brw-rw---- 1 root disk 8,  0 May  2 11:51 /dev/sda</span><br><span class="line">brw-rw---- 1 root disk 8,  1 May  2 11:51 /dev/sda1</span><br><span class="line">brw-rw---- 1 root disk 8,  2 May  2 11:51 /dev/sda2</span><br><span class="line">brw-rw---- 1 root disk 8,  3 May  2 11:51 /dev/sda3</span><br><span class="line">brw-rw---- 1 root disk 8, 16 May  2 11:51 /dev/sdb</span><br><span class="line">brw-rw---- 1 root disk 8, 17 May  2 11:51 /dev/sdb1</span><br><span class="line">brw-rw---- 1 root disk 8, 18 May  2 11:51 /dev/sdb2</span><br><span class="line">brw-rw---- 1 root disk 8, 19 May  2 11:51 /dev/sdb3</span><br><span class="line">brw-rw---- 1 root disk 8, 20 May  2 11:51 /dev/sdb4</span><br><span class="line">brw-rw---- 1 root disk 8, 32 May  2 12:01 /dev/sdc</span><br><span class="line">brw-rw---- 1 root disk 8, 33 May  2 12:01 /dev/sdc1</span><br><span class="line">brw-rw---- 1 root disk 8, 34 May  2 12:01 /dev/sdc2</span><br><span class="line">brw-rw---- 1 root disk 8, 35 May  2 12:01 /dev/sdc3</span><br><span class="line">brw-rw---- 1 root disk 8, 36 May  2 12:01 /dev/sdc4</span><br></pre></td></tr></table></figure><p><strong><em>用parted磁盘分区工具非交互式创建分区的方法类似fdisk，唯一区别就是将交互式下输入的命令作为参数传递parted工具，比如：将交互执行的命令直接放在parted /dev/sdb后面就实现非交互分区了。整体上实现其实比fdisk工具简单，请大家自行练习。</em></strong> </p><h2 id="mkfs：创建Linux文件系统-（格式化）"><a href="#mkfs：创建Linux文件系统-（格式化）" class="headerlink" title="mkfs：创建Linux文件系统 （格式化）"></a>mkfs：创建Linux文件系统 （格式化）</h2><p>mkfs命令用于在指定的设备（或硬盘分区等）上格式化并创建文件系统，fdisk和parted等分区工具相当于建房的人，把房子（硬盘），分成几居室（分区），mkfs就相当于对不同的居室装修（创建文件系统）了，只有装修好的房子（有文件系统）才能入住，分区也是一样，只有格式化创建文件系统（存取数据的机制）后，才能用来存取数据。</p><p><strong>mkfs只是一个前端命令，它通过-t参数指定文件系统类型后会调用相应的命令mkfs.fstype。因此，也可以直接使用mkfs.ext4、mkfs.xfs这类命令创建相应的文件系统。</strong></p><p><strong>语法格式：mkfs [option] [filesys]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae3fee7aba.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>通过-t选项创建xfs文件系统和ext4文件系统</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建/dev/sdb1分区的文件系统为xfs</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mkfs -t xfs /dev/sdb1</span></span><br><span class="line">meta-data=/dev/sdb1              isize=512    agcount=4, agsize=327680 blks</span><br><span class="line">=                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">=                       crc=1        finobt=0, sparse=0</span><br><span class="line">data     =                       bsize=4096   blocks=1310720, imaxpct=25</span><br><span class="line">=                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br><span class="line"><span class="built_in">log</span>      =internal <span class="built_in">log</span>           bsize=4096   blocks=2560, version=2</span><br><span class="line">=                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br></pre></td></tr></table></figure><p><strong><em>确认是否创建成功</em></strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae42a1b479.jpg"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用mkfs.xfs创建/dev/sdb2的文件系统为xfs</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mkfs.xfs /dev/sdb2</span></span><br><span class="line">meta-data=/dev/sdb2              isize=512    agcount=4, agsize=327680 blks</span><br><span class="line">=                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">=                       crc=1        finobt=0, sparse=0</span><br><span class="line">data     =                       bsize=4096   blocks=1310720, imaxpct=25</span><br><span class="line">=                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br><span class="line"><span class="built_in">log</span>      =internal <span class="built_in">log</span>           bsize=4096   blocks=2560, version=2</span><br><span class="line">=                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br></pre></td></tr></table></figure><p><strong><em>再次确认</em></strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae4502e412.jpg"></p><p><strong>创建ext4文件系统的方法类似，请大家自行练习。</strong> </p><h2 id="dumpe2fs：导出ext2-ext3-ext4文件系统信息"><a href="#dumpe2fs：导出ext2-ext3-ext4文件系统信息" class="headerlink" title="dumpe2fs：导出ext2/ext3/ext4文件系统信息"></a>dumpe2fs：导出ext2/ext3/ext4文件系统信息</h2><p>dumpe2fs命令用于导出ext2/ext3/ext4文件系统内部的相关信息，例如：文件系统的组成包含超级快、块组、inode、block等信息。<strong>如果要导出xfs文件系统的信息，需要使用xfs_info指令</strong>。</p><p><strong>语法格式：dumpe2fs [option] [device]</strong></p><p><strong>重要参数选项</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae470c6349.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）查看分区文件系统的inode信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建/dev/sdb3分区为ext4文件系统格式</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mkfs.ext4 /dev/sdb3</span></span><br><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS <span class="built_in">type</span>: Linux</span><br><span class="line">Block size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Fragment size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Stride=0 blocks, Stripe width=0 blocks</span><br><span class="line">327680 inodes, 1310720 blocks</span><br><span class="line">65536 blocks (5.00%) reserved <span class="keyword">for</span> the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=1342177280</span><br><span class="line">40 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736</span><br><span class="line"></span><br><span class="line">Allocating group tables: <span class="keyword">done</span>                            </span><br><span class="line">Writing inode tables: <span class="keyword">done</span>                            </span><br><span class="line">Creating journal (32768 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出/dev/sdb3分区的中inode相关信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dumpe2fs /dev/sdb3 | egrep -i "inode size|inode count"</span></span><br><span class="line">dumpe2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Inode count:              327680</span><br><span class="line">Inode size:          256</span><br></pre></td></tr></table></figure><p><strong>2）在xfs文件系统下，使用xfs_info指令查看/dev/sdb1的inode信息和block信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先需要个/dev/sdb1分区设置一个挂载点，然后使用xfs_info + 挂载点的方式进行查看</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount /dev/sdb1 ~/mydata/</span></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># xfs_info ~/mydata/</span></span><br><span class="line">meta-data=/dev/sdb1              isize=512    agcount=4, agsize=327680 blks</span><br><span class="line">=                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">=                       crc=1        finobt=0 spinodes=0</span><br><span class="line">data     =                       bsize=4096   blocks=1310720, imaxpct=25</span><br><span class="line">=                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br><span class="line"><span class="built_in">log</span>      =internal               bsize=4096   blocks=2560, version=2</span><br><span class="line">=                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br></pre></td></tr></table></figure><h2 id="fsck：检查并修复Linux文件系统"><a href="#fsck：检查并修复Linux文件系统" class="headerlink" title="fsck：检查并修复Linux文件系统"></a>fsck：检查并修复Linux文件系统</h2><p>fsck命令用于检查并修复文件系统中的错误，即针对有问题的系统或磁盘进行修复，类似的命令还有e2fsck命令。有关fsck的使用需要特别注意的是：1）文件系统必须是卸载状态，否则可能会出现故障。2）不要对正常的分区使用fsck，在不加参数的情况下，fsck会根据/etc/fstab进行文件系统检查，这相当于fsck-As参数的功能。</p><p><strong>注意：必须卸载文件系统后才能对其进行检查，否则可能会出现错误。平时没有必要使用这个命令检查磁盘，只有当系统开机显示磁盘错误时，才需要执行。</strong></p><p><strong>语法格式：fsck [option] [filesys]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae4da09a97.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）系统开机通过fsck自检</strong></p><p>Linux在开机过程中系统会自动调用fsck命令对需要自检的磁盘进行自检，如下图：</p><p><img src="https://i.loli.net/2019/05/02/5ccae4f632933.jpg"></p><p>这是因为系统开机过程中会优先读取/etc/fstab文件，当最后一列设置为1或2时，这个磁盘在开机时就会调用fsck进行自检，fstab的文件（man fstab看帮助）信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># cat /etc/fstab </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /etc/fstab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Created by anaconda on Sun Apr  7 20:32:53 2019</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Accessible filesystems, by reference, are maintained under '/dev/disk'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">UUID=0887567f-1df6-425f-ba3d-ce58584279e0 /                       xfs     defaults        0 0</span><br><span class="line">UUID=26954b3f-dd29-4a25-85ba-471cdbbf82df /boot                   xfs     defaults        0 0</span><br><span class="line">UUID=1f9ad06d-860c-4166-b142-6b633ee82851 swap                    swap    defaults        0 0</span><br></pre></td></tr></table></figure><p><strong>在CentOS6系统中，系统分区的根分区最后一列一般是1，boot分区最后一列是2，其余是0。但是在CentOS7系统中，为了不影响系统启动，把系统分区最后1列均设为0，即开机不自检。</strong></p><p><strong>需要提醒一下：有时我们自己增加硬盘规划分区，一般最后一列都设置为0，即开机过程中不对磁盘检查，否则，一旦自定义挂载的磁盘有问题，会影响系统启动。 如果真有问题，可以在启动系统后人为进行检查。</strong></p><p><strong>2）Linux断电后重启故障修复</strong></p><p>当Linux系统遭遇突然断电等非正常关机操作时，很容易导致文件系统数据损坏，造成系统不能重新启动，此时，屏幕出现的提示可能是如下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* AN error occurred during the file system check</span><br><span class="line">*** xxx</span><br><span class="line">*** xxx</span><br><span class="line">Give root password <span class="keyword">for</span> maintenance</span><br><span class="line">(or <span class="built_in">type</span> Control-D to <span class="built_in">continue</span>):</span><br></pre></td></tr></table></figure><p>此时根据系统提示输入root用户的密码，注意而不是直接按Control-D继续，会再重启。</p><p>当输入正确的密码之后，正常会出现下面的提示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(Repair filesystem) 1 <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>此时就可以输入fsck或者fsck-A对磁盘进行修复检查，执行后可能出现一堆询问，按yes即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(Repair filesystem) 1 <span class="comment"># fsck -A #&lt;==可能会等待一段时间或fsck。</span></span><br><span class="line">(Repair filesystem) 2 <span class="comment"># #&lt;==修复完毕会返回到这个提示符，此时就可以试着重启系统看故障是否修复了。</span></span><br></pre></td></tr></table></figure><p><strong>除了按照开机的提示进行修复外，也可以利用系统盘进入救援模式或单用户模式对系统故障进行修复。千万不要在开机正常工作的情况下执行fsck来检查磁盘，因为这样有可能会导致正常的磁盘发生故障。</strong></p><h2 id="mount：挂载文件系统"><a href="#mount：挂载文件系统" class="headerlink" title="mount：挂载文件系统"></a>mount：挂载文件系统</h2><p>mount命令可以将指定的文件系统挂载到指定目录（挂载点），在Linux系统下必须先挂载所有的设备，然后才能被访问，挂载其实就是为要访问的设置开个门（开门才能访问）。挂载的目录必须事先存在且最好为空，如果目录不为空，那么挂载设备后会掩盖以前的目录内容，但原目录下的内容不会受损，所以，如果卸载了相应的设备，那么此前的目录内容又可以访问了。</p><p><strong>语法格式：mount [option] [device] [dir]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae591533e9.jpg"></p><p>其中，-o选项后接的挂载参数如下：</p><p><img src="https://i.loli.net/2019/05/02/5ccae5a7e7b0e.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）显示系统已挂载的信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不加参数或加-l选项</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount</span></span><br><span class="line">sysfs on /sys <span class="built_in">type</span> sysfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">proc on /proc <span class="built_in">type</span> proc (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">devtmpfs on /dev <span class="built_in">type</span> devtmpfs (rw,nosuid,size=3984384k,nr_inodes=996096,mode=755)</span><br><span class="line">securityfs on /sys/kernel/security <span class="built_in">type</span> securityfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">tmpfs on /dev/shm <span class="built_in">type</span> tmpfs (rw,nosuid,nodev)</span><br><span class="line">devpts on /dev/pts <span class="built_in">type</span> devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)</span><br><span class="line">tmpfs on /run <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,mode=755)</span><br><span class="line">tmpfs on /sys/fs/cgroup <span class="built_in">type</span> tmpfs (ro,nosuid,nodev,noexec,mode=755)</span><br><span class="line">cgroup on /sys/fs/cgroup/systemd <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)</span><br><span class="line">pstore on /sys/fs/pstore <span class="built_in">type</span> pstore (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls,net_prio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/pids <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu,cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">configfs on /sys/kernel/config <span class="built_in">type</span> configfs (rw,relatime)</span><br><span class="line">/dev/sda3 on / <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">debugfs on /sys/kernel/debug <span class="built_in">type</span> debugfs (rw,relatime)</span><br><span class="line">hugetlbfs on /dev/hugepages <span class="built_in">type</span> hugetlbfs (rw,relatime)</span><br><span class="line">systemd-1 on /proc/sys/fs/binfmt_misc <span class="built_in">type</span> autofs (rw,relatime,fd=32,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=24337)</span><br><span class="line">mqueue on /dev/mqueue <span class="built_in">type</span> mqueue (rw,relatime)</span><br><span class="line">/dev/sda1 on /boot <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/user/0 <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,relatime,size=799032k,mode=700)</span><br><span class="line">/dev/sdb1 on /root/mydata <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount -l</span></span><br><span class="line">sysfs on /sys <span class="built_in">type</span> sysfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">proc on /proc <span class="built_in">type</span> proc (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">devtmpfs on /dev <span class="built_in">type</span> devtmpfs (rw,nosuid,size=3984384k,nr_inodes=996096,mode=755)</span><br><span class="line">securityfs on /sys/kernel/security <span class="built_in">type</span> securityfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">tmpfs on /dev/shm <span class="built_in">type</span> tmpfs (rw,nosuid,nodev)</span><br><span class="line">devpts on /dev/pts <span class="built_in">type</span> devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)</span><br><span class="line">tmpfs on /run <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,mode=755)</span><br><span class="line">tmpfs on /sys/fs/cgroup <span class="built_in">type</span> tmpfs (ro,nosuid,nodev,noexec,mode=755)</span><br><span class="line">cgroup on /sys/fs/cgroup/systemd <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)</span><br><span class="line">pstore on /sys/fs/pstore <span class="built_in">type</span> pstore (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls,net_prio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/pids <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu,cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">configfs on /sys/kernel/config <span class="built_in">type</span> configfs (rw,relatime)</span><br><span class="line">/dev/sda3 on / <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">debugfs on /sys/kernel/debug <span class="built_in">type</span> debugfs (rw,relatime)</span><br><span class="line">hugetlbfs on /dev/hugepages <span class="built_in">type</span> hugetlbfs (rw,relatime)</span><br><span class="line">systemd-1 on /proc/sys/fs/binfmt_misc <span class="built_in">type</span> autofs (rw,relatime,fd=32,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=24337)</span><br><span class="line">mqueue on /dev/mqueue <span class="built_in">type</span> mqueue (rw,relatime)</span><br><span class="line">/dev/sda1 on /boot <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/user/0 <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,relatime,size=799032k,mode=700)</span><br><span class="line">/dev/sdb1 on /root/mydata <span class="built_in">type</span> xfs (rw,relatime,attr2,inode64,noquota)</span><br></pre></td></tr></table></figure><p><strong>2）对系统的光驱进行挂载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不使用-t选项指定类型为 iso9660，但mount命令可以自动识别</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount /dev/cdrom /mnt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提示为只读挂载</span></span><br><span class="line"></span><br><span class="line">mount: /dev/sr0 is write-protected, mounting <span class="built_in">read</span>-only</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看/dev/cdrom文件，发现设备cdrom是sr0的一个软链接</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h /dev/cdrom</span></span><br><span class="line">lrwxrwxrwx 1 root root 3 May  2 18:10 /dev/cdrom -&gt; sr0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看是否挂载</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        42G  2.6G   40G   7% /</span><br><span class="line">devtmpfs        3.8G     0  3.8G   0% /dev</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs           3.9G   12M  3.8G   1% /run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       397M  162M  236M  41% /boot</span><br><span class="line">tmpfs           781M     0  781M   0% /run/user/0</span><br><span class="line">/dev/sdb1       5.0G   33M  5.0G   1% /root/mydata</span><br><span class="line">/dev/sr0        4.3G  4.3G     0 100% /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看挂载点内容</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h /mnt</span></span><br><span class="line">total 686K</span><br><span class="line">-rw-rw-r-- 1 root root   14 Nov 26 00:01 CentOS_BuildTag</span><br><span class="line">drwxr-xr-x 3 root root 2.0K Nov 26 00:20 EFI</span><br><span class="line">-rw-rw-r-- 1 root root  227 Aug 30  2017 EULA</span><br><span class="line">-rw-rw-r-- 1 root root  18K Dec 10  2015 GPL</span><br><span class="line">drwxr-xr-x 3 root root 2.0K Nov 26 00:21 images</span><br><span class="line">drwxr-xr-x 2 root root 2.0K Nov 26 00:20 isolinux</span><br><span class="line">drwxr-xr-x 2 root root 2.0K Nov 26 00:20 LiveOS</span><br><span class="line">drwxrwxr-x 2 root root 648K Nov 26 07:52 Packages</span><br><span class="line">drwxrwxr-x 2 root root 4.0K Nov 26 07:53 repodata</span><br><span class="line">-rw-rw-r-- 1 root root 1.7K Dec 10  2015 RPM-GPG-KEY-CentOS-7</span><br><span class="line">-rw-rw-r-- 1 root root 1.7K Dec 10  2015 RPM-GPG-KEY-CentOS-Testing-7</span><br><span class="line">-r--r--r-- 1 root root 2.9K Nov 26 07:54 TRANS.TBL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载挂载点</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># umount /mnt/</span></span><br></pre></td></tr></table></figure><p>在实际中，我们经常会挂载NFS（网络文件系统），这就要用到mount命令的-o选项，来保证性能和安全性。具体的说明，请参见本站Linux常用工具分类中的NFS文件系统一文。</p><h2 id="umount：卸载文件系统"><a href="#umount：卸载文件系统" class="headerlink" title="umount：卸载文件系统"></a>umount：卸载文件系统</h2><p>umount命令可以卸载已经挂载的文件系统，如上文中示例2的卸载挂载点。<strong>umount卸载可以接挂载点目录，也可以接设备文件。</strong></p><p><strong>语法格式：umount [option] [dir|device]</strong></p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae65d205b3.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）卸载光驱挂载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先挂载光驱</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount -t iso9660 /dev/cdrom /mnt</span></span><br><span class="line">mount: /dev/sr0 is write-protected, mounting <span class="built_in">read</span>-only</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统挂载信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        42G  2.6G   40G   7% /</span><br><span class="line">devtmpfs        3.8G     0  3.8G   0% /dev</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs           3.9G   12M  3.8G   1% /run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       397M  162M  236M  41% /boot</span><br><span class="line">tmpfs           781M     0  781M   0% /run/user/0</span><br><span class="line">/dev/sdb1       5.0G   33M  5.0G   1% /root/mydata</span><br><span class="line">/dev/sr0        4.3G  4.3G     0 100% /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用设备文件卸载</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># umount /dev/cdrom</span></span><br></pre></td></tr></table></figure><p><strong>2）强制卸载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 挂载光驱，并进入挂载点</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount /dev/cdrom /mnt &amp;&amp; cd /mnt</span></span><br><span class="line">mount: /dev/sr0 is write-protected, mounting <span class="built_in">read</span>-only</span><br><span class="line">[root@C7-Server01 mnt]<span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时尝试卸载光驱，会提示设备忙，无法卸载</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 mnt]<span class="comment"># umount /mnt</span></span><br><span class="line">umount: /mnt: target is busy.</span><br><span class="line">        (In some cases useful info about processes that use</span><br><span class="line">         the device is found by lsof(8) or fuser(1))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用-lf选项强制卸载</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 mnt]<span class="comment"># umount -lf /mnt</span></span><br><span class="line">[root@C7-Server01 mnt]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        42G  2.6G   40G   7% /</span><br><span class="line">devtmpfs        3.8G     0  3.8G   0% /dev</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs           3.9G   12M  3.8G   1% /run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       397M  162M  236M  41% /boot</span><br><span class="line">tmpfs           781M     0  781M   0% /run/user/0</span><br><span class="line">/dev/sdb1       5.0G   33M  5.0G   1% /root/mydata</span><br></pre></td></tr></table></figure><h2 id="sync：刷新文件系统缓冲区"><a href="#sync：刷新文件系统缓冲区" class="headerlink" title="sync：刷新文件系统缓冲区"></a>sync：刷新文件系统缓冲区</h2><p>sync命令会将内存缓冲区内的数据强制刷新到磁盘。Linux内核为了达到最佳的磁盘操作效率，默认会先在内存中将需要写入到磁盘的数据缓存起来，然后等待合适的时机将它们真正写入到磁盘中，这在绝大多数情况下都是没有任何问题的，而且还提高了系统的效率，但是如果系统出现宕机、掉电等情况，就可能会导致有些文件内容没能保存下来。当然，在Linux系统正常关机或者重启时，会将缓冲区中的内容自动同步到磁盘中。我们也可以手工执行sync命令，将内存中的文件缓冲内容强制写到磁盘中。</p><p>但是通常情况下没有必要执行这个命令，一是Linux内核会尽快让内存中的数据自动同步到磁盘上去，二是我们也无法预计什么时候会宕机、掉电。</p><p><strong>语法格式：sync [option]</strong> </p><p><strong>【使用示例】</strong></p><p><strong>手动将数据从缓冲区刷到磁盘中并重启系统</strong></p><p>**</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写一个测试循环脚本来完成三次同步，每次间隔1秒，然后重启系统**</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 mnt]<span class="comment"># for i in `seq 3`;do sync;sleep 1; done &amp;&amp; reboot;</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/05/02/5ccae6c094551.jpg"></p><h2 id="dd：转换或复制文件"><a href="#dd：转换或复制文件" class="headerlink" title="dd：转换或复制文件"></a>dd：转换或复制文件</h2><p>dd命令具有复制文件、转换文件和格式化文本的功能。</p><p><strong>语法格式：dd [option]</strong> </p><p><strong>重要选项参数</strong></p><p><img src="https://i.loli.net/2019/05/02/5ccae8ce512d2.jpg"></p><p><strong>【使用示例】</strong></p><p><strong>1）将/dev/sda1分区复制（备份）到文件中</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看磁盘使用情况</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        42G  2.6G   40G   7% /</span><br><span class="line">devtmpfs        3.8G     0  3.8G   0% /dev</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs           3.9G   12M  3.8G   1% /run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       397M  162M  236M  41% /boot</span><br><span class="line">tmpfs           781M     0  781M   0% /run/user/0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份分区表信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/sda1 of=sda1-partb.info</span></span><br><span class="line">819200+0 records <span class="keyword">in</span></span><br><span class="line">819200+0 records out</span><br><span class="line">419430400 bytes (419 MB) copied, 5.68928 s, 73.7 MB/s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看输出文件的信息</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h sda1-partb.info </span></span><br><span class="line">-rw-r--r-- 1 root root 400M May  2 19:48 sda1-partb.info</span><br></pre></td></tr></table></figure><p><strong>2）删除/dev/sdb1分区数据</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 挂载/dev/sdb1分区到root用户家目录下的mydata/目录</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># mount /dev/sdb1 mydata/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在mydata/目录下创建1000个文件</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># touch mydata/file&#123;01..1000&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统挂载信息，发现/dev/sdb1已使用33M，占比1%</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        42G  3.0G   39G   8% /</span><br><span class="line">devtmpfs        3.8G     0  3.8G   0% /dev</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs           3.9G   12M  3.8G   1% /run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       397M  162M  236M  41% /boot</span><br><span class="line">tmpfs           781M     0  781M   0% /run/user/0</span><br><span class="line">/dev/sdb1       5.0G   33M  5.0G   1% /root/mydata</span><br><span class="line"></span><br><span class="line"><span class="comment"># /dev/zero设备读取数据，写入到/dev/sdb1中，就会清空/dev/sdb1分区的数据</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/zero of=/dev/sdb1</span></span><br><span class="line">dd: writing to ‘/dev/sdb1’: No space left on device  <span class="comment"># 提示磁盘被写满</span></span><br><span class="line">10485761+0 records <span class="keyword">in</span></span><br><span class="line">10485760+0 records out</span><br><span class="line">5368709120 bytes (5.4 GB) copied, 73.561 s, 73.0 MB/s</span><br></pre></td></tr></table></figure><p><strong><em>/dev/zero是0字符设备，可产生连续不断的特殊数据流，生成的文件为特殊格式的数据文件（二进制）。</em></strong></p><p><strong>3）生成任意大小的文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一个大小为10M的测试文件test01</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/zero of=test01 bs=1M count=10</span></span><br><span class="line">10+0 records <span class="keyword">in</span></span><br><span class="line">10+0 records out</span><br><span class="line">10485760 bytes (10 MB) copied, 0.136475 s, 76.8 MB/s</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h test01 </span></span><br><span class="line">-rw-r--r-- 1 root root 10M May  2 20:11 test01</span><br></pre></td></tr></table></figure><p><strong>生成文件test01的大小为bs*count=1M*10=10M。</strong></p><p><strong>4）生成CentOS7的镜像文件</strong></p><p>在Windows系统里制作光盘的ISO镜像，还需要安装其他软件。但在Linux系统中只需要dd命令就足够了，可以使用dd命令，将从光驱读取的镜像复制到系统中，相当于光驱与磁盘对拷。使用此类防范可以不用ftp工具或lrzsz工具对镜像文件进行上传。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@C7-Server01 ~]<span class="comment"># dd if=/dev/cdrom of=CentOS74.img</span></span><br><span class="line">8962048+0 records <span class="keyword">in</span></span><br><span class="line">8962048+0 records out</span><br><span class="line">4588568576 bytes (4.6 GB) copied, 30.8377 s, 149 MB/s</span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># ll -h CentOS74.img </span></span><br><span class="line">-rw-r--r-- 1 root root 4.3G May  2 20:16 CentOS74.img</span><br></pre></td></tr></table></figure><p>这样我们就创建了一个用于KVM或OpenStack的母版镜像文件CentOS74.img。</p><p><strong>5）使用dd复制文件，并转换大小写</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在当前目录下创建测试文件，内容随便编辑</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># cat &gt; file01 &lt;&lt; EOF</span></span><br><span class="line">WWW.sn.Chinamobile.com</span><br><span class="line">我爱北京天安门！！！1234</span><br><span class="line">www.sina.com.CN</span><br><span class="line"><span class="comment">###!www.openstack.org</span></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用dd复制文件，并将原文件中所有大写字母转换为小写字母</span></span><br><span class="line"></span><br><span class="line">&gt; EOF</span><br><span class="line">&gt; [root@C7-Server01 ~]<span class="comment"># dd if=file01 of=file01_new conv=lcase</span></span><br><span class="line">&gt; 0+1 records <span class="keyword">in</span></span><br><span class="line">&gt; 0+1 records out</span><br><span class="line">&gt; 96 bytes (96 B) copied, 0.000108961 s, 881 kB/s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 产看file01_new文件内容</span></span><br><span class="line"></span><br><span class="line">[root@C7-Server01 ~]<span class="comment"># cat file01_new</span></span><br><span class="line">www.sn.chinamobile.com</span><br><span class="line">我爱北京天安门！！！1234</span><br><span class="line">www.sina.com.cn</span><br><span class="line"><span class="comment">###!www.openstack.org</span></span><br></pre></td></tr></table></figure><p><strong><em>Linux磁盘与文件系统管理命令掌握上述命令即可，还有三个用于交换分区管理的命令mkswap（创建交换分区）、swapon（激活交换分区）和swapoff（关闭交换分区）很少会被使用到，大家知道即可。如果在实际运维中需要，到时再通过man查询帮助即可。</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;fdisk：磁盘分区工具&quot;&gt;&lt;a href=&quot;#fdisk：磁盘分区工具&quot; class=&quot;headerlink&quot; title=&quot;fdisk：磁盘分区工具&quot;&gt;&lt;/a&gt;fdisk：磁盘分区工具&lt;/h2&gt;&lt;p&gt;fdisk是Linux下常用的磁盘分区工具。受mbr分区表的限制，fdisk工具只能给小于2TB的磁盘划分分区。如果使用fdisk对大于2TB的磁盘进行分区，虽然可以分区，但其仅识别2TB的空间，所以磁盘容量若超过2TB，就要使用parted分区工具（后面会讲）进行分区。
    
    </summary>
    
      <category term="Linux核心命令" scheme="https://kkutysllb.cn/categories/Linux%E6%A0%B8%E5%BF%83%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="Linux" scheme="https://kkutysllb.cn/tags/Linux/"/>
    
  </entry>
  
</feed>
